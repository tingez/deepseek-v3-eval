{
  "192eab2db6236874": {
    "email_id": "192eab2db6236874",
    "post_labels": [
      "LLM/inference"
    ],
    "post_content_cn": "Tom DÃ¶rr (@tom_doerr) äº2024å¹´10æœˆ31æ—¥æ˜ŸæœŸå››ä¸‹åˆ5:19å‘å¸ƒï¼š\nè™½ç„¶æˆ‘ç¡®ä¿¡405Bå’Œ8GBæ˜¾å­˜ä¸ä¼šä»¥ç«ç®­é€Ÿåº¦è¿è¡Œ",
    "post_content_en": "Tom DÃ¶rr (@tom_doerr) posted at 5:19 PM on Thu, Oct 31, 2024:\nThough I'm sure 405B with 8GB vram won't be running at rocket speed",
    "link_lists": [
      "https://t.co/1AztdJExTZ",
      "https://x.com/tom_doerr/status/1852143317636780044?t=xpEu7KWNWjCXmHqHBnTc2g&s=03"
    ],
    "post_summary_cn": "Tom DÃ¶rr æåˆ°405Bå’Œ8GBæ˜¾å­˜ä¸ä¼šä»¥æé€Ÿè¿è¡Œã€‚",
    "post_summary_en": "Tom DÃ¶rr mentioned that 405B with 8GB vram won't run at rocket speed.",
    "post_datetime": "2024-11-01T19:27:22-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "192f3dbdcbf233dd": {
    "email_id": "192f3dbdcbf233dd",
    "post_labels": [
      "LLM/OCR"
    ],
    "post_content_cn": "é˜…è¯» Datadrifters åœ¨ Medium ä¸Šçš„æ–‡ç« ã€ŠLlama 3.2-Vision for High-Precision OCR with Ollamaã€‹",
    "post_content_en": "Read â€œLlama 3.2-Vision for High-Precision OCR with Ollamaâ€œ by Datadrifters on Medium",
    "link_lists": [
      "https://medium.com/@datadrifters/llama-3-2-vision-for-high-precision-ocr-with-ollama-472222da0ab5"
    ],
    "post_summary_cn": "Datadrifters åœ¨ Medium ä¸Šå‘å¸ƒäº†ä¸€ç¯‡å…³äºä½¿ç”¨ Llama 3.2-Vision å’Œ Ollama è¿›è¡Œé«˜ç²¾åº¦ OCR çš„æ–‡ç« ã€‚",
    "post_summary_en": "Datadrifters published an article on Medium about using Llama 3.2-Vision and Ollama for high-precision OCR.",
    "post_datetime": "2024-03-11T13:08:45-08:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "192895e02386c8fd": {
    "email_id": "192895e02386c8fd",
    "post_labels": [
      "LLM/OCR"
    ],
    "post_content_cn": "Tom DÃ¶rr (@tom_doerr) äº2024å¹´10æœˆ13æ—¥æ˜ŸæœŸæ—¥ä¸Šåˆ11:08å‘å¸ƒï¼šOCRå·¥å…·åŒ…",
    "post_content_en": "Tom DÃ¶rr (@tom_doerr) posted at 11:08 AM on Sun, Oct 13, 2024: OCR toolkit",
    "link_lists": [
      "https://t.co/ui7ScfoEFD",
      "https://x.com/tom_doerr/status/1845527077795311623?t=YJ2DVR1JKU6RdtUvBMaN-w&s=03"
    ],
    "post_summary_cn": "Tom DÃ¶rr å‘å¸ƒäº†ä¸€ä¸ªå…³äºOCRå·¥å…·åŒ…çš„å¸–å­ã€‚",
    "post_summary_en": "Tom DÃ¶rr posted about an OCR toolkit.",
    "post_datetime": "2024-10-13T21:51:32-07:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "192017092e1b4935": {
    "email_id": "192017092e1b4935",
    "post_labels": [
      "LLM",
      "OCR"
    ],
    "post_content_cn": "è¿™ä¸ªå¾ˆæœ‰æ„æ€ï¼åŸºäº QWen2 0.5 B æ¨¡å‹ã€‚å·ç§° OCR 2.0ï¼Œ580M å‚æ•°çš„ç«¯åˆ°ç«¯ OCR æ¨¡å‹ï¼Œæ‹¿åˆ°äº† BLEU 0.972 åˆ†æ•°ğŸ”¥\n\n0.58B æ¨¡å‹ï¼Œè¿˜æ˜¯ç«¯åˆ°ç«¯çš„å¤šæ¨¡æ€ğŸ¤” è¿™ä¸ªæ•ˆæœæœ‰ç‚¹ç¦»è°±ï¼Œæ„Ÿå…´è¶£çš„å¯ä»¥è¯•è¯•",
    "post_content_en": "This is very interesting! Based on the QWen2 0.5 B model. It claims to be OCR 2.0, an end-to-end OCR model with 580M parameters, achieving a BLEU score of 0.972ğŸ”¥\n\nA 0.58B model, and it's end-to-end multimodalğŸ¤” The results are a bit unbelievable, interested parties can give it a try.",
    "link_lists": [
      "https://t.co/TxM511I8vV",
      "https://t.co/WIiiaZEXxY",
      "https://t.co/YD9kAfMiBS",
      "https://x.com/tuturetom/status/1835166243323887646?t=G3ScUkhJVkIyx5scb7oj-w&s=03"
    ],
    "post_summary_cn": "åŸºäº QWen2 0.5 B æ¨¡å‹çš„ OCR 2.0ï¼Œæ‹¥æœ‰ 580M å‚æ•°ï¼ŒBLEU åˆ†æ•°è¾¾åˆ° 0.972ï¼Œæ•ˆæœæƒŠäººã€‚",
    "post_summary_en": "OCR 2.0 based on the QWen2 0.5 B model, with 580M parameters, achieves a BLEU score of 0.972, with impressive results.",
    "post_datetime": "2024-09-17T12:23:27-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1922d0d014b9e3ae": {
    "email_id": "1922d0d014b9e3ae",
    "post_labels": [
      "LLM/edge"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 5:12 PM on Wed, Sep 25, 2024:\né«˜é€šæºæ‰‹ Meta æ¨ Llama 3.2: è®¾å¤‡ç«¯ AI çš„é‡å¤§çªç ´\n@Qualcomm x @AIatMeta\n\né«˜é€šä¸ Meta åˆä½œ, ä¼˜åŒ–äº† Llama 3.2 ç³»åˆ—æ¨¡å‹, ä½¿å®ƒèƒ½åœ¨æ­è½½éªé¾™ @Snapdragon å¹³å°çš„è®¾å¤‡ä¸Šè¿è¡Œ, è¿™ä¸€åˆä½œæ—¨åœ¨æ¨è¿›è®¾å¤‡ç«¯\nAI çš„å‘å±•ã€‚\n\né«˜é€šæä¾›äº†å¤šç§å·¥å…·å’Œèµ„æº, å¸®åŠ©å¼€å‘è€…åœ¨éªé¾™å¹³å°ä¸Šä¼˜åŒ–å’Œéƒ¨ç½² Llama 3.2:\n- Ollama",
    "post_content_en": "meng shao (@shao__meng) posted at 5:12 PM on Wed, Sep 25, 2024:\nQualcomm collaborates with Meta to launch Llama 3.2: A major breakthrough in on-device AI\n@Qualcomm x @AIatMeta\n\nQualcomm and Meta have collaborated to optimize the Llama 3.2 series models, enabling them to run on devices equipped with the Snapdragon @Snapdragon platform. This collaboration aims to advance the development of on-device AI.\n\nQualcomm provides various tools and resources to help developers optimize and deploy Llama 3.2 on the Snapdragon platform:\n- Ollama",
    "link_lists": [
      "https://t.co/yNjiw0hBDs",
      "https://x.com/shao__meng/status/1839095670571151753?t=3VzOSQaBw1PJSIc8mTGnFw&s=03"
    ],
    "post_summary_cn": "é«˜é€šä¸ Meta åˆä½œä¼˜åŒ– Llama 3.2 æ¨¡å‹ï¼Œä½¿å…¶èƒ½åœ¨éªé¾™å¹³å°ä¸Šè¿è¡Œï¼Œæ¨åŠ¨è®¾å¤‡ç«¯ AI å‘å±•ï¼Œå¹¶æä¾›å·¥å…·å¸®åŠ©å¼€å‘è€…ä¼˜åŒ–å’Œéƒ¨ç½²ã€‚",
    "post_summary_en": "Qualcomm and Meta collaborate to optimize Llama 3.2 for Snapdragon platforms, advancing on-device AI and providing tools for developers.",
    "post_datetime": "2024-09-25T23:38:00-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1911a21f6ff55c59": {
    "email_id": "1911a21f6ff55c59",
    "post_labels": [
      "LLM/edge"
    ],
    "post_content_cn": "Tom Huang (@tuturetom) posted at 9:12 AM on Sat, Aug 03, 2024:\nç›´æ¥åœ¨æ ‘è“æ´¾ä¸Šè¿è¡Œç«¯ä¾§å‘é‡æ•°æ®åº“å¹¶è¿›è¡Œç«¯ä¾§çš„ ã€Œè¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…ã€ğŸ¤¯ğŸ¤¯\n\nSQLite-vec ä¹Ÿå¤ªé…·äº†ï¼å…¼å®¹ OpenAI Embedding æ¥å£çš„å®ç°ï¼Œæ”¯æŒç¦»çº¿ Embedding",
    "post_content_en": "Tom Huang (@tuturetom) posted at 9:12 AM on Sat, Aug 03, 2024:\nRun a vector database directly on the Raspberry Pi and perform on-device \"semantic similarity matching\" ğŸ¤¯ğŸ¤¯\n\nSQLite-vec is so cool! It is compatible with the OpenAI Embedding interface and supports offline Embedding",
    "link_lists": [
      "https://t.co/jccppCPBX6",
      "https://x.com/tuturetom/status/1819768397900681355?t=scoy-2K5x_I5bxaZ4Qomzg&s=03"
    ],
    "post_summary_cn": "Tom Huang åœ¨æ ‘è“æ´¾ä¸Šè¿è¡Œç«¯ä¾§å‘é‡æ•°æ®åº“å¹¶è¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…ï¼Œä»‹ç»äº†æ”¯æŒç¦»çº¿ Embedding çš„ SQLite-vecã€‚",
    "post_summary_en": "Tom Huang runs a vector database on the Raspberry Pi for semantic similarity matching and introduces SQLite-vec, which supports offline Embedding.",
    "post_datetime": "2024-03-08T14:25:15-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192eab0114bb7dc3": {
    "email_id": "192eab0114bb7dc3",
    "post_labels": [
      "LLM/meeting"
    ],
    "post_content_cn": "AIGCLINK (@aigclink) posted at 0:32 AM on Fri, Nov 01, 2024:\nä¸€æ¬¾åŸºäºLangflowã€Groqã€OpenAIæ„å»ºçš„æ™ºèƒ½ä¼šè®®åˆ†æåŠ©æ‰‹ï¼šmeetingmindï¼Œå®ƒå¯ä»¥ç”¨30ç§’åˆ†æä¸€å°æ—¶çš„ä¼šè®®ï¼Œè‡ªåŠ¨ç”Ÿæˆä¼šè®®è®°å½•å’Œå…³é”®ä¿¡æ¯\n\nç‰¹ç‚¹ï¼š\n1ã€æä¾›ä»ªè¡¨æ¿æŸ¥çœ‹åˆ†æç»“æœ\n2ã€æ”¯æŒéŸ³é¢‘å½•åˆ¶å’Œæ–‡ä»¶ä¸Šä¼ ï¼Œè‡ªåŠ¨è½¬å½•\n3ã€è‡ªåŠ¨æå–å…³é”®ä¿¡æ¯ï¼Œä»»åŠ¡ã€å†³ç­–ã€é—®é¢˜ã€æ´å¯Ÿã€æˆªæ­¢æ—¥æœŸã€å‚ä¸è€…ã€åç»­è¡ŒåŠ¨ã€é£é™©å’Œè®®ç¨‹ç­‰",
    "post_content_en": "AIGCLINK (@aigclink) posted at 0:32 AM on Fri, Nov 01, 2024:\nAn intelligent meeting analysis assistant built on Langflow, Groq, and OpenAI: meetingmind, which can analyze a one-hour meeting in 30 seconds, automatically generating meeting minutes and key information.\n\nFeatures:\n1. Provides a dashboard to view analysis results\n2. Supports audio recording and file upload, automatically transcribing\n3. Automatically extracts key information such as tasks, decisions, issues, insights, deadlines, participants, follow-ups, risks, and agendas",
    "link_lists": [
      "https://t.co/5qHx8eY9Pi",
      "https://x.com/aigclink/status/1852252263877873898?t=HVSOB8RG7YQ2AKgKTfRMlQ&s=03"
    ],
    "post_summary_cn": "AIGCLINKå‘å¸ƒäº†ä¸€æ¬¾åŸºäºLangflowã€Groqã€OpenAIçš„æ™ºèƒ½ä¼šè®®åˆ†æåŠ©æ‰‹meetingmindï¼Œèƒ½åœ¨30ç§’å†…åˆ†æä¸€å°æ—¶ä¼šè®®ï¼Œè‡ªåŠ¨ç”Ÿæˆä¼šè®®è®°å½•å’Œå…³é”®ä¿¡æ¯ï¼Œæ”¯æŒéŸ³é¢‘å½•åˆ¶ã€æ–‡ä»¶ä¸Šä¼ å’Œè‡ªåŠ¨è½¬å½•ï¼Œå¹¶æå–ä»»åŠ¡ã€å†³ç­–ã€é—®é¢˜ç­‰å…³é”®ä¿¡æ¯ã€‚",
    "post_summary_en": "AIGCLINK introduced an intelligent meeting analysis assistant, meetingmind, built on Langflow, Groq, and OpenAI. It can analyze a one-hour meeting in 30 seconds, automatically generating meeting minutes and key information. It supports audio recording, file upload, automatic transcription, and extracts key information such as tasks, decisions, and issues.",
    "post_datetime": "2024-01-11T19:24:20-07:00",
    "source_language": "cn",
    "confidence_score": 1.0
  },
  "192fad0282d9a104": {
    "email_id": "192fad0282d9a104",
    "post_labels": [
      "LLM/annotation"
    ],
    "post_content_cn": "Tom DÃ¶rr (@tom_doerr) äº2024å¹´11æœˆ4æ—¥æ˜ŸæœŸä¸€ä¸Šåˆ7:39å‘å¸ƒï¼š\n\"Label Studio æ˜¯ä¸€ä¸ªå¤šç±»å‹æ•°æ®æ ‡æ³¨å’Œæ³¨é‡Šå·¥å…·ï¼Œå…·æœ‰æ ‡å‡†åŒ–è¾“å‡ºæ ¼å¼\"",
    "post_content_en": "Tom DÃ¶rr (@tom_doerr) posted at 7:39 AM on Mon, Nov 04, 2024:\n\"Label Studio is a multi-type data labeling and annotation tool with standardized output format\"",
    "link_lists": [
      "https://t.co/l8jmkviFfd",
      "https://x.com/tom_doerr/status/1853462058387583234?t=v0RtFooqGnIyJ327Ggzo0w&s=03"
    ],
    "post_summary_cn": "Tom DÃ¶rr ä»‹ç»äº† Label Studioï¼Œä¸€ä¸ªå¤šç±»å‹æ•°æ®æ ‡æ³¨å’Œæ³¨é‡Šå·¥å…·ï¼Œå…·æœ‰æ ‡å‡†åŒ–è¾“å‡ºæ ¼å¼ã€‚",
    "post_summary_en": "Tom DÃ¶rr introduced Label Studio, a multi-type data labeling and annotation tool with standardized output format.",
    "post_datetime": "2024-04-11T21:33:20-08:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "1936c211dd9acd6f": {
    "email_id": "1936c211dd9acd6f",
    "post_labels": [
      "LLM/front-end"
    ],
    "post_content_cn": "AIGCLINK (@aigclink) posted at 6:13 PM on Tue, Nov 26, 2024:\nèš‚èšé›†å›¢å¼€æºçš„ä¸€ä¸ªå¯ä»¥å¿«é€Ÿæ„å»ºAIèŠå¤©ç•Œé¢çš„å·¥å…·åŒ…ï¼šAnt Design\nXï¼Œç”¨å®ƒå¯ä»¥å¿«é€Ÿæ­å»ºå‡ºç±»ä¼¼ChatGPTé‚£ç§ä¸“ä¸šçš„å¯¹è¯ç•Œé¢ï¼Œä¸”å¯ä»¥è½»æ¾æ¥å…¥AIæ¨¡å‹\n\nä¸ç”¨ä»é›¶å¼€å§‹å†™ä»£ç ï¼Œç•Œé¢è®¾è®¡å·²ç»åšå¥½äº†ï¼Œç›´æ¥ç”¨å°±è¡Œ\næ”¯æŒè‡ªå®šä¹‰æ ·å¼\n\nå®ƒå¯ä»¥ç”¨äºå„ç§éœ€è¦å’ŒAIå¯¹è¯çš„åº”ç”¨ï¼Œæ¯”å¦‚æ™ºèƒ½å®¢æœç³»ç»Ÿã€AIåŠ©æ‰‹ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿç­‰",
    "post_content_en": "AIGCLINK (@aigclink) posted at 6:13 PM on Tue, Nov 26, 2024:\nAnt Group has open-sourced a toolkit called Ant Design X that can quickly build AI chat interfaces. It can be used to quickly create professional dialogue interfaces similar to ChatGPT and can easily integrate AI models.\n\nNo need to write code from scratch; the interface design is already done and can be used directly.\nSupports custom styles.\n\nIt can be used in various applications that require AI dialogue, such as intelligent customer service systems, AI assistants, and intelligent Q&A systems.",
    "link_lists": [
      "https://t.co/XqYqi9nbSN",
      "https://x.com/aigclink/status/1861594072743583942?t=-W8h4dOt5c3ZoQy7L4EEQg&s=03"
    ],
    "post_summary_cn": "èš‚èšé›†å›¢å¼€æºäº†Ant Design Xå·¥å…·åŒ…ï¼Œå¯å¿«é€Ÿæ„å»ºç±»ä¼¼ChatGPTçš„AIèŠå¤©ç•Œé¢ï¼Œæ”¯æŒè‡ªå®šä¹‰æ ·å¼ï¼Œé€‚ç”¨äºæ™ºèƒ½å®¢æœã€AIåŠ©æ‰‹ç­‰åº”ç”¨ã€‚",
    "post_summary_en": "Ant Group has open-sourced the Ant Design X toolkit, which can quickly build AI chat interfaces similar to ChatGPT, supports custom styles, and is suitable for applications like intelligent customer service and AI assistants.",
    "post_datetime": "2024-11-26T21:38:50-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "19074e4198617737": {
    "email_id": "19074e4198617737",
    "post_labels": [
      "LLM/front-end"
    ],
    "post_content_cn": "é˜…è¯»Om Kamathåœ¨Mediumä¸Šçš„æ–‡ç« ã€ŠDid Google Just Kill Streamlit?ã€‹",
    "post_content_en": "Read â€œDid Google Just Kill Streamlit?â€œ by Om Kamath on Medium",
    "link_lists": [
      "https://medium.com/google-cloud/did-google-just-kill-streamlit-76f719d9e275"
    ],
    "post_summary_cn": "Om Kamathåœ¨Mediumä¸Šå‘å¸ƒäº†ä¸€ç¯‡å…³äºGoogleæ˜¯å¦æ‰¼æ€äº†Streamlitçš„æ–‡ç« ã€‚",
    "post_summary_en": "Om Kamath published an article on Medium discussing whether Google has killed Streamlit.",
    "post_datetime": "2024-02-07T12:20:25-07:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "1905f6b02ef2f58e": {
    "email_id": "1905f6b02ef2f58e",
    "post_labels": [
      "LLM/front-end"
    ],
    "post_content_cn": "é˜…è¯»Preston Blackburnåœ¨Mediumä¸Šçš„æ–‡ç« â€œStreamlit vs HTMX â€” LLM Streaming Chatbotsâ€",
    "post_content_en": "Read â€œStreamlit vs HTMX â€” LLM Streaming Chatbotsâ€œ by Preston Blackburn on Medium",
    "link_lists": [
      "https://medium.com/@prestonblckbrn/streamlit-vs-htmx-llm-streaming-chatbots-783708e3cddb"
    ],
    "post_summary_cn": "Preston Blackburnåœ¨Mediumä¸Šå‘è¡¨äº†å…³äºStreamlitä¸HTMXåœ¨LLMæµå¼èŠå¤©æœºå™¨äººä¸­åº”ç”¨çš„æ–‡ç« ã€‚",
    "post_summary_en": "Preston Blackburn published an article on Medium comparing Streamlit and HTMX in the context of LLM streaming chatbots.",
    "post_datetime": "2024-06-28T08:16:06-07:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "18fe678380223406": {
    "email_id": "18fe678380223406",
    "post_labels": [
      "LLM/front-end",
      "LLM"
    ],
    "post_content_cn": "Jintao Zhang (@zhangjintao9020) äº2024å¹´6æœˆ4æ—¥æ˜ŸæœŸäºŒä¸Šåˆ5:50å‘å¸ƒï¼š\nGoogle å¼€æºäº†ä¸ªåŸºäº Python çš„ UI æ¡†æ¶ Mesop, æœ‰ç‚¹ç±»ä¼¼äº streamlit å’Œ Gradio ä¹‹ç±»çš„ç»„ä»¶ã€‚å…¶ä¸­çš„ç¤ºä¾‹çœ‹èµ·æ¥å°±æ˜¯ Gemini çš„æ ·å­äº†ã€‚è¿™ç±»ç»„ä»¶å¯èƒ½æ›´å¤šå°±æ˜¯ä¸ºäº†èƒ½è®©äººå¿«é€Ÿæ„å»ºä¸€ä¸ªä½¿ç”¨ #LLM API çš„åº”ç”¨å§",
    "post_content_en": "Jintao Zhang (@zhangjintao9020) posted at 5:50 AM on Tue, Jun 04, 2024:\nGoogle has open-sourced a Python-based UI framework called Mesop, which is somewhat similar to components like streamlit and Gradio. The examples look like Gemini. These components are probably more for quickly building applications that use #LLM APIs.",
    "link_lists": [
      "https://t.co/yWksBInzPh",
      "https://x.com/zhangjintao9020/status/1797974187375821287?t=drGARnhWrdR5g0HPLsPeLg&s=03"
    ],
    "post_summary_cn": "Google å¼€æºäº†ä¸€ä¸ªåŸºäº Python çš„ UI æ¡†æ¶ Mesopï¼Œç±»ä¼¼äº streamlit å’Œ Gradioï¼Œä¸»è¦ç”¨äºå¿«é€Ÿæ„å»ºä½¿ç”¨ #LLM API çš„åº”ç”¨ã€‚",
    "post_summary_en": "Google has open-sourced a Python-based UI framework called Mesop, similar to streamlit and Gradio, mainly for quickly building applications that use #LLM APIs.",
    "post_datetime": "2024-04-06T20:36:30-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "193070131f9b93fb": {
    "email_id": "193070131f9b93fb",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "é˜…è¯»Leon Eversbergåšå£«åœ¨Mediumä¸Šçš„æ–‡ç« ã€Šå¦‚ä½•ä»æ–‡æ¡£åˆ›å»ºRAGè¯„ä¼°æ•°æ®é›†ã€‹ã€‚",
    "post_content_en": "Read â€œHow to Create a RAG Evaluation Dataset From Documentsâ€œ by Dr. Leon Eversberg on Medium.",
    "link_lists": [
      "https://towardsdatascience.com/how-to-create-a-rag-evaluation-dataset-from-documents-140daa3cbe71"
    ],
    "post_summary_cn": "Leon Eversbergåšå£«åœ¨Mediumä¸Šåˆ†äº«äº†å¦‚ä½•ä»æ–‡æ¡£åˆ›å»ºRAGè¯„ä¼°æ•°æ®é›†çš„æ–¹æ³•ã€‚",
    "post_summary_en": "Dr. Leon Eversberg shares a method on Medium for creating a RAG evaluation dataset from documents.",
    "post_datetime": "2024-07-11T06:22:20-08:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "192def19a6b15af6": {
    "email_id": "192def19a6b15af6",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "Braintrust (@braintrustdata) äº2024å¹´10æœˆ29æ—¥æ˜ŸæœŸäºŒä¸Šåˆ9:17å‘å¸ƒã€‚",
    "post_content_en": "Braintrust (@braintrustdata) posted at 9:17 AM on Tue, Oct 29, 2024.",
    "link_lists": [
      "https://t.co/fdU8HG6Lql",
      "https://x.com/braintrustdata/status/1851297307775623465?t=xtQh7SFyixLynAebI9FVMg&s=03"
    ],
    "post_summary_cn": "Braintrust (@braintrustdata) åœ¨2024å¹´10æœˆ29æ—¥å‘å¸ƒäº†ä¸€æ¡æ¶ˆæ¯ã€‚",
    "post_summary_en": "Braintrust (@braintrustdata) posted a message on October 29, 2024.",
    "post_datetime": "2024-10-30T12:40:29-07:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "192deef375b504b3": {
    "email_id": "192deef375b504b3",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "Jason Wei (@_jasonwei) äº2024å¹´10æœˆ30æ—¥æ˜ŸæœŸä¸‰ä¸Šåˆ10:45å‘å¸ƒï¼š\nå¾ˆé«˜å…´å¼€æºä¸€ä¸ªæ–°çš„å¹»è§‰è¯„ä¼°å·¥å…·SimpleQAï¼\næœ‰ä¸€æ®µæ—¶é—´æ„Ÿè§‰æ²¡æœ‰ä¸€ä¸ªå¾ˆå¥½çš„åŸºå‡†æ¥è¯„ä¼°äº‹å®æ€§ï¼Œæ‰€ä»¥æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªç®€å•ã€å¯é ä¸”æ˜“äºç ”ç©¶äººå‘˜ä½¿ç”¨çš„è¯„ä¼°å·¥å…·ã€‚\nSimpleQAçš„ä¸»è¦ç‰¹ç‚¹ï¼š\n1. éå¸¸ç®€å•çš„è®¾ç½®ï¼š",
    "post_content_en": "Jason Wei (@_jasonwei) posted at 10:45 AM on Wed, Oct 30, 2024:\nExcited to open-source a new hallucinations eval called SimpleQA!\nFor a while it felt like there was no great benchmark for factuality, and so we created an eval that was simple, reliable, and easy-to-use for researchers.\nMain features of SimpleQA:\n1. Very simple setup:",
    "link_lists": [
      "https://t.co/ffsC9yshiF",
      "https://x.com/_jasonwei/status/1851681730845118799?t=LOpHX_GGQJDKXjzpVIgunA&s=03"
    ],
    "post_summary_cn": "Jason Weiå®£å¸ƒå¼€æºæ–°çš„å¹»è§‰è¯„ä¼°å·¥å…·SimpleQAï¼Œæ—¨åœ¨æä¾›ä¸€ä¸ªç®€å•ã€å¯é ä¸”æ˜“äºä½¿ç”¨çš„åŸºå‡†æ¥è¯„ä¼°äº‹å®æ€§ã€‚",
    "post_summary_en": "Jason Wei announced the open-source release of SimpleQA, a new hallucinations evaluation tool designed to provide a simple, reliable, and easy-to-use benchmark for assessing factuality.",
    "post_datetime": "2024-10-30T12:37:52-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "192d6bd3eb6f9a0d": {
    "email_id": "192d6bd3eb6f9a0d",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 0:31 AM on Mon, Oct 28, 2024:\nè®© AI æ›´æ‡‚æŒ‡ä»¤: RAG ç³»ç»Ÿçš„æ™ºèƒ½å¯¹é½æ–¹æ¡ˆ\n\nè¿™ä¸ªé¡¹ç›®åŒ…å«äº†è®ºæ–‡ã€æ•°æ®å’Œä»£ç å®ç°, ä¸»è¦æ˜¯ RAG é¢†åŸŸçš„æŒ‡ä»¤å¯¹é½ç®¡é“ç³»ç»Ÿå’Œè‡ªåŠ¨è¯„ä¼°åŸºå‡†æµ‹è¯•ç³»ç»Ÿ:\nâ€» VIF-RAG: ä¸€ä¸ªåˆ›æ–°çš„æŒ‡ä»¤å¯¹é½ç®¡é“ç³»ç»Ÿ\nâ€» FollowRAG: ä¸€ä¸ªè‡ªåŠ¨è¯„ä¼°åŸºå‡†æµ‹è¯•ç³»ç»Ÿ\n\nä¸»è¦å†…å®¹:\n- VIF-RAG æ˜¯é¦–ä¸ªè‡ªåŠ¨åŒ–ã€å¯æ‰©å±•ã€å¯éªŒè¯çš„æ•°æ®åˆæˆç®¡é“",
    "post_content_en": "meng shao (@shao__meng) posted at 0:31 AM on Mon, Oct 28, 2024:\nMaking AI Understand Instructions Better: Intelligent Alignment Solutions for RAG Systems\n\nThis project includes papers, data, and code implementations, mainly focusing on instruction alignment pipeline systems and automatic evaluation benchmark systems in the RAG field:\nâ€» VIF-RAG: An innovative instruction alignment pipeline system\nâ€» FollowRAG: An automatic evaluation benchmark system\n\nMain content:\n- VIF-RAG is the first automated, scalable, and verifiable data synthesis pipeline",
    "link_lists": [
      "https://t.co/fiviPvzQSv",
      "https://x.com/shao__meng/status/1850802644761391420?t=imDLlCeUMOP_I-6jnNJ7Qg&s=03"
    ],
    "post_summary_cn": "meng shao å‘å¸ƒäº†ä¸€ä¸ªå…³äº RAG ç³»ç»Ÿçš„æ™ºèƒ½å¯¹é½æ–¹æ¡ˆçš„é¡¹ç›®ï¼ŒåŒ…å« VIF-RAG å’Œ FollowRAG ä¸¤ä¸ªä¸»è¦ç³»ç»Ÿï¼Œæ—¨åœ¨æé«˜ AI å¯¹æŒ‡ä»¤çš„ç†è§£ã€‚",
    "post_summary_en": "meng shao posted a project on intelligent alignment solutions for RAG systems, including VIF-RAG and FollowRAG, aimed at improving AI's understanding of instructions.",
    "post_datetime": "2024-10-28T22:26:20-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192d185f6bde68e6": {
    "email_id": "192d185f6bde68e6",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 5:20 AM on Sun, Oct 27, 2024:\nRAGChecker: ç»†ç²’åº¦ RAG è¯Šæ–­è¯„ä¼°æ¡†æ¶\n\n@AmazonScience å¼€æºçš„ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼° RAG ç³»ç»Ÿçš„ç»¼åˆæ€§è‡ªåŠ¨è¯„ä¼°æ¡†æ¶, æä¾›äº†ä¸€å¥—å®Œæ•´çš„æŒ‡æ ‡å’Œå·¥å…·, ç”¨äºæ·±å…¥åˆ†æ RAG æ€§èƒ½ã€‚\n\nâ€» ä¸»è¦ç‰¹è‰²åŠŸèƒ½ â€»\n\nå…¨é¢çš„è¯„ä¼°ä½“ç³»:\n- æ•´ä½“æŒ‡æ ‡: è¯„ä¼°å®Œæ•´ RAG æµç¨‹\n- è¯Šæ–­æ€§æŒ‡æ ‡: åˆ†åˆ«é’ˆå¯¹æ£€ç´¢ç»„ä»¶å’Œç”Ÿæˆç»„ä»¶\n- ç»†ç²’åº¦è¯„ä¼°:",
    "post_content_en": "meng shao (@shao__meng) posted at 5:20 AM on Sun, Oct 27, 2024:\nRAGChecker: Fine-grained RAG Diagnostic Evaluation Framework\n\n@AmazonScience has open-sourced a comprehensive automatic evaluation framework specifically designed for evaluating RAG systems, providing a complete set of metrics and tools for in-depth analysis of RAG performance.\n\nâ€» Main Features â€»\n\nComprehensive evaluation system:\n- Overall metrics: Evaluate the entire RAG process\n- Diagnostic metrics: Specifically for retrieval and generation components\n- Fine-grained evaluation:",
    "link_lists": [
      "https://t.co/0qX6oZOO5j",
      "https://x.com/shao__meng/status/1850512837711659211?t=gMoftwD44-YANOdjqYhHow&s=03"
    ],
    "post_summary_cn": "meng shao ä»‹ç»äº†ç”± @AmazonScience å¼€æºçš„ RAGCheckerï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼° RAG ç³»ç»Ÿçš„ç»¼åˆæ€§è‡ªåŠ¨è¯„ä¼°æ¡†æ¶ï¼Œæä¾›å…¨é¢çš„è¯„ä¼°ä½“ç³»ï¼ŒåŒ…æ‹¬æ•´ä½“æŒ‡æ ‡ã€è¯Šæ–­æ€§æŒ‡æ ‡å’Œç»†ç²’åº¦è¯„ä¼°ã€‚",
    "post_summary_en": "meng shao introduced RAGChecker, an open-source comprehensive automatic evaluation framework by @AmazonScience for assessing RAG systems, offering a complete evaluation system including overall metrics, diagnostic metrics, and fine-grained evaluation.",
    "post_datetime": "2024-10-27T22:07:50-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192c6fb5e9da181b": {
    "email_id": "192c6fb5e9da181b",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 5:16 PM on Thu, Oct 24, 2024:\nå­é—®é¢˜è¦†ç›–é©±åŠ¨çš„ RAG ç³»ç»Ÿä¼˜åŒ–\n\næ¥è‡ª @SFResearch çš„è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„è¯„ä¼°æ¡†æ¶, ä¸»è¦èšç„¦äº \"å­é—®é¢˜è¦†ç›–ç‡\" è¿™ä¸ªç»´åº¦æ¥è¯„ä¼° RAG ç³»ç»Ÿ, ä¸»è¦å†…å®¹:\n- å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºæ ¸å¿ƒã€èƒŒæ™¯å’Œåç»­ä¸‰ç±»å­é—®é¢˜\n- æå‡ºäº†ä¸€ä¸ªåŸºäºå­é—®é¢˜è¦†ç›–çš„ç»†ç²’åº¦è¯„ä¼°åè®®",
    "post_content_en": "meng shao (@shao__meng) posted at 5:16 PM on Thu, Oct 24, 2024:\nSubproblem Coverage-Driven RAG System Optimization\n\nA paper from @SFResearch proposes a novel evaluation framework, focusing on the dimension of \"subproblem coverage\" to evaluate RAG systems. The main points are:\n- Decomposing complex problems into core, background, and follow-up subproblems\n- Proposing a fine-grained evaluation protocol based on subproblem coverage",
    "link_lists": [
      "https://t.co/9lLn0EAFhe",
      "https://x.com/shao__meng/status/1849605989894672821?t=Lo2Sv_lmVyNroW9J2HA6BA&s=03"
    ],
    "post_summary_cn": "meng shao (@shao__meng) å‘å¸ƒäº†ä¸€ç¯‡å…³äº RAG ç³»ç»Ÿä¼˜åŒ–çš„å¸–å­ï¼Œä»‹ç»äº† @SFResearch æå‡ºçš„åŸºäºå­é—®é¢˜è¦†ç›–ç‡çš„è¯„ä¼°æ¡†æ¶ï¼ŒåŒ…æ‹¬å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºä¸‰ç±»å­é—®é¢˜å¹¶æå‡ºç»†ç²’åº¦è¯„ä¼°åè®®ã€‚",
    "post_summary_en": "meng shao (@shao__meng) posted about RAG system optimization, introducing a novel evaluation framework from @SFResearch that focuses on subproblem coverage, including decomposing complex problems into three types of subproblems and proposing a fine-grained evaluation protocol.",
    "post_datetime": "2024-10-25T21:00:16-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192c1d52c1896f13": {
    "email_id": "192c1d52c1896f13",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 5:16 PM on Thu, Oct 24, 2024:\nå­é—®é¢˜è¦†ç›–é©±åŠ¨çš„ RAG ç³»ç»Ÿä¼˜åŒ–\n\næ¥è‡ª @SFResearch çš„è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„è¯„ä¼°æ¡†æ¶, ä¸»è¦èšç„¦äº \"å­é—®é¢˜è¦†ç›–ç‡\" è¿™ä¸ªç»´åº¦æ¥è¯„ä¼° RAG ç³»ç»Ÿ, ä¸»è¦å†…å®¹:\n- å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºæ ¸å¿ƒã€èƒŒæ™¯å’Œåç»­ä¸‰ç±»å­é—®é¢˜\n- æå‡ºäº†ä¸€ä¸ªåŸºäºå­é—®é¢˜è¦†ç›–çš„ç»†ç²’åº¦è¯„ä¼°åè®®",
    "post_content_en": "meng shao (@shao__meng) posted at 5:16 PM on Thu, Oct 24, 2024:\nSubproblem Coverage-Driven RAG System Optimization\n\nA paper from @SFResearch proposes a novel evaluation framework, focusing on the dimension of \"subproblem coverage\" to evaluate RAG systems, main content:\n- Decompose complex problems into core, background, and follow-up subproblems\n- Propose a fine-grained evaluation protocol based on subproblem coverage",
    "link_lists": [
      "https://t.co/9lLn0EAFhe",
      "https://x.com/shao__meng/status/1849605989894672821?t=-AZKGS_2LX-TgL5Vwtde-A&s=03"
    ],
    "post_summary_cn": "meng shao åˆ†äº«äº†ä¸€ç¯‡å…³äº RAG ç³»ç»Ÿä¼˜åŒ–çš„è®ºæ–‡ï¼Œè¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºå­é—®é¢˜è¦†ç›–ç‡çš„è¯„ä¼°æ¡†æ¶ï¼Œå°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºä¸‰ç±»å­é—®é¢˜ï¼Œå¹¶æå‡ºäº†ç»†ç²’åº¦çš„è¯„ä¼°åè®®ã€‚",
    "post_summary_en": "meng shao shared a paper on RAG system optimization, which proposes an evaluation framework based on subproblem coverage, decomposing complex problems into three types of subproblems and proposing a fine-grained evaluation protocol.",
    "post_datetime": "2024-10-24T21:00:27-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192bd0e74d6cf141": {
    "email_id": "192bd0e74d6cf141",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 5:07 PM on Wed, Oct 23, 2024:\nRAG è¯„ä¼°å·¥ç¨‹å®è·µ: Ragas æŒ‡æ ‡ä½“ç³»ä¸ Comet Opik é›†æˆ\n@Cometml @ragas_io\n\nè¿™ç¯‡æ–‡æ¡£ä¸»è¦ä»‹ç»äº†å¦‚ä½•å°† Ragas ä¸ Opik å¹³å°ç»“åˆä½¿ç”¨æ¥ç›‘æ§å’Œè¯„ä¼° RAG pipeline.\n\nä¸¤ç§è¯„ä¼°æ–¹æ³•\n\n1. å¯¹è¿½è¸ª(Traces)è¿›è¡Œè¯„åˆ†\n- é€‚ç”¨äºç”Ÿäº§ç¯å¢ƒä¸­çš„å®æ—¶è¯„ä¼°\n- å¯ä»¥è¿½è¸ªå•ä¸ªæŸ¥è¯¢çš„å®Œæ•´å¤„ç†æµç¨‹\n- èƒ½å¤Ÿå®æ—¶è·å–è¯„åˆ†ç»“æœ",
    "post_content_en": "meng shao (@shao__meng) posted at 5:07 PM on Wed, Oct 23, 2024:\nRAG Evaluation Engineering Practice: Ragas Metrics System and Comet Opik Integration\n@Cometml @ragas_io\n\nThis document mainly introduces how to use Ragas with the Opik platform to monitor and evaluate the RAG pipeline.\n\nTwo evaluation methods\n\n1. Scoring Traces\n- Suitable for real-time evaluation in production environments\n- Can track the complete processing flow of a single query\n- Able to obtain scoring results in real-time",
    "link_lists": [
      "https://t.co/sFPDbPHxdG",
      "https://x.com/shao__meng/status/1849241214635356232?t=QNGdK49fbYqo_uH17Agg6A&s=03"
    ],
    "post_summary_cn": "æœ¬æ–‡ä»‹ç»äº†å¦‚ä½•å°†Ragasä¸Opikå¹³å°ç»“åˆä½¿ç”¨ï¼Œä»¥ç›‘æ§å’Œè¯„ä¼°RAG pipelineã€‚ä¸»è¦è®¨è®ºäº†ä¸¤ç§è¯„ä¼°æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯å¯¹è¿½è¸ªè¿›è¡Œè¯„åˆ†çš„æ–¹æ³•ï¼Œé€‚ç”¨äºç”Ÿäº§ç¯å¢ƒä¸­çš„å®æ—¶è¯„ä¼°ã€‚",
    "post_summary_en": "This document introduces how to use Ragas with the Opik platform to monitor and evaluate the RAG pipeline. It mainly discusses two evaluation methods, particularly the scoring of traces, which is suitable for real-time evaluation in production environments.",
    "post_datetime": "2024-10-23T22:44:54-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192b5441bf9af40a": {
    "email_id": "192b5441bf9af40a",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 11:51 PM on Mon, Oct 21, 2024:\nRagas v0.2 å‘å¸ƒ: ä» RAG è¿ˆå‘å…¨æ–¹ä½ LLM åº”ç”¨è¯„ä¼°\n\nLLM åº”ç”¨è¯„ä¼°æ¡†æ¶ Ragas @ragas_io äº 2023 å¹´ä¸­æœŸå¼€æº, æœ€åˆç›®æ ‡æ˜¯ä¸º RAG åº”ç”¨æä¾›è¯„ä¼°å·¥å…·, ä¸€å¹´å LLM\nåº”ç”¨å·²ç»å‘å±•è¶…è¶Šäº† RAG çš„èŒƒç•´ã€‚\n\nRagas v0.2 å¼€å§‹æ‰©å±•ä»¥æ”¯æŒæ›´å¹¿æ³›çš„ LLM åº”ç”¨è¯„ä¼°éœ€æ±‚, ç‰¹åˆ«æ˜¯ Agentic å·¥ä½œæµ, ä¸»è¦æ›´æ–° ğŸ‘‡ğŸ‘‡",
    "post_content_en": "meng shao (@shao__meng) posted at 11:51 PM on Mon, Oct 21, 2024:\nRagas v0.2 Released: From RAG to Comprehensive LLM Application Evaluation\n\nThe LLM application evaluation framework Ragas @ragas_io was open-sourced in mid-2023, initially aimed at providing evaluation tools for RAG applications. A year later, LLM\napplications have evolved beyond the scope of RAG.\n\nRagas v0.2 has begun to expand to support broader LLM application evaluation needs, particularly Agentic workflows, with major updates ğŸ‘‡ğŸ‘‡",
    "link_lists": [
      "https://t.co/IZErsBN7b3",
      "https://x.com/shao__meng/status/1848618137044062224?t=pJXbYaZEkh5ZXy-xxvD42A&s=03"
    ],
    "post_summary_cn": "Ragas v0.2 å‘å¸ƒï¼Œæ‰©å±•äº† LLM åº”ç”¨è¯„ä¼°æ¡†æ¶ï¼Œæ”¯æŒæ›´å¹¿æ³›çš„éœ€æ±‚ï¼Œç‰¹åˆ«æ˜¯ Agentic å·¥ä½œæµã€‚",
    "post_summary_en": "Ragas v0.2 has been released, expanding the LLM application evaluation framework to support broader needs, particularly Agentic workflows.",
    "post_datetime": "2024-10-22T10:26:34-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "191f8f965132937e": {
    "email_id": "191f8f965132937e",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation",
      "LLM/RAG"
    ],
    "post_content_cn": "orange.ai (@oran_ge) äº 2024å¹´9æœˆ15æ—¥ 6:42 AM å‘å¸ƒï¼š\nRAG å’Œ Long Context ä¹‹äº‰ï¼Œç»ˆäºæœ‰äº†é‡åŒ–çš„ç»“è®ºï¼š\n\nä¸ºé•¿ä¸Šä¸‹æ–‡è¯­è¨€æ¨¡å‹æ—¶ä»£çš„ RAG è¾©æŠ¤",
    "post_content_en": "orange.ai (@oran_ge) posted at 6:42 AM on Sun, Sep 15, 2024:\nThe debate between RAG and Long Context has finally reached a quantified conclusion:\n\nIn Defense of RAG in the Era of Long-Context Language Models",
    "link_lists": [
      "https://t.co/5tEacB9LJn",
      "https://t.co/djTITRMcVh",
      "https://x.com/oran_ge/status/1835313228416696371?t=j1_1XWSUaHH7SdzQuV3huA&s=03"
    ],
    "post_summary_cn": "orange.ai å‘å¸ƒäº†ä¸€ç¯‡å…³äº RAG å’Œé•¿ä¸Šä¸‹æ–‡è¯­è¨€æ¨¡å‹ä¹‹é—´äº‰è®ºçš„é‡åŒ–ç»“è®ºï¼Œä¸º RAG åœ¨é•¿ä¸Šä¸‹æ–‡è¯­è¨€æ¨¡å‹æ—¶ä»£çš„åº”ç”¨è¿›è¡Œäº†è¾©æŠ¤ã€‚",
    "post_summary_en": "orange.ai posted a quantified conclusion on the debate between RAG and Long Context, defending the use of RAG in the era of long-context language models.",
    "post_datetime": "2024-09-15T20:56:19-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1915f7118677a8ed": {
    "email_id": "1915f7118677a8ed",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "Kalyan KS (@kalyan_kpl) äº2024å¹´8æœˆ16æ—¥æ˜ŸæœŸäº”ä¸Šåˆ9:47å‘å¸ƒï¼š\nRAGChecker - è¯Šæ–­RAGç³»ç»Ÿ\n\nRAGCheckeræ¡†æ¶\n\nRAGCheckeræ˜¯ä¸€ä¸ªç”¨äºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿçš„ç»†ç²’åº¦è¯„ä¼°æ¡†æ¶ã€‚\n\nè¯¥æ¡†æ¶åŒ…æ‹¬æ£€ç´¢å’Œç”Ÿæˆæ¨¡å—çš„è¯Šæ–­æŒ‡æ ‡ã€‚\n\næ”¹è¿›çš„è¯„ä¼°å‡†ç¡®æ€§",
    "post_content_en": "Kalyan KS (@kalyan_kpl) posted at 9:47 AM on Fri, Aug 16, 2024:\nRAGChecker - Diagnosing RAG Systems\n\nRAGChecker Framework\n\nRAGChecker is a fine-grained evaluation framework for Retrieval-Augmented Generation (RAG) systems.\n\nThis framework includes diagnostic metrics for both retrieval and generation modules.\n\nImproved Evaluation Accuracy",
    "link_lists": [
      "https://t.co/MnBLtV1GVE",
      "https://x.com/kalyan_kpl/status/1824488109637243094?t=Gln7pJSw5qA7Y8CSa4Tygw&s=03"
    ],
    "post_summary_cn": "Kalyan KSä»‹ç»äº†RAGCheckerï¼Œä¸€ä¸ªç”¨äºè¯Šæ–­å’Œè¯„ä¼°æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿçš„ç»†ç²’åº¦æ¡†æ¶ï¼ŒåŒ…æ‹¬æ£€ç´¢å’Œç”Ÿæˆæ¨¡å—çš„è¯Šæ–­æŒ‡æ ‡ã€‚",
    "post_summary_en": "Kalyan KS introduced RAGChecker, a fine-grained framework for diagnosing and evaluating Retrieval-Augmented Generation (RAG) systems, including diagnostic metrics for both retrieval and generation modules.",
    "post_datetime": "2024-08-17T01:25:34-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "1915e8ff7f829004": {
    "email_id": "1915e8ff7f829004",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "elvis (@omarsar0) äº2024å¹´8æœˆ16æ—¥æ˜ŸæœŸäº”ä¸Šåˆ7:56å‘å¸ƒï¼š\nRAGCheckerï¼šä¸€ä¸ªç”¨äºè¯Šæ–­RAGä¸­æ£€ç´¢å’Œç”Ÿæˆæ¨¡å—çš„ç»†ç²’åº¦è¯„ä¼°æ¡†æ¶ã€‚\n\næ˜¾ç¤ºRAGCheckerä¸äººç±»åˆ¤æ–­æœ‰æ›´å¥½çš„ç›¸å…³æ€§ã€‚\n\næŠ¥å‘Šäº†RAGæ¶æ„è®¾è®¡é€‰æ‹©ä¸­çš„å‡ ä¸ªæ­ç¤ºæ€§è§è§£å’Œæƒè¡¡ã€‚",
    "post_content_en": "elvis (@omarsar0) posted at 7:56 AM on Fri, Aug 16, 2024:\nRAGChecker: a fine-grained evaluation framework for diagnosing retrieval\nand generation modules in RAG.\n\nShows that RAGChecker has better correlations with human judgment.\n\nReports several revealing insightful patterns and trade-offs in design\nchoices of RAG architectures.",
    "link_lists": [
      "https://t.co/ZgwCJQszVM",
      "https://x.com/omarsar0/status/1824460245051081216?t=OCzDcZdcdJqpdueMzu5xnw&s=03"
    ],
    "post_summary_cn": "elvis (@omarsar0) å‘å¸ƒäº†ä¸€ä¸ªåä¸ºRAGCheckerçš„ç»†ç²’åº¦è¯„ä¼°æ¡†æ¶ï¼Œç”¨äºè¯Šæ–­RAGä¸­çš„æ£€ç´¢å’Œç”Ÿæˆæ¨¡å—ã€‚è¯¥æ¡†æ¶ä¸äººç±»åˆ¤æ–­æœ‰æ›´å¥½çš„ç›¸å…³æ€§ï¼Œå¹¶æ­ç¤ºäº†RAGæ¶æ„è®¾è®¡é€‰æ‹©ä¸­çš„ä¸€äº›è§è§£å’Œæƒè¡¡ã€‚",
    "post_summary_en": "elvis (@omarsar0) introduced RAGChecker, a fine-grained evaluation framework for diagnosing retrieval and generation modules in RAG. It shows better correlations with human judgment and reveals insightful patterns and trade-offs in RAG architecture design choices.",
    "post_datetime": "2024-08-16T21:19:40-07:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "1913b8985d0a921e": {
    "email_id": "1913b8985d0a921e",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "Kalyan KS (@kalyan_kpl) äº2024å¹´8æœˆ9æ—¥æ˜ŸæœŸäº”ä¸Šåˆ9:11å‘å¸ƒï¼š\nWalledEval - LLMå®‰å…¨è¯„ä¼°å·¥å…·åŒ…\n\nWalledEvalæ˜¯ä¸€ä¸ªå…¨é¢çš„AIå®‰å…¨æµ‹è¯•å·¥å…·åŒ…ï¼Œæ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚\n\nè¯¥å·¥å…·åŒ…å…·æœ‰å¤šåŠŸèƒ½æ€§ï¼Œé€‚ç”¨äºå„ç§æ¨¡å‹ã€‚\n\nå®ƒå¯ä»¥è¯„ä¼°å¼€æ”¾æƒé‡æ¨¡å‹å’Œé€šè¿‡APIè®¿é—®çš„æ¨¡å‹ã€‚",
    "post_content_en": "Kalyan KS (@kalyan_kpl) posted at 9:11 AM on Fri, Aug 09, 2024:\nWalledEval - LLM Safety Evaluation Toolkit\n\nWalledEval is a comprehensive AI safety testing toolkit designed to evaluate large language models (LLMs).\n\nThe toolkit is versatile, accommodating a wide range of models.\n\nIt can evaluate both open-weight models and those accessed via API.",
    "link_lists": [
      "https://t.co/e4VRmnDYxa",
      "https://x.com/kalyan_kpl/status/1821942405970772397?t=wBmtMR3AafpOGZ457r7fiQ&s=03"
    ],
    "post_summary_cn": "Kalyan KSä»‹ç»äº†WalledEvalï¼Œä¸€ä¸ªç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„AIå®‰å…¨æµ‹è¯•å·¥å…·åŒ…ï¼Œé€‚ç”¨äºå¤šç§æ¨¡å‹ã€‚",
    "post_summary_en": "Kalyan KS introduced WalledEval, an AI safety testing toolkit for evaluating large language models (LLMs), suitable for a variety of models.",
    "post_datetime": "2024-10-08T02:05:55-07:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "1913b886d4cbc848": {
    "email_id": "1913b886d4cbc848",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "Kalyan KS (@kalyan_kpl) äº2024å¹´8æœˆ8æ—¥æ™šä¸Š11:57å‘å¸ƒï¼š\nRAGEval - ç”¨äºè‡ªåŠ¨ç”ŸæˆLLMè¯„ä¼°æ•°æ®é›†çš„æ–°æ¡†æ¶\n\nç°æœ‰RAGåŸºå‡†çš„å±€é™æ€§\n\nå½“å‰çš„RAGåŸºå‡†ä¸»è¦è¯„ä¼°LLMå›ç­”ä¸€èˆ¬çŸ¥è¯†é—®é¢˜çš„èƒ½åŠ›ã€‚\n\nå®ƒä»¬æ— æ³•æœ‰æ•ˆè¯„ä¼°RAGç³»ç»Ÿåœ¨",
    "post_content_en": "Kalyan KS (@kalyan_kpl) posted at 11:57 PM on Thu, Aug 08, 2024:\nRAGEval - Novel framework for automatically generating LLM evaluation datasets\n\nLimitations of existing RAG benchmarks\n\nCurrent RAG benchmarks primarily assess LLMs' ability to answer general knowledge questions.\n\nThey don't effectively evaluate RAG systems' performance across",
    "link_lists": [
      "https://t.co/CocwzlCkRM",
      "https://x.com/kalyan_kpl/status/1821803072177516736?t=JkUU25223YbEsNAAGZYLCQ&s=03"
    ],
    "post_summary_cn": "Kalyan KSä»‹ç»äº†RAGEvalï¼Œä¸€ä¸ªç”¨äºè‡ªåŠ¨ç”ŸæˆLLMè¯„ä¼°æ•°æ®é›†çš„æ–°æ¡†æ¶ï¼Œå¹¶æŒ‡å‡ºäº†ç°æœ‰RAGåŸºå‡†çš„å±€é™æ€§ã€‚",
    "post_summary_en": "Kalyan KS introduced RAGEval, a novel framework for automatically generating LLM evaluation datasets, and highlighted the limitations of existing RAG benchmarks.",
    "post_datetime": "2024-10-08T02:04:43-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "1906a75dc2188234": {
    "email_id": "1906a75dc2188234",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "Simon (@YRSM_Simon) posted at 6:23 PM on Sat, May 11, 2024:\næœ¬å‘¨ï¼Œæˆ‘ä»¬ç»§ç»­æµ‹è¯„å„ ai search äº§å“çš„å‡†ç¡®ç‡ã€‚\n\næœ¬æ¬¡æµ‹è¯„ï¼Œé‡ç‚¹å…³æ³¨å„äº§å“åœ¨ã€Šå¤æ‚æŸ¥è¯¢ã€‹ä¸‹çš„è¡¨ç°ï¼Œå³å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„å¤šå®ä½“æˆ–å¤šç›®æ ‡çš„æŸ¥è¯¢ã€‚ä¾‹å¦‚ï¼Œ\n\n- è‡ºç£2022å¹´GDPç¸½é‡ç›¸æ¯”2012å¹´å¢åŠ äº†å¤šå°‘ç¾å…ƒï¼Ÿ\n- Which movie is longer, Hamlet or Gone with the Wind",
    "post_content_en": "Simon (@YRSM_Simon) posted at 6:23 PM on Sat, May 11, 2024:\nThis week, we continue to evaluate the accuracy of various AI search products.\n\nThis evaluation focuses on the performance of each product in 'complex queries,' which are multi-entity or multi-objective queries in a multilingual environment. For example,\n\n- How much did Taiwan's GDP increase in 2022 compared to 2012 in US dollars?\n- Which movie is longer, Hamlet or Gone with the Wind",
    "link_lists": [
      "https://t.co/Ymv6Qm5SX5",
      "https://x.com/YRSM_Simon/status/1789466458772378085?t=U5NqRxmd3Uoc6AdTMxPyrA&s=03"
    ],
    "post_summary_cn": "æœ¬å‘¨ç»§ç»­æµ‹è¯„å„AIæœç´¢äº§å“çš„å‡†ç¡®ç‡ï¼Œé‡ç‚¹å…³æ³¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„å¤æ‚æŸ¥è¯¢è¡¨ç°ã€‚",
    "post_summary_en": "This week, we continue to evaluate the accuracy of various AI search products, focusing on complex queries in a multilingual environment.",
    "post_datetime": "2024-06-30T11:43:49-07:00",
    "source_language": "cn",
    "confidence_score": 1.0
  },
  "1902f3def2a9b305": {
    "email_id": "1902f3def2a9b305",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "LangChain (@LangChainAI) äº2024å¹´6æœˆ18æ—¥æ˜ŸæœŸäºŒä¸Šåˆ11:18å‘å¸ƒï¼š\nä»£ç†è¯„ä¼°ğŸ¤–ï¼šè¯„ä¼°ä»£ç†çš„ç«¯åˆ°ç«¯æ€§èƒ½\n\nå°†LLMé©±åŠ¨çš„è‡ªåŠ¨åŒ–ä»£ç†æŠ•å…¥ç”Ÿäº§å…·æœ‰æŒ‘æˆ˜æ€§ã€‚éšç€å·¥å…·è°ƒç”¨LLMå’Œä»£ç†ç¼–æ’å·¥å…·çš„æ”¹è¿›ï¼Œå¼€å‘äººå‘˜éœ€è¦ç³»ç»Ÿçš„æ–¹æ³•æ¥è¯„ä¼°ä»£ç†æ€§èƒ½ã€‚\næˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªæ•™ç¨‹ï¼Œâ€¦",
    "post_content_en": "LangChain (@LangChainAI) posted at 11:18 AM on Tue, Jun 18, 2024:\nAgent evaluations ğŸ¤–: Evaluating an agent's end-to-end performance\n\nProductionizing LLM-powered automated agents is challenging. With improved tool-calling LLMs and agent orchestration tools, developers need systematic ways to evaluate agent performance.\nWe've added a tutorial,â€¦",
    "link_lists": [
      "https://t.co/1bhUjNJC1n",
      "https://x.com/LangChainAI/status/1803130164718739573?t=e0Wk2D1cpq0M7CH98raNTg&s=03"
    ],
    "post_summary_cn": "LangChainå‘å¸ƒå…³äºLLMé©±åŠ¨çš„è‡ªåŠ¨åŒ–ä»£ç†çš„ç«¯åˆ°ç«¯æ€§èƒ½è¯„ä¼°çš„æ•™ç¨‹ã€‚",
    "post_summary_en": "LangChain posted a tutorial on evaluating the end-to-end performance of LLM-powered automated agents.",
    "post_datetime": "2024-06-18T23:45:08-07:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "193c3827ce66e248": {
    "email_id": "193c3827ce66e248",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "Will (@FinanceYF5) posted at 7:43 PM on Fri, Dec 13, 2024: ä»¥ä¸‹æ˜¯è¿‘æœŸAIä»£ç†é¢†åŸŸå‘ç”Ÿçš„æ‰€æœ‰äº‹æƒ… ğŸ§µ",
    "post_content_en": "Will (@FinanceYF5) posted at 7:43 PM on Fri, Dec 13, 2024: Here is everything that has happened recently in the field of AI agents ğŸ§µ",
    "link_lists": [
      "https://t.co/GAieNzErQC",
      "https://x.com/FinanceYF5/status/1867777385653055823?t=-VF3zdFhHVkhUsIv_esTeQ&s=03"
    ],
    "post_summary_cn": "Will (@FinanceYF5) å‘å¸ƒäº†å…³äºè¿‘æœŸAIä»£ç†é¢†åŸŸçš„æ‰€æœ‰åŠ¨æ€ã€‚",
    "post_summary_en": "Will (@FinanceYF5) posted about all recent developments in the field of AI agents.",
    "post_datetime": "2024-12-13T20:52:08-08:00",
    "source_language": "cn",
    "confidence_score": 1.0
  },
  "193c0c0092687f54": {
    "email_id": "193c0c0092687f54",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "Tom DÃ¶rr (@tom_doerr) äº2024å¹´12æœˆ11æ—¥æ˜ŸæœŸä¸‰ä¸Šåˆ11:09å‘å¸ƒï¼š\nWren AI æ˜¯ä¸€ä¸ªå¼€æºçš„ SQL AI ä»£ç†ï¼Œå¯ä»¥å°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸º SQL æŸ¥è¯¢ï¼Œä¸å„ç§æ•°æ®åº“å’Œ LLM é›†æˆï¼Œå¹¶æä¾›ç”¨äºæ•°æ®åˆ†æå’ŒæŸ¥è¯¢ç”Ÿæˆçš„ç”¨æˆ·ç•Œé¢ã€‚",
    "post_content_en": "Tom DÃ¶rr (@tom_doerr) posted at 11:09 AM on Wed, Dec 11, 2024:\nWren AI is an open-source SQL AI agent that converts natural language questions into SQL queries, integrates with various databases and LLMs, and provides a user interface for data analysis and query generation.",
    "link_lists": [
      "https://t.co/nGehrQTWjk",
      "https://x.com/tom_doerr/status/1866923282081124684?t=QW9PMhOH-UrPYwUTUV0URg&s=03"
    ],
    "post_summary_cn": "Tom DÃ¶rr ä»‹ç»äº† Wren AIï¼Œä¸€ä¸ªå¼€æºçš„ SQL AI ä»£ç†ï¼Œèƒ½å¤Ÿå°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸º SQL æŸ¥è¯¢ï¼Œå¹¶ä¸å¤šç§æ•°æ®åº“å’Œ LLM é›†æˆï¼Œæä¾›æ•°æ®åˆ†æå’ŒæŸ¥è¯¢ç”Ÿæˆçš„ç”¨æˆ·ç•Œé¢ã€‚",
    "post_summary_en": "Tom DÃ¶rr introduced Wren AI, an open-source SQL AI agent that converts natural language into SQL queries, integrates with various databases and LLMs, and offers a user interface for data analysis and query generation.",
    "post_datetime": "2024-12-13T08:00:32-08:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "193bcbdddee5d289": {
    "email_id": "193bcbdddee5d289",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "Daily Dose of Data Science (@DailyDoseOfDS_) äº2024å¹´12æœˆ12æ—¥æ˜ŸæœŸå››ä¸Šåˆ5:09å‘å¸ƒï¼š\nä½¿ç”¨DSPyå¾®è°ƒRAGï¼Œæ¸…æ™°è§£é‡Šï¼š",
    "post_content_en": "Daily Dose of Data Science (@DailyDoseOfDS_) posted at 5:09 AM on Thu, Dec 12, 2024:\nFinetuning RAG using DSPy, clearly explained:",
    "link_lists": [
      "https://t.co/MKuLx5Y9hN",
      "https://x.com/DailyDoseOfDS_/status/1867195101002584355?t=1TzYsZRk8CivgPBFniY6XQ&s=03"
    ],
    "post_summary_cn": "Daily Dose of Data Scienceå‘å¸ƒäº†ä¸€æ¡å…³äºä½¿ç”¨DSPyå¾®è°ƒRAGçš„å¸–å­ã€‚",
    "post_summary_en": "Daily Dose of Data Science posted about finetuning RAG using DSPy.",
    "post_datetime": "2024-12-12T13:19:40-08:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "193b913a081e63aa": {
    "email_id": "193b913a081e63aa",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "Michael Ryan (@michaelryan207) äº2024å¹´12æœˆ10æ—¥æ˜ŸæœŸäºŒä¸Šåˆ8:34å‘å¸ƒï¼š\nä½¿ç”¨@_rchaves_çš„LangWatchå¯è§†åŒ–æ‚¨çš„è¯­è¨€ç¨‹åºä¼˜åŒ–ï¼\nè¶…çº§é…·çš„ç•Œé¢ï¼Œç”¨äºæŸ¥çœ‹å’Œä¼˜åŒ–è¯­è¨€ç¨‹åºï¼Œä½¿ç”¨#DSPyï¼\nMIPROv2åœ¨å‘å¸ƒè§†é¢‘ä¸­äº®ç›¸ğŸ‘€",
    "post_content_en": "Michael Ryan (@michaelryan207) posted at 8:34 AM on Tue, Dec 10, 2024:\nVisualize your Language Program Optimization with @_rchaves_â€™s LangWatch!\nSuper cool interface for viewing and optimizing Language Programs with\n#DSPy!\nMIPROv2 makes an appearance in the launch video ğŸ‘€",
    "link_lists": [
      "https://x.com/michaelryan207/status/1866521952086823138?t=T0g8-8g-S3S1hJt2zql8iQ&s=03"
    ],
    "post_summary_cn": "Michael Ryanä»‹ç»äº†ä½¿ç”¨LangWatchè¿›è¡Œè¯­è¨€ç¨‹åºä¼˜åŒ–çš„å¯è§†åŒ–å·¥å…·ï¼Œå¹¶æåˆ°MIPROv2åœ¨å‘å¸ƒè§†é¢‘ä¸­äº®ç›¸ã€‚",
    "post_summary_en": "Michael Ryan introduced LangWatch, a tool for visualizing language program optimization, and mentioned MIPROv2 appearing in the launch video.",
    "post_datetime": "2024-11-12T20:14:50-08:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "1939c788ff081e3a": {
    "email_id": "1939c788ff081e3a",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "idoubi (@idoubicc) posted at 6:57 PM on Thu, Dec 05, 2024: ä¸Šäº†ä¸€ä¸ª MCP Servers åº”ç”¨å•†åº—ï¼Œæ¬¢è¿æ¥æŸ¥æ‰¾å’Œæäº¤å¥½ç©çš„ MCP ServersğŸ‘‡",
    "post_content_en": "idoubi (@idoubicc) posted at 6:57 PM on Thu, Dec 05, 2024: Launched an MCP Servers app store, welcome to find and submit fun MCP ServersğŸ‘‡",
    "link_lists": [
      "https://t.co/uZVqggsjnN",
      "https://x.com/idoubicc/status/1864866694302437503?t=FxEeLb8EArA3-tZsJL71NA&s=03"
    ],
    "post_summary_cn": "idoubi å‘å¸ƒäº†ä¸€ä¸ª MCP Servers åº”ç”¨å•†åº—ï¼Œé‚€è¯·å¤§å®¶æŸ¥æ‰¾å’Œæäº¤æœ‰è¶£çš„ MCP Serversã€‚",
    "post_summary_en": "idoubi launched an MCP Servers app store, inviting everyone to find and submit fun MCP Servers.",
    "post_datetime": "2024-06-12T06:56:07-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "19337a37aa365f6b": {
    "email_id": "19337a37aa365f6b",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 1:21 AM on Sat, Nov 16, 2024:\nAI Agents æŠ€æœ¯æ ˆå…¨æ™¯ï¼šä» LLM åˆ° Agents çš„æŠ€æœ¯æ¼”è¿›\n\n// @Letta_AI å›¢é˜Ÿå‘å¸ƒçš„æ·±åº¦åˆ†æï¼ŒAI Agents æ­£ä»ç®€å•çš„ LLM\nåº”ç”¨æ¼”å˜ä¸ºé›†çŠ¶æ€ç®¡ç†ã€å·¥å…·è°ƒç”¨å’Œè‡ªä¸»å†³ç­–äºä¸€ä½“çš„å®Œæ•´æŠ€æœ¯æ ˆï¼Œè¿™ä¸€æ¼”è¿›è¿‡ç¨‹æ­£é‡å¡‘ AI åº”ç”¨çš„å¼€å‘æ¨¡å¼ï¼Œå¹¶å°†æ¨åŠ¨ä¸‹ä¸€ä»£ AI æœåŠ¡çš„æ ‡å‡†åŒ–éƒ¨ç½²\n\n// AI Agents çš„æ¼”è¿›ï¼š\n- 2022-2023",
    "post_content_en": "meng shao (@shao__meng) posted at 1:21 AM on Sat, Nov 16, 2024:\nAI Agents Technology Stack Overview: The Evolution from LLM to Agents\n\n// @Letta_AI team's in-depth analysis, AI Agents are evolving from simple LLM\napplications to a complete technology stack integrating state management, tool invocation, and autonomous decision-making. This evolution is reshaping the development model of AI applications and will promote the standardized deployment of next-generation AI services.\n\n// The Evolution of AI Agents:\n- 2022-2023",
    "link_lists": [
      "https://t.co/guBG6CKIZu",
      "https://x.com/shao__meng/status/1857715647217807712?t=AavHyWDG2LcGCamFiLegNw&s=03"
    ],
    "post_summary_cn": "meng shao (@shao__meng) å‘å¸ƒäº†å…³äº AI Agents æŠ€æœ¯æ ˆçš„æ¼”è¿›åˆ†æï¼ŒæŒ‡å‡º AI Agents æ­£ä»ç®€å•çš„ LLM åº”ç”¨å‘å±•ä¸ºé›†çŠ¶æ€ç®¡ç†ã€å·¥å…·è°ƒç”¨å’Œè‡ªä¸»å†³ç­–äºä¸€ä½“çš„å®Œæ•´æŠ€æœ¯æ ˆï¼Œè¿™å°†é‡å¡‘ AI åº”ç”¨çš„å¼€å‘æ¨¡å¼å¹¶æ¨åŠ¨ä¸‹ä¸€ä»£ AI æœåŠ¡çš„æ ‡å‡†åŒ–éƒ¨ç½²ã€‚",
    "post_summary_en": "meng shao (@shao__meng) posted an analysis on the evolution of AI Agents technology stack, highlighting that AI Agents are evolving from simple LLM applications to a complete technology stack integrating state management, tool invocation, and autonomous decision-making. This evolution will reshape the development model of AI applications and promote the standardized deployment of next-generation AI services.",
    "post_datetime": "2024-11-16T17:01:20-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "193378cb0ed494b3": {
    "email_id": "193378cb0ed494b3",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "elvis (@omarsar0) äº2024å¹´11æœˆ15æ—¥æ˜ŸæœŸäº”å‡Œæ™¨4:30å‘å¸ƒï¼š\nåŸºäºåŸºç¡€æ¨¡å‹çš„ä»£ç†å¯è§‚æµ‹æ€§çš„AgentOpsåˆ†ç±»æ³•\n\næ–°ç ”ç©¶åˆ†æäº†AgentOpså¹³å°å’Œå·¥å…·ï¼Œå¼ºè°ƒäº†ç¡®ä¿åŸºäºåŸºç¡€æ¨¡å‹çš„è‡ªä¸»ä»£ç†å¯é æ€§æ‰€éœ€çš„å…¨é¢å¯è§‚æµ‹æ€§å’Œå¯è¿½æº¯æ€§åŠŸèƒ½ã€‚",
    "post_content_en": "elvis (@omarsar0) posted at 4:30 AM on Fri, Nov 15, 2024:\nA Taxonomy of AgentOps for Enabling Observability of Foundation Model based Agents\n\nNew research analyzes AgentOps platforms and tools, highlighting the need for comprehensive observability and traceability features to ensure reliability in foundation model-based autonomous agents.",
    "link_lists": [
      "https://t.co/pHmey3pcWC",
      "https://x.com/omarsar0/status/1857400667318702118?t=7ZAi5P3KyezavFd_EkQpxw&s=03"
    ],
    "post_summary_cn": "elvis (@omarsar0) å‘å¸ƒäº†ä¸€ç¯‡å…³äºåŸºäºåŸºç¡€æ¨¡å‹çš„ä»£ç†å¯è§‚æµ‹æ€§çš„AgentOpsåˆ†ç±»æ³•çš„ç ”ç©¶ï¼Œå¼ºè°ƒäº†å…¨é¢å¯è§‚æµ‹æ€§å’Œå¯è¿½æº¯æ€§åŠŸèƒ½çš„é‡è¦æ€§ã€‚",
    "post_summary_en": "elvis (@omarsar0) posted research on a taxonomy of AgentOps for enabling observability of foundation model-based agents, emphasizing the importance of comprehensive observability and traceability features.",
    "post_datetime": "2024-11-16T16:36:26-08:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "193378b7a8487a78": {
    "email_id": "193378b7a8487a78",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 6:40 AM on Fri, Nov 15, 2024:\næç¤ºè¯å·¥ç¨‹å…¨æ™¯å›¾ï¼šAI æç¤ºè¯è®¾è®¡ä¸ç®¡ç†çš„ç³»ç»Ÿæ¡†æ¶\n\n// æ¥è‡ª AWS GenAI Lead @ordax\nåˆ†äº«çš„æ¡†æ¶å›¾å…¨é¢æ¶µç›–äº†æç¤ºè¯å·¥ç¨‹çš„å„ä¸ªç¯èŠ‚ï¼Œä»è®¾è®¡ã€ä¼˜åŒ–åˆ°éƒ¨ç½²å’Œç»´æŠ¤ï¼Œæ˜¯ä¸€ä¸ªç³»ç»Ÿæ€§çš„æ–¹æ³•è®ºå‚è€ƒï¼Œå¯¹äºæƒ³è¦ç³»ç»Ÿå­¦ä¹ å’Œåº”ç”¨æç¤ºå·¥ç¨‹çš„æœ‹å‹ä»¬æ¥è¯´æ˜¯å¾ˆæœ‰ä»·å€¼çš„æŒ‡å¯¼ã€‚\n\n1. æç¤ºè®¾è®¡(Prompt Design)",
    "post_content_en": "meng shao (@shao__meng) posted at 6:40 AM on Fri, Nov 15, 2024:\nPanorama of Prompt Engineering: A Systematic Framework for AI Prompt Design and Management\n\n// From AWS GenAI Lead @ordax\nThe shared framework comprehensively covers all aspects of prompt engineering, from design, optimization to deployment and maintenance. It is a systematic methodological reference and a valuable guide for those who want to systematically learn and apply prompt engineering.\n\n1. Prompt Design",
    "link_lists": [
      "https://t.co/tWyLPjL6JR",
      "https://x.com/shao__meng/status/1857433449298296956?t=84ziroLJ2ApfnPjWerMx5w&s=03"
    ],
    "post_summary_cn": "meng shao åˆ†äº«äº†æ¥è‡ª AWS GenAI Lead @ordax çš„æç¤ºè¯å·¥ç¨‹å…¨æ™¯å›¾ï¼Œæ¶µç›–äº†ä»è®¾è®¡ã€ä¼˜åŒ–åˆ°éƒ¨ç½²å’Œç»´æŠ¤çš„ç³»ç»Ÿæ€§æ–¹æ³•è®ºï¼Œå¯¹å­¦ä¹ å’Œåº”ç”¨æç¤ºå·¥ç¨‹çš„äººå…·æœ‰é‡è¦å‚è€ƒä»·å€¼ã€‚",
    "post_summary_en": "meng shao shared a panorama of prompt engineering from AWS GenAI Lead @ordax, covering a systematic methodology from design, optimization to deployment and maintenance, which is a valuable reference for those learning and applying prompt engineering.",
    "post_datetime": "2024-11-16T16:35:07-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "19330972819b334c": {
    "email_id": "19330972819b334c",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "é˜…è¯»Mehul Guptaåœ¨Mediumä¸Šçš„æ–‡ç« â€œMagentic-One, AutoGen, LangGraph, CrewAI, or OpenAI Swarm: Which Multi-AI Agent Framework is Best?â€",
    "post_content_en": "Read â€œMagentic-One, AutoGen, LangGraph, CrewAI, or OpenAI Swarm: Which Multi-AI Agent Framework is Best?â€œ by Mehul Gupta on Medium",
    "link_lists": [
      "https://medium.com/data-science-in-your-pocket/magentic-one-autogen-langgraph-crewai-or-openai-swarm-which-multi-ai-agent-framework-is-best-6629d8bd9509"
    ],
    "post_summary_cn": "Mehul Guptaåœ¨Mediumä¸Šå‘å¸ƒäº†ä¸€ç¯‡æ–‡ç« ï¼Œæ¢è®¨äº†Magentic-Oneã€AutoGenã€LangGraphã€CrewAIå’ŒOpenAI Swarmç­‰å¤šAIä»£ç†æ¡†æ¶çš„ä¼˜åŠ£ã€‚",
    "post_summary_en": "Mehul Gupta published an article on Medium discussing the pros and cons of multi-AI agent frameworks such as Magentic-One, AutoGen, LangGraph, CrewAI, and OpenAI Swarm.",
    "post_datetime": "2024-11-15T08:10:31-08:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "1932deb53555c3b8": {
    "email_id": "1932deb53555c3b8",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "Harrison Chase (@hwchase17) äº2024å¹´11æœˆ14æ—¥æ˜ŸæœŸå››ä¸‹åˆ1:14å‘å¸ƒï¼š\né¡¶çº§ä»£ç†ç”¨ä¾‹ï¼š\n\n- ç ”ç©¶å’Œæ€»ç»“\n- ä¸ªäººåŠ©ç†\n- å®¢æˆ·æœåŠ¡\n- ä»£ç ç”Ÿæˆ\n\næœ‰è¶£çš„æ˜¯ï¼Œå¤§å¤šæ•°æ–°å…´çš„ä»£ç†åˆåˆ›å…¬å¸ä¼¼ä¹éƒ½é›†ä¸­åœ¨å®¢æˆ·æœåŠ¡å’Œç¼–ç é¢†åŸŸã€‚",
    "post_content_en": "Harrison Chase (@hwchase17) posted at 1:14 PM on Thu, Nov 14, 2024:\nTop agent use cases:\n\n- research and summarization\n- personal assistant\n- customer service\n- code gen\n\ninteresting that most agent startups popping up seem to be in customer service and coding",
    "link_lists": [
      "https://t.co/4oqJmPNBj3",
      "https://t.co/lbRa1PRCEE",
      "https://x.com/hwchase17/status/1857170293061742743?t=3bVDdniynzynGTo4GkNNuw&s=03"
    ],
    "post_summary_cn": "Harrison Chaseè®¨è®ºäº†é¡¶çº§ä»£ç†çš„ç”¨ä¾‹ï¼ŒåŒ…æ‹¬ç ”ç©¶ã€ä¸ªäººåŠ©ç†ã€å®¢æˆ·æœåŠ¡å’Œä»£ç ç”Ÿæˆï¼Œå¹¶æŒ‡å‡ºæ–°å…´çš„ä»£ç†åˆåˆ›å…¬å¸ä¸»è¦é›†ä¸­åœ¨å®¢æˆ·æœåŠ¡å’Œç¼–ç é¢†åŸŸã€‚",
    "post_summary_en": "Harrison Chase discusses top agent use cases, including research, personal assistant, customer service, and code generation, noting that most emerging agent startups focus on customer service and coding.",
    "post_datetime": "2024-11-14T19:43:36-08:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "1932bb33822de5e4": {
    "email_id": "1932bb33822de5e4",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 3:18 PM on Wed, Nov 13, 2024:\nå‘Šåˆ« RPA: æ™ºèƒ½è‡ªåŠ¨åŒ–çš„æ–°çºªå…ƒ\nä½œè€… - @kimberlywtan(@a16z)\n\n// éšç€ AI æŠ€æœ¯çš„æˆç†Ÿï¼Œç‰¹åˆ«æ˜¯ LLM çš„å‡ºç°ï¼Œæ–°ä¸€ä»£æ™ºèƒ½è‡ªåŠ¨åŒ–æ­£åœ¨å–ä»£ä¼ ç»Ÿçš„ RPA\næµç¨‹è‡ªåŠ¨åŒ–å·¥å…·ï¼Œè¿™ä¸ä»…èƒ½çœŸæ­£å®ç°ä¼ä¸šå†…éƒ¨è¿è¥çš„å…¨é¢è‡ªåŠ¨åŒ–ï¼Œæ›´å¼€åˆ›äº†ä¸€ä¸ªä¼°å€¼è¶…è¿‡2500äº¿ç¾å…ƒçš„å…¨æ–°åˆ›ä¸šè“æµ·å¸‚åœº\n\n// ä¼ ç»Ÿ RPA çš„å±€é™æ€§\n- è™½ç„¶åƒ UiPath",
    "post_content_en": "meng shao (@shao__meng) posted at 3:18 PM on Wed, Nov 13, 2024:\nFarewell RPA: The New Era of Intelligent Automation\nAuthor - @kimberlywtan(@a16z)\n\n// With the maturity of AI technology, especially the emergence of LLMs, a new generation of intelligent automation is replacing traditional RPA\nprocess automation tools, which not only truly achieves comprehensive automation of internal operations within enterprises but also opens up a new entrepreneurial blue ocean market valued at over $250 billion.\n\n// Limitations of Traditional RPA\n- Although like UiPath",
    "link_lists": [
      "https://t.co/xX72THYqj7",
      "https://x.com/shao__meng/status/1856839145412596001?t=54tsROvBBai9YvjKWLMgWA&s=03"
    ],
    "post_summary_cn": "éšç€AIæŠ€æœ¯çš„æˆç†Ÿï¼Œç‰¹åˆ«æ˜¯LLMçš„å‡ºç°ï¼Œæ–°ä¸€ä»£æ™ºèƒ½è‡ªåŠ¨åŒ–æ­£åœ¨å–ä»£ä¼ ç»Ÿçš„RPAæµç¨‹è‡ªåŠ¨åŒ–å·¥å…·ï¼Œå¼€åˆ›äº†ä¸€ä¸ªä¼°å€¼è¶…è¿‡2500äº¿ç¾å…ƒçš„å…¨æ–°åˆ›ä¸šè“æµ·å¸‚åœºã€‚ä¼ ç»ŸRPAå­˜åœ¨å±€é™æ€§ã€‚",
    "post_summary_en": "With the maturity of AI technology, especially the emergence of LLMs, a new generation of intelligent automation is replacing traditional RPA process automation tools, opening up a new entrepreneurial blue ocean market valued at over $250 billion. Traditional RPA has limitations.",
    "post_datetime": "2024-11-14T09:23:05-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1931cdfadb549992": {
    "email_id": "1931cdfadb549992",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 8:09 AM on Sun, Nov 10, 2024:\nRD-Agent: å¾®è½¯å¼€æºçš„ç ”å‘è‡ªåŠ¨åŒ–å·¥å…·, ä¸“æ³¨äºæ•°æ®é©±åŠ¨çš„ AI ç ”å‘æµç¨‹, ç”¨ AI æ¥è‡ªåŠ¨åŒ– AI ç›¸å…³çš„ç ”å‘å·¥ä½œ\n\n# æ ¸å¿ƒæ¡†æ¶ç»„æˆ\n- \"R\"(Research)æ¨¡å—: è´Ÿè´£æå‡ºæ–°æƒ³æ³•\n- \"D\"(Development)æ¨¡å—: è´Ÿè´£å®ç°è¿™äº›æƒ³æ³•\n- æ”¯æŒæŒç»­è¿›åŒ–: é€šè¿‡åé¦ˆä¸æ–­æ”¹è¿›æ€§èƒ½\n\n# ä¸»è¦åº”ç”¨åœºæ™¯\n- ğŸ¤– æ•°æ®æŒ–æ˜Agent:",
    "post_content_en": "meng shao (@shao__meng) posted at 8:09 AM on Sun, Nov 10, 2024:\nRD-Agent: Microsoft's open-source R&D automation tool, focusing on data-driven AI R&D processes, using AI to automate AI-related R&D work\n\n# Core Framework Components\n- \"R\"(Research) module: Responsible for proposing new ideas\n- \"D\"(Development) module: Responsible for implementing these ideas\n- Supports continuous evolution: Continuously improves performance through feedback\n\n# Main Application Scenarios\n- ğŸ¤– Data Mining Agent:",
    "link_lists": [
      "https://t.co/SfeEwdtND4",
      "https://x.com/shao__meng/status/1855643962679472215?t=_ZstkgKp4YLmBR1AOR7EWQ&s=03"
    ],
    "post_summary_cn": "meng shao ä»‹ç»äº†å¾®è½¯å¼€æºçš„ RD-Agent å·¥å…·ï¼Œè¯¥å·¥å…·ä¸“æ³¨äºæ•°æ®é©±åŠ¨çš„ AI ç ”å‘æµç¨‹ï¼Œé€šè¿‡ AI è‡ªåŠ¨åŒ– AI ç›¸å…³çš„ç ”å‘å·¥ä½œã€‚æ ¸å¿ƒæ¡†æ¶åŒ…æ‹¬æå‡ºæ–°æƒ³æ³•çš„ \"R\" æ¨¡å—å’Œå®ç°è¿™äº›æƒ³æ³•çš„ \"D\" æ¨¡å—ï¼Œæ”¯æŒé€šè¿‡åé¦ˆä¸æ–­æ”¹è¿›æ€§èƒ½ã€‚ä¸»è¦åº”ç”¨åœºæ™¯åŒ…æ‹¬æ•°æ®æŒ–æ˜ Agentã€‚",
    "post_summary_en": "meng shao introduced Microsoft's open-source RD-Agent tool, which focuses on data-driven AI R&D processes, using AI to automate AI-related R&D work. The core framework includes the \"R\" module for proposing new ideas and the \"D\" module for implementing these ideas, supporting continuous performance improvement through feedback. Main application scenarios include data mining Agent.",
    "post_datetime": "2024-11-11T12:17:22-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1931a68971305413": {
    "email_id": "1931a68971305413",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "Noise (@liangwenhao3) å‘å¸ƒäº 2024å¹´11æœˆ10æ—¥ ä¸Šåˆ8:59ï¼š#AI #æ•°å­—äºº å®æ—¶è¯­éŸ³äº¤äº’æ•°å­—äººï¼Œæ”¯æŒç«¯åˆ°ç«¯è¯­éŸ³æ–¹æ¡ˆï¼ˆGLM-4-Voice - THGï¼‰å’Œçº§è”æ–¹æ¡ˆï¼ˆASR-LLM-TTS-THGï¼‰ã€‚å¯è‡ªå®šä¹‰å½¢è±¡ä¸éŸ³è‰²ï¼Œæ— é¡»è®­ç»ƒï¼Œæ”¯æŒéŸ³è‰²å…‹éš†ï¼Œé¦–åŒ…å»¶è¿Ÿä½è‡³3s",
    "post_content_en": "Noise (@liangwenhao3) posted at 8:59 AM on Sun, Nov 10, 2024: #AI #DigitalHuman Real-time voice interactive digital human, supports end-to-end voice solution (GLM-4-Voice - THG) and cascaded solution (ASR-LLM-TTS-THG). Customizable appearance and voice, no training required, supports voice cloning, with initial packet delay as low as 3s",
    "link_lists": [
      "https://t.co/8TjVCQzxjV",
      "https://x.com/liangwenhao3/status/1855656585072177364?t=s45_eqfjOD2qBsySS38kbA&s=03"
    ],
    "post_summary_cn": "Noise (@liangwenhao3) ä»‹ç»äº†å®æ—¶è¯­éŸ³äº¤äº’æ•°å­—äººï¼Œæ”¯æŒç«¯åˆ°ç«¯è¯­éŸ³æ–¹æ¡ˆå’Œçº§è”æ–¹æ¡ˆï¼Œå¯è‡ªå®šä¹‰å½¢è±¡ä¸éŸ³è‰²ï¼Œæ”¯æŒéŸ³è‰²å…‹éš†ï¼Œé¦–åŒ…å»¶è¿Ÿä½è‡³3ç§’ã€‚",
    "post_summary_en": "Noise (@liangwenhao3) introduced a real-time voice interactive digital human, supporting end-to-end and cascaded voice solutions, customizable appearance and voice, with voice cloning and initial packet delay as low as 3 seconds.",
    "post_datetime": "2024-11-11T00:48:03-08:00",
    "source_language": "cn",
    "confidence_score": 1.0
  },
  "19309ff5d98bffba": {
    "email_id": "19309ff5d98bffba",
    "post_labels": [
      "LLM/agent",
      "LLM/tutorial"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 3:53 PM on Thu, Nov 07, 2024:\nLLM æ™ºèƒ½ Agent: æ„å»ºå…·æœ‰æŒä¹…è®°å¿†çš„ AI ç³»ç»Ÿ\n# æŒæ¡å¦‚ä½•è®© AI Agent åƒæ“ä½œç³»ç»Ÿèˆ¬æ™ºèƒ½ç®¡ç†è®°å¿†, ä»è€Œæ„å»ºèƒ½æŒç»­å­¦ä¹ ã€è‡ªä¸»å†³ç­–çš„ä¸‹ä¸€ä»£ LLM åº”ç”¨\n@DeepLearningAI x @Letta_AI\n# è¯¾ç¨‹è®²å¸ˆ: @charlespacker @sarahwooders\n\n# ä¸»è¦å­¦ä¹ å†…å®¹\n- å­¦ä¹ å¦‚ä½•æ„å»ºå…·æœ‰é•¿æœŸã€æŒä¹…æ€§è®°å¿†çš„ Agent\n- äº†è§£å¦‚ä½•å°†",
    "post_content_en": "meng shao (@shao__meng) posted at 3:53 PM on Thu, Nov 07, 2024:\nLLM Intelligent Agent: Building AI Systems with Persistent Memory\n# Learn how to make AI Agents manage memory intelligently like an operating system, thereby building the next generation of LLM applications that can continuously learn and make autonomous decisions\n@DeepLearningAI x @Letta_AI\n# Course Instructors: @charlespacker @sarahwooders\n\n# Main Learning Content\n- Learn how to build Agents with long-term, persistent memory\n- Understand how to",
    "link_lists": [
      "https://t.co/P0Q5aGUNCg",
      "https://x.com/shao__meng/status/1854673617898160297?t=rTUcYTD-Uk1OqE2pG4RYzg&s=03"
    ],
    "post_summary_cn": "meng shao å‘å¸ƒäº†ä¸€ç¯‡å…³äºæ„å»ºå…·æœ‰æŒä¹…è®°å¿†çš„ LLM æ™ºèƒ½ Agent çš„å¸–å­ï¼Œä»‹ç»äº†å¦‚ä½•è®© AI Agent åƒæ“ä½œç³»ç»Ÿèˆ¬æ™ºèƒ½ç®¡ç†è®°å¿†ï¼Œä»è€Œæ„å»ºèƒ½æŒç»­å­¦ä¹ ã€è‡ªä¸»å†³ç­–çš„ä¸‹ä¸€ä»£ LLM åº”ç”¨ã€‚è¯¾ç¨‹ç”± @DeepLearningAI å’Œ @Letta_AI æä¾›ï¼Œè®²å¸ˆä¸º @charlespacker å’Œ @sarahwoodersã€‚ä¸»è¦å†…å®¹åŒ…æ‹¬å­¦ä¹ å¦‚ä½•æ„å»ºå…·æœ‰é•¿æœŸã€æŒä¹…æ€§è®°å¿†çš„ Agentã€‚",
    "post_summary_en": "meng shao posted about building LLM Intelligent Agents with persistent memory, explaining how to make AI Agents manage memory intelligently like an operating system, thereby building the next generation of LLM applications that can continuously learn and make autonomous decisions. The course is offered by @DeepLearningAI and @Letta_AI, with instructors @charlespacker and @sarahwooders. The main content includes learning how to build Agents with long-term, persistent memory.",
    "post_datetime": "2024-07-11T20:19:10-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192facf148e7279f": {
    "email_id": "192facf148e7279f",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "AIGCLINK (@aigclink) å‘å¸ƒäº 2024å¹´11æœˆ4æ—¥ ä¸‹åˆ5:58ï¼š\nAFLOWçš„ä»£ç æ€»ç®—æ˜¯å¼€æºäº†ï¼Œæ‰‹åŠ¨å·¥ä½œæµå˜è‡ªåŠ¨æ™ºèƒ½å·¥ä½œæµçš„ç¥å™¨",
    "post_content_en": "AIGCLINK (@aigclink) posted at 5:58 PM on Mon, Nov 04, 2024:\nThe code for AFLOW has finally been open-sourced, a tool that transforms manual workflows into automated intelligent workflows.",
    "link_lists": [
      "https://t.co/gPJJg8T8tV",
      "https://t.co/HJ2jLZBXaK",
      "https://x.com/aigclink/status/1853617774901551395?t=CM0vmGkrkh9p2VckZGiMSA&s=03"
    ],
    "post_summary_cn": "AFLOWä»£ç å·²å¼€æºï¼Œå¯å°†æ‰‹åŠ¨å·¥ä½œæµè½¬å˜ä¸ºè‡ªåŠ¨æ™ºèƒ½å·¥ä½œæµã€‚",
    "post_summary_en": "AFLOW code has been open-sourced, transforming manual workflows into automated intelligent workflows.",
    "post_datetime": "2024-04-11T21:32:09-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192b7826e44c98d1": {
    "email_id": "192b7826e44c98d1",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "orange.ai (@oran_ge) posted at 8:25 PM on Tue, Oct 22, 2024:\nDify å‘å¸ƒäº† NotebookLM å·¥ä½œæµï¼\nå¼€å‘è€…ç›´æ¥ Copyï¼Œä¸ç”¨é‡å¤åŠ³åŠ¨äº† ğŸ˜‚",
    "post_content_en": "orange.ai (@oran_ge) posted at 8:25 PM on Tue, Oct 22, 2024:\nDify has released the NotebookLM workflow!\nDevelopers can directly copy it, no need to repeat the work ğŸ˜‚",
    "link_lists": [
      "https://x.com/oran_ge/status/1848928586264416551?t=9cL3hXhm7ko9RnEZSizveg&s=03"
    ],
    "post_summary_cn": "Difyå‘å¸ƒäº†NotebookLMå·¥ä½œæµï¼Œå¼€å‘è€…å¯ä»¥ç›´æ¥å¤åˆ¶ä½¿ç”¨ï¼Œæ— éœ€é‡å¤åŠ³åŠ¨ã€‚",
    "post_summary_en": "Dify has released the NotebookLM workflow, allowing developers to directly copy and use it without repeating the work.",
    "post_datetime": "2024-10-22T20:53:50-07:00",
    "source_language": "cn",
    "confidence_score": 1.0
  },
  "192b260433731315": {
    "email_id": "192b260433731315",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 3:22 AM on Mon, Oct 21, 2024: ä»æ–°æ‰‹åˆ°ä¸“å®¶: 12 æ­¥æŒæ¡ AI Agent å¼€å‘ æ–‡ç« æä¾›äº†ä¸€ä¸ªå…¨é¢çš„ AI Agent å­¦ä¹ è·¯å¾„, æ¶µç›–ä»ç”Ÿæˆå¼ AI åŸºç¡€åˆ°é«˜çº§ Agentic RAG ç³»ç»Ÿçš„ 12 ä¸ªå…³é”®æ­¥éª¤ã€‚å®ƒä¸ºè¯»è€…æä¾›äº†ç†è®ºçŸ¥è¯†å’Œå®è·µæŒ‡å¯¼, åŒ…æ‹¬ç¼–ç¨‹åŸºç¡€ã€å¤§è¯­è¨€æ¨¡å‹ã€æç¤ºå·¥ç¨‹ã€å„ç§æ¡†æ¶çš„ä½¿ç”¨ï¼Œä»¥åŠä»æ— ä»£ç å·¥å…·åˆ° Python ç¼–ç¨‹çš„å®é™…å¼€å‘ç»éªŒ ğŸ‘‡ğŸ‘‡ğŸ‘‡",
    "post_content_en": "meng shao (@shao__meng) posted at 3:22 AM on Mon, Oct 21, 2024: From Novice to Expert: 12 Steps to Master AI Agent Development The article provides a comprehensive learning path for AI Agent, covering 12 key steps from the basics of generative AI to advanced Agentic RAG systems. It offers readers theoretical knowledge and practical guidance, including programming basics, large language models, prompt engineering, the use of various frameworks, and practical development experience from no-code tools to Python programming ğŸ‘‡ğŸ‘‡ğŸ‘‡",
    "link_lists": [
      "https://t.co/6M7RymhsKh",
      "https://x.com/shao__meng/status/1848308814715437317?t=5-2xeS5KJ5Hx3jemYGO0Ww&s=03"
    ],
    "post_summary_cn": "æ–‡ç« ä»‹ç»äº†ä»æ–°æ‰‹åˆ°ä¸“å®¶çš„12æ­¥AI Agentå¼€å‘å­¦ä¹ è·¯å¾„ï¼Œæ¶µç›–ç”Ÿæˆå¼AIåŸºç¡€åˆ°é«˜çº§Agentic RAGç³»ç»Ÿï¼Œæä¾›ç†è®ºçŸ¥è¯†å’Œå®è·µæŒ‡å¯¼ã€‚",
    "post_summary_en": "The article outlines a 12-step learning path for AI Agent development, from the basics of generative AI to advanced Agentic RAG systems, offering both theoretical knowledge and practical guidance.",
    "post_datetime": "2024-10-21T20:58:27-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192b25ffe5cadfcb": {
    "email_id": "192b25ffe5cadfcb",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "Ningyu Zhang@ZJU (@zxlzr) äº2024å¹´10æœˆ20æ—¥æ˜ŸæœŸæ—¥ä¸Šåˆ9:12å‘å¸ƒï¼š\nä»‹ç»æˆ‘ä»¬çš„æœ€æ–°è®ºæ–‡ã€ŠåŸºå‡†ä»£ç†å·¥ä½œæµç”Ÿæˆã€‹ï¼ğŸš€\n\nğŸ§  å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åˆ†è§£ä¸­èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨",
    "post_content_en": "Ningyu Zhang@ZJU (@zxlzr) posted at 9:12 AM on Sun, Oct 20, 2024:\nIntroducing our latest paper, \"Benchmarking Agentic Workflow Generation\"! ğŸš€\n\nğŸ§  Large Language Models (LLMs) play a crucial role in breaking down",
    "link_lists": [
      "https://t.co/WtzU8Ep87A",
      "https://t.co/71cauFyyYJ",
      "https://t.co/qlWNnNPA9D",
      "https://t.co/fNGNGYjJUu",
      "https://t.co/nYLGmb3NOh",
      "https://x.com/zxlzr/status/1848034469506330759?t=0cEg2uWx_N3z_rnnZcNGbw&s=03"
    ],
    "post_summary_cn": "Ningyu Zhang@ZJU (@zxlzr) å‘å¸ƒäº†æœ€æ–°è®ºæ–‡ã€ŠåŸºå‡†ä»£ç†å·¥ä½œæµç”Ÿæˆã€‹ï¼Œå¹¶å¼ºè°ƒäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å…¶ä¸­çš„é‡è¦ä½œç”¨ã€‚",
    "post_summary_en": "Ningyu Zhang@ZJU (@zxlzr) introduced their latest paper, \"Benchmarking Agentic Workflow Generation,\" and highlighted the crucial role of Large Language Models (LLMs).",
    "post_datetime": "2024-10-21T20:58:09-07:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "192a239e70ff38c7": {
    "email_id": "192a239e70ff38c7",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "elvis (@omarsar0) äº2024å¹´10æœˆ17æ—¥æ˜ŸæœŸå››ä¸Šåˆ8:05å‘å¸ƒï¼š\nAgent S æ˜¯ä¸€ä¸ªæ–°çš„å¼€æ”¾å¼ä»£ç†æ¡†æ¶ï¼Œé€šè¿‡å›¾å½¢ç”¨æˆ·ç•Œé¢å®ç°ä¸è®¡ç®—æœºçš„è‡ªä¸»äº¤äº’ã€‚\n\nAgent S è§£å†³äº†è¯¸å¦‚è·å–çŸ¥è¯†ã€é•¿æœŸä»»åŠ¡è§„åˆ’å’Œå¤„ç†åŠ¨æ€ç•Œé¢ç­‰æŒ‘æˆ˜ã€‚\n\nå®ƒå¼•å…¥äº†ç»éªŒå¢å¼ºçš„åˆ†å±‚",
    "post_content_en": "elvis (@omarsar0) posted at 8:05 AM on Thu, Oct 17, 2024:\nAgent S is a new open agentic framework that enables autonomous interaction\nwith computers through a GUI.\n\nAgent S tackles challenges such as acquiring knowledge, planning over\nlong-task horizons, and handling dynamic interfaces.\n\nIt introduces experience-augmented hierarchical",
    "link_lists": [
      "https://t.co/EMisz54euk",
      "https://x.com/omarsar0/status/1846930425849303424?t=VjOHRe_EG_x4A6p0Ht7TLw&s=03"
    ],
    "post_summary_cn": "elvis (@omarsar0) ä»‹ç»äº†æ–°çš„å¼€æ”¾å¼ä»£ç†æ¡†æ¶ Agent Sï¼Œå®ƒé€šè¿‡å›¾å½¢ç”¨æˆ·ç•Œé¢å®ç°ä¸è®¡ç®—æœºçš„è‡ªä¸»äº¤äº’ï¼Œè§£å†³äº†è·å–çŸ¥è¯†ã€é•¿æœŸä»»åŠ¡è§„åˆ’å’Œå¤„ç†åŠ¨æ€ç•Œé¢ç­‰æŒ‘æˆ˜ã€‚",
    "post_summary_en": "elvis (@omarsar0) introduced Agent S, a new open agentic framework that enables autonomous interaction with computers through a GUI, addressing challenges such as acquiring knowledge, long-term task planning, and handling dynamic interfaces.",
    "post_datetime": "2024-10-18T17:42:36-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "192932fe9e25be66": {
    "email_id": "192932fe9e25be66",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "Jeffery Kaneda é‡‘ç”°é”ä¹Ÿ (@JefferyTatsuya) posted at 11:18 PM on Mon, Oct 14, 2024: æˆ‘è®¤ä¸ºswarmè¿˜æ²¡æœ‰ä¸€ä¸ªUIç•Œé¢ï¼Œä¸€æ—¦åšå¥½äº†è¿™æ ·çš„äº¤äº’ï¼Œæ™®é€šç”¨æˆ·å…¶å®é è‡ªç„¶è¯­è¨€å°±èƒ½åšæˆä¸€ç¾¤Agentã€‚ è€Œä¸”ä¸éœ€è¦æ‹–æ‹–æ”¾æ”¾ã€‚ä¼šæ›´åŠ çš„ç®€å•ã€‚ ä¸€å¥è¯ï¼šLLM-based Agent will eat Rule-based Agent.",
    "post_content_en": "Jeffery Kaneda é‡‘ç”°é”ä¹Ÿ (@JefferyTatsuya) posted at 11:18 PM on Mon, Oct 14, 2024: I think swarm does not have a UI interface yet. Once such interaction is established, ordinary users can actually create a group of Agents using natural language. Moreover, there is no need for drag-and-drop. It will be much simpler. In one sentence: LLM-based Agent will eat Rule-based Agent.",
    "link_lists": [
      "https://x.com/JefferyTatsuya/status/1846073241619910656?t=jUcp_bYxBrzTeakGvFNCVQ&s=03"
    ],
    "post_summary_cn": "Jeffery Kanedaè®¤ä¸ºswarmç›®å‰ç¼ºä¹UIç•Œé¢ï¼Œä¸€æ—¦å®ç°è‡ªç„¶è¯­è¨€äº¤äº’ï¼Œæ™®é€šç”¨æˆ·å°†èƒ½è½»æ¾åˆ›å»ºAgentç¾¤ç»„ï¼Œæ— éœ€æ‹–æ”¾æ“ä½œï¼Œæ›´åŠ ç®€ä¾¿ã€‚ä»–æ€»ç»“é“ï¼šåŸºäºLLMçš„Agentå°†å–ä»£åŸºäºè§„åˆ™çš„Agentã€‚",
    "post_summary_en": "Jeffery Kaneda believes that swarm currently lacks a UI interface. Once natural language interaction is established, ordinary users will be able to easily create groups of Agents without drag-and-drop, making it much simpler. He concludes: LLM-based Agents will replace rule-based Agents.",
    "post_datetime": "2024-10-15T19:37:25-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1929325d0bd814d6": {
    "email_id": "1929325d0bd814d6",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 3:27 AM on Tue, Oct 15, 2024:\n# OpenAI o1 å¯èƒ½æ”¹å˜ AI Agent æ¶æ„æ–¹å¼\n\næ„Ÿè°¢ @JefferyTatsuya åˆ†äº«çš„è¿™ç¯‡æ–‡ç« , æ¢è®¨äº†ä¸€ç§æ–°çš„ AI Agent æ¶æ„, å®ƒåˆ©ç”¨äº† OpenAI o1 æ¨¡å‹çš„å¼ºå¤§èƒ½åŠ›,\nä¸ºä¼ä¸šå†³ç­–å’Œå¤æ‚é—®é¢˜è§£å†³æä¾›æ–°çš„æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•ç»“åˆäº†è‡ªåŠ¨åŒ–çš„æ•ˆç‡å’Œäººç±»æ™ºæ…§çš„çµæ´»æ€§, å¯èƒ½å¯¹æœªæ¥çš„ AI åº”ç”¨äº§ç”Ÿé‡å¤§å½±å“ã€‚\n\n# OpenAI o1 æ¨¡å‹çš„",
    "post_content_en": "meng shao (@shao__meng) posted at 3:27 AM on Tue, Oct 15, 2024:\n# OpenAI o1 may change the way AI Agent architectures are designed\n\nThanks to @JefferyTatsuya for sharing this article, which explores a new AI Agent architecture that leverages the powerful capabilities of the OpenAI o1 model,\nproviding new methods for enterprise decision-making and complex problem-solving. This approach combines the efficiency of automation with the flexibility of human intelligence, potentially having a significant impact on future AI applications.\n\n# OpenAI o1 model",
    "link_lists": [
      "https://t.co/vbwX59bXjB",
      "https://x.com/shao__meng/status/1846135706923814975?t=vtv3RTzdS4tf_mi82BXytQ&s=03"
    ],
    "post_summary_cn": "meng shao åˆ†äº«äº†ä¸€ç¯‡å…³äº OpenAI o1 æ¨¡å‹å¯èƒ½æ”¹å˜ AI Agent æ¶æ„çš„æ–‡ç« ï¼Œæ¢è®¨äº†å…¶å¯¹ä¼ä¸šå†³ç­–å’Œå¤æ‚é—®é¢˜è§£å†³çš„æ–°æ–¹æ³•ã€‚",
    "post_summary_en": "meng shao shared an article about how the OpenAI o1 model may change AI Agent architectures, exploring new methods for enterprise decision-making and complex problem-solving.",
    "post_datetime": "2024-10-15T19:26:23-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1928e0d75a3a86bd": {
    "email_id": "1928e0d75a3a86bd",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 5:53 PM on Mon, Oct 14, 2024:\nAutoGen å®ç° Handoff Multi-Agents @pyautogen\n\nHandoff æ¨¡å¼çš„æ ¸å¿ƒæ€æƒ³æ˜¯å…è®¸ Agents å°†ä»»åŠ¡å§”æ‰˜ç»™å…¶ä»– Agents, ä½¿ç”¨ç‰¹æ®Šçš„å·¥å…·è°ƒç”¨æ¥å®ç°, ä½¿ç”¨ AutoGen Core\nAPI æ¥å®ç° Handoff æ¨¡å¼, å‘æŒ¥ AutoGen å¯æ‰©å±•æ€§ã€çµæ´»æ€§å’Œæ˜“äºé›†æˆçš„ä¼˜åŠ¿ã€‚\n\n# å®ç°æ€æƒ³:\n- Multi-Agents åä½œ:",
    "post_content_en": "meng shao (@shao__meng) posted at 5:53 PM on Mon, Oct 14, 2024:\nAutoGen implements Handoff Multi-Agents @pyautogen\n\nThe core idea of the Handoff mode is to allow Agents to delegate tasks to other Agents, using special tool calls to achieve this, and leveraging the AutoGen Core\nAPI to implement the Handoff mode, taking advantage of AutoGen's scalability, flexibility, and ease of integration.\n\n# Implementation ideas:\n- Multi-Agents collaboration:",
    "link_lists": [
      "https://t.co/StuAo9LoSP",
      "https://x.com/shao__meng/status/1845991257161847071?t=_rWqa2qoE2mTzlbc0eZhCw&s=03"
    ],
    "post_summary_cn": "meng shao ä»‹ç»äº† AutoGen çš„ Handoff æ¨¡å¼ï¼Œè¯¥æ¨¡å¼å…è®¸ Agents å°†ä»»åŠ¡å§”æ‰˜ç»™å…¶ä»– Agentsï¼Œåˆ©ç”¨ AutoGen Core API å®ç°ï¼Œå……åˆ†å‘æŒ¥ AutoGen çš„å¯æ‰©å±•æ€§ã€çµæ´»æ€§å’Œæ˜“äºé›†æˆçš„ä¼˜åŠ¿ã€‚",
    "post_summary_en": "meng shao introduced the Handoff mode of AutoGen, which allows Agents to delegate tasks to other Agents, leveraging the AutoGen Core API to fully utilize AutoGen's scalability, flexibility, and ease of integration.",
    "post_datetime": "2024-10-14T19:41:40-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192223a50551b17f": {
    "email_id": "192223a50551b17f",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 1:18 AM on Mon, Sep 23, 2024:\nGenAI Agents @NirDiamantAI\n\nGenAI Agents å¼€å‘çš„ç»¼åˆæ€§èµ„æºï¼Œæ¶µç›–äº†ä»åŸºç¡€åˆ°é«˜çº§çš„å„ç§ç†è®ºç»“åˆå®ç°çš„å¼€æºé¡¹ç›®ã€‚\n\nä¸»è¦ç‰¹ç‚¹ï¼š\n- æä¾›å„ç§éš¾åº¦çº§åˆ«çš„ GenAI Agents æ„å»ºæ•™ç¨‹\n- æ¢ç´¢å¤šç§ Agents æ¶æ„å’Œåº”ç”¨\n- åŒ…å«å®ç”¨çš„ã€éšæ—¶å¯ç”¨çš„ Agents å®ç°\n- å®šæœŸæ›´æ–°æœ€æ–°çš„ GenAI è¿›å±•",
    "post_content_en": "meng shao (@shao__meng) posted at 1:18 AM on Mon, Sep 23, 2024:\nGenAI Agents @NirDiamantAI\n\nComprehensive resources for GenAI Agents development, covering open-source projects that combine theory and implementation from basic to advanced levels.\n\nMain features:\n- Tutorials for building GenAI Agents at various difficulty levels\n- Exploration of multiple Agent architectures and applications\n- Includes practical, ready-to-use Agent implementations\n- Regular updates on the latest GenAI advancements",
    "link_lists": [
      "https://t.co/3f1z0Ak1ST",
      "https://x.com/shao__meng/status/1838130687322566699?t=wtqigjMDrdZvBz4GY64nbw&s=03"
    ],
    "post_summary_cn": "meng shao åˆ†äº«äº†å…³äº GenAI Agents çš„ç»¼åˆæ€§èµ„æºï¼ŒåŒ…æ‹¬æ„å»ºæ•™ç¨‹ã€æ¶æ„æ¢ç´¢ã€å®ç”¨å®ç°å’Œæœ€æ–°è¿›å±•ã€‚",
    "post_summary_en": "meng shao shared comprehensive resources on GenAI Agents, including tutorials, architecture exploration, practical implementations, and the latest advancements.",
    "post_datetime": "2024-09-23T21:11:41-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "191636db3be1214e": {
    "email_id": "191636db3be1214e",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "AIGCLINK (@aigclink) posted at 6:45 PM on Sat, Aug 17, 2024:\nä¸€æ¬¾è½»é‡çº§ã€ç»“åˆLLMè¿›è¡Œç½‘é¡µæ•°æ®æŠ“å–çš„å·¥å…·ï¼šparsera\n\næ”¯æŒå¤šç§ LLM\næ”¯æŒæå–å¤šç§ç±»å‹æ–‡æœ¬æ•°æ®\nä½¿ç”¨LLMè¯†åˆ«æ‰€éœ€æå–çš„ä¿¡æ¯\n\n#æ•°æ®æå– #parsera",
    "post_content_en": "AIGCLINK (@aigclink) posted at 6:45 PM on Sat, Aug 17, 2024:\nA lightweight tool for web data scraping combined with LLM: parsera\n\nSupports multiple LLMs\nSupports extracting various types of text data\nUses LLM to identify the information to be extracted\n\n#DataExtraction #parsera",
    "link_lists": [
      "https://t.co/7RWmke3Of2",
      "https://t.co/qFWst9lFjx",
      "https://x.com/aigclink/status/1824985974323229166?t=aSV0TwYqP7TaBJh59Vqlqw&s=03"
    ],
    "post_summary_cn": "AIGCLINKå‘å¸ƒäº†ä¸€æ¬¾åä¸ºparseraçš„è½»é‡çº§å·¥å…·ï¼Œç»“åˆLLMè¿›è¡Œç½‘é¡µæ•°æ®æŠ“å–ï¼Œæ”¯æŒå¤šç§LLMå’Œæ–‡æœ¬æ•°æ®æå–ï¼Œä½¿ç”¨LLMè¯†åˆ«æ‰€éœ€ä¿¡æ¯ã€‚",
    "post_summary_en": "AIGCLINK introduced a lightweight tool called parsera for web data scraping combined with LLM, supporting multiple LLMs and text data extraction, using LLM to identify the required information.",
    "post_datetime": "2024-08-17T20:00:19-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "19163247db47eef3": {
    "email_id": "19163247db47eef3",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 5:17 PM on Fri, Aug 16, 2024:\nå¤šæ¨¡æ€æŠ¥å‘Šç”Ÿæˆ AI Agent @llama_index\n\nLlamaIndex å…³äºå¤šæ¨¡æ€æ¨¡å‹çš„ Cookbookï¼Œå±•ç¤ºäº†å¦‚ä½•ä»ä¸€ç»„ç ”ç©¶æŠ¥å‘Šåº“ä¸­æ„å»ºä¸€ä¸ªå¤šæ¨¡æ€æŠ¥å‘Šç”Ÿæˆ AI Agentï¼Œä½œè€…æ˜¯\nLlamaIndex åˆ›å§‹äºº Jerry Liu @jerryjliu0\n\nä½œè€…ä½¿ç”¨äº†ä¸€ç»„ ICLR è®ºæ–‡ï¼Œå€ŸåŠ© Llama-Parse å·¥ä½œæµæŠ½è±¡æ¥å®šä¹‰ä¸€ä¸ª Agent",
    "post_content_en": "meng shao (@shao__meng) posted at 5:17 PM on Fri, Aug 16, 2024:\nMultimodal Report Generation AI Agent @llama_index\n\nLlamaIndex's Cookbook on multimodal models demonstrates how to build a multimodal report generation AI Agent from a set of research report libraries, authored by\nLlamaIndex founder Jerry Liu @jerryjliu0\n\nThe author used a set of ICLR papers, leveraging the Llama-Parse workflow abstraction to define an Agent",
    "link_lists": [
      "https://t.co/CdQfHezrDU",
      "https://x.com/shao__meng/status/1824601351621578896?t=NNh-IiU5nr4RvUp07tafQA&s=03"
    ],
    "post_summary_cn": "meng shao åˆ†äº«äº† LlamaIndex å…³äºå¤šæ¨¡æ€æ¨¡å‹çš„ Cookbookï¼Œå±•ç¤ºäº†å¦‚ä½•æ„å»ºå¤šæ¨¡æ€æŠ¥å‘Šç”Ÿæˆ AI Agentï¼Œä½œè€…æ˜¯ LlamaIndex åˆ›å§‹äºº Jerry Liuã€‚",
    "post_summary_en": "meng shao shared LlamaIndex's Cookbook on multimodal models, demonstrating how to build a multimodal report generation AI Agent, authored by LlamaIndex founder Jerry Liu.",
    "post_datetime": "2024-08-17T18:40:21-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "19114965b27eb33b": {
    "email_id": "19114965b27eb33b",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "å°äº’ (@imxiaohu) posted at 6:51 AM on Fri, Aug 02, 2024:\nMindSearchï¼šèƒ½å¤Ÿæ¨¡ä»¿äººç±»åœ¨ç½‘ç»œä¸Šå¯»æ‰¾å’Œæ•´åˆä¿¡æ¯çš„AIæœç´¢å¼•æ“\n\nMindSearchèƒ½å¤Ÿåœ¨3åˆ†é’Ÿå†…ä»è¶…è¿‡300ä¸ªç½‘é¡µä¸­æ”¶é›†å’Œæ•´åˆä¿¡æ¯ï¼Œè¿™ç›¸å½“äºäººç±»ä¸“å®¶å¤§çº¦3å°æ—¶çš„å·¥ä½œé‡ã€‚\n\nåœ¨æ·±åº¦ã€å¹¿åº¦å’Œç”Ÿæˆå“åº”çš„å‡†ç¡®æ€§ä¸‰ä¸ªæ–¹é¢ï¼Œå…¶åœ¨äººç±»ä¸“å®¶è¯„ä¼°ä¸­éƒ½è¶…è¶Šäº†ï¼› Perplexity AIå’Œ ChatGPTã€‚",
    "post_content_en": "Xiao Hu (@imxiaohu) posted at 6:51 AM on Fri, Aug 02, 2024:\nMindSearch: An AI search engine capable of mimicking humans in searching and integrating information on the web.\n\nMindSearch can collect and integrate information from over 300 web pages in 3 minutes, which is equivalent to about 3 hours of work for a human expert.\n\nIn terms of depth, breadth, and accuracy of generated responses, it has surpassed Perplexity AI and ChatGPT in human expert evaluations.",
    "link_lists": [
      "https://t.co/xIPzlIgCb0",
      "https://x.com/imxiaohu/status/1819370552848761191?t=2MXWmCp_sbP2DJrJjZP5uA&s=03"
    ],
    "post_summary_cn": "å°äº’ä»‹ç»äº†MindSearchï¼Œä¸€ä¸ªèƒ½å¤Ÿæ¨¡ä»¿äººç±»åœ¨ç½‘ç»œä¸Šå¯»æ‰¾å’Œæ•´åˆä¿¡æ¯çš„AIæœç´¢å¼•æ“ã€‚MindSearchåœ¨3åˆ†é’Ÿå†…å¯ä»¥ä»è¶…è¿‡300ä¸ªç½‘é¡µä¸­æ”¶é›†å’Œæ•´åˆä¿¡æ¯ï¼Œç›¸å½“äºäººç±»ä¸“å®¶3å°æ—¶çš„å·¥ä½œé‡ã€‚åœ¨æ·±åº¦ã€å¹¿åº¦å’Œç”Ÿæˆå“åº”çš„å‡†ç¡®æ€§æ–¹é¢ï¼ŒMindSearchåœ¨äººç±»ä¸“å®¶è¯„ä¼°ä¸­è¶…è¶Šäº†Perplexity AIå’ŒChatGPTã€‚",
    "post_summary_en": "Xiao Hu introduced MindSearch, an AI search engine that mimics humans in searching and integrating information on the web. MindSearch can collect and integrate information from over 300 web pages in 3 minutes, equivalent to 3 hours of work for a human expert. In terms of depth, breadth, and accuracy of generated responses, MindSearch has surpassed Perplexity AI and ChatGPT in human expert evaluations.",
    "post_datetime": "2024-02-08T12:34:44-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "190e1066baa11125": {
    "email_id": "190e1066baa11125",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "AIGCLINK (@aigclink) posted at 3:48 AM on Tue, Jul 23, 2024:\nä¸€ä¸ªçµæ´»æ˜“ç”¨çš„ LLM è·¯ç”±æ¡†æ¶ï¼šRouteLLM\nRouteLLMè§£å†³äº†å¤§æ¨¡å‹æ€§èƒ½å¼ºä»·æ ¼è´µï¼Œä»·æ ¼ä¾¿å®œä½†æ€§èƒ½å¼±çš„é—®é¢˜ï¼Œå…¶èƒ½å¤Ÿåœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€é€‰æ‹©æ›´å¼ºæˆ–æ›´å¼±çš„LLMï¼Œåšåˆ°é™ä½æˆæœ¬çš„åŒæ—¶ä¸å½±å“è´¨é‡\n\nåœ¨MT BenchåŸºå‡†ä¸Šæˆæœ¬é™ä½ 85%ï¼ŒåŒæ—¶å¯ä»¥è¾¾åˆ° 95% çš„ GPT-4 æ€§èƒ½\n\nåŠŸèƒ½:\n1ã€æ›¿ä»£OpenAI",
    "post_content_en": "AIGCLINK (@aigclink) posted at 3:48 AM on Tue, Jul 23, 2024:\nA flexible and easy-to-use LLM routing framework: RouteLLM\nRouteLLM addresses the issue of high-performance but expensive large models versus cheap but weak models. It dynamically selects stronger or weaker LLMs during inference, reducing costs without compromising quality.\n\nOn the MT Bench benchmark, costs are reduced by 85%, while achieving 95% of GPT-4's performance.\n\nFeatures:\n1. Replacement for OpenAI",
    "link_lists": [
      "https://t.co/KwcP0e2RJ5",
      "https://x.com/aigclink/status/1815700556914331662?t=bIygVtB2QBx9mk9eVC14VA&s=03"
    ],
    "post_summary_cn": "RouteLLMæ˜¯ä¸€ä¸ªçµæ´»æ˜“ç”¨çš„LLMè·¯ç”±æ¡†æ¶ï¼Œè§£å†³äº†å¤§æ¨¡å‹æ€§èƒ½å¼ºä»·æ ¼è´µçš„é—®é¢˜ï¼Œèƒ½åœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€é€‰æ‹©LLMï¼Œé™ä½æˆæœ¬åŒæ—¶ä¸å½±å“è´¨é‡ã€‚åœ¨MT BenchåŸºå‡†ä¸Šæˆæœ¬é™ä½85%ï¼Œè¾¾åˆ°95%çš„GPT-4æ€§èƒ½ã€‚",
    "post_summary_en": "RouteLLM is a flexible and easy-to-use LLM routing framework that addresses the issue of high-performance but expensive large models. It dynamically selects LLMs during inference, reducing costs without compromising quality. On the MT Bench benchmark, costs are reduced by 85%, achieving 95% of GPT-4's performance.",
    "post_datetime": "2024-07-23T12:16:52-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1905f18e265590c2": {
    "email_id": "1905f18e265590c2",
    "post_labels": [
      "LLM/agent",
      "LLM"
    ],
    "post_content_cn": "Tom Huang (@tuturetom) äº 2024å¹´6æœˆ27æ—¥ 6:31 AM å‘å¸ƒï¼š\nTuGraphã€OpenSPGã€DB-GPTï¼Œæ„Ÿè§‰é›†é½äº†æ„å»º AI Native Agentic Data App çš„æ ¸å¿ƒè¦ç´ ï¼ğŸ”¥\n\n- DB-GPTï¼šå›¾å½¢åŒ–ç•Œé¢ç®¡ç†èµ„æºã€Embeddingã€å›¾å­˜å‚¨ã€AWELï¼ˆAgentic Workflow è¡¨è¾¾è¯­è¨€ï¼‰ã€æ„å»º\nAgentã€å…¼å®¹å¼€æºæ¨¡å‹ã€æ”¶é›†æ•°æ®é›†å’Œè‡ªåŠ¨å¾®è°ƒ",
    "post_content_en": "Tom Huang (@tuturetom) posted at 6:31 AM on Thu, Jun 27, 2024:\nTuGraph, OpenSPG, DB-GPT, it feels like we have gathered the core elements to build an AI Native Agentic Data App! ğŸ”¥\n\n- DB-GPT: Graphical interface for resource management, Embedding, graph storage, AWEL (Agentic Workflow Expression Language), building\nAgent, compatible with open-source models, collecting datasets, and automatic fine-tuning",
    "link_lists": [
      "https://t.co/77DjjH15kx",
      "https://t.co/yuWr76LkJ4",
      "https://x.com/tuturetom/status/1806319351609606470?t=OR-HKm6gOY9eOsq-QZfSQQ&s=03"
    ],
    "post_summary_cn": "Tom Huang è®¤ä¸º TuGraphã€OpenSPG å’Œ DB-GPT æ˜¯æ„å»º AI Native Agentic Data App çš„æ ¸å¿ƒè¦ç´ ï¼Œå¹¶è¯¦ç»†ä»‹ç»äº† DB-GPT çš„åŠŸèƒ½ã€‚",
    "post_summary_en": "Tom Huang believes that TuGraph, OpenSPG, and DB-GPT are the core elements for building an AI Native Agentic Data App and detailed the features of DB-GPT.",
    "post_datetime": "2024-06-28T06:46:27-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1904d72deee53016": {
    "email_id": "1904d72deee53016",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "AIGCLINK (@aigclink) äº2024å¹´6æœˆ24æ—¥æ˜ŸæœŸä¸€å‡Œæ™¨2:14å‘å¸ƒï¼š\nç¡…åŸºæ™ºèƒ½å°†å…¶DUIXï¼ˆDialogue User Interface Systemï¼‰å¼€æºäº†\nDUIXæ˜¯2D çœŸäººçº§ã€AIGC å®æ—¶æ¸²æŸ“æ•°å­—äººæ¨¡å‹ï¼\n\nå¼€å‘è€…å¯è‡ªè¡Œæ¥å…¥å¤šæ–¹å¤§æ¨¡å‹ã€è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ã€è¯­éŸ³åˆæˆï¼ˆTTSï¼‰èƒ½åŠ›å®ç°æ•°å­—äººå®æ—¶äº¤äº’\n\nå¯åœ¨Androidå’ŒiOSå¤šç»ˆç«¯ä¸€é”®éƒ¨ç½²ï¼ŒDUIXè¿˜æä¾›äº† 14 ä¸ªæ•°å­—äººæ¨¡æ¿",
    "post_content_en": "AIGCLINK (@aigclink) posted at 2:14 AM on Mon, Jun 24, 2024:\nSilicon Intelligence has open-sourced its DUIX (Dialogue User Interface System)\nDUIX is a 2D human-level, AIGC real-time rendering digital human model!\n\nDevelopers can integrate multiple large models, speech recognition (ASR), and speech synthesis (TTS) capabilities to achieve real-time interaction with digital humans\n\nIt can be deployed with one click on multiple terminals including Android and iOS, and DUIX also provides 14 digital human templates",
    "link_lists": [
      "https://t.co/oD6KffFCNR",
      "https://x.com/aigclink/status/1805167554174021830?t=j9DhkQ3qiDz2PSt_KXW1Pg&s=03"
    ],
    "post_summary_cn": "ç¡…åŸºæ™ºèƒ½å¼€æºäº†å…¶DUIXç³»ç»Ÿï¼Œè¿™æ˜¯ä¸€ä¸ª2DçœŸäººçº§ã€AIGCå®æ—¶æ¸²æŸ“çš„æ•°å­—äººæ¨¡å‹ã€‚å¼€å‘è€…å¯ä»¥æ¥å…¥å¤§æ¨¡å‹ã€è¯­éŸ³è¯†åˆ«å’Œè¯­éŸ³åˆæˆæŠ€æœ¯ï¼Œå®ç°æ•°å­—äººå®æ—¶äº¤äº’ï¼Œå¹¶æ”¯æŒåœ¨Androidå’ŒiOSå¤šç»ˆç«¯ä¸€é”®éƒ¨ç½²ï¼Œæä¾›14ä¸ªæ•°å­—äººæ¨¡æ¿ã€‚",
    "post_summary_en": "Silicon Intelligence has open-sourced its DUIX system, a 2D human-level, AIGC real-time rendering digital human model. Developers can integrate large models, speech recognition, and speech synthesis for real-time interaction, with one-click deployment on Android and iOS, offering 14 digital human templates.",
    "post_datetime": "2024-06-24T20:31:32-07:00",
    "source_language": "cn",
    "confidence_score": 1.0
  },
  "1901e1d3340e613a": {
    "email_id": "1901e1d3340e613a",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "ginobefun (@hongming731) posted at 2:26 AM on Fri, Jun 14, 2024: æœ‰ç‚¹çˆ±ä¸Š dify äº†ï¼Œä»Šå¤©è‡ªå·±éƒ¨ç½²äº†ä¸€å¥—æœåŠ¡ï¼Œå°è¯•å†™äº†å‡ ä¸ªæµç¨‹ï¼Œè¾¹å¼€å‘è¾¹è°ƒè¯•ï¼Œç›¸æ¯”åŸå…ˆé€šè¿‡ä»£ç ç¼–æ’å’Œè°ƒè¯•æ•ˆç‡é«˜å¤ªå¤šäº†ï¼Œæ•´ä¸ªé¡µé¢éå¸¸ä¸æ»‘ï¼Œåé¢ä¼šé€æ­¥å°†ä¸Šçš„ä¸€äº›è‡ªåŠ¨åŒ–æµç¨‹åˆ‡æ¢åˆ° dify ä¸Šæ¥ã€‚",
    "post_content_en": "ginobefun (@hongming731) posted at 2:26 AM on Fri, Jun 14, 2024: I'm starting to fall in love with dify. Today, I deployed a set of services myself, tried writing a few workflows, and developed while debugging. Compared to the previous method of code orchestration and debugging, the efficiency is much higher. The entire page is very smooth. Later, I will gradually switch some automated workflows to dify.",
    "link_lists": [
      "https://t.co/gLQOSl6U7V",
      "https://t.co/Ww3bDvm4lC",
      "https://x.com/hongming731/status/1801546636126208043?t=yvRcRVnltN9qqOvmaXPXkg&s=03"
    ],
    "post_summary_cn": "ginobefun (@hongming731) è¡¨ç¤ºå¯¹ dify äº§ç”Ÿäº†å…´è¶£ï¼Œä»Šå¤©è‡ªå·±éƒ¨ç½²äº†æœåŠ¡å¹¶å°è¯•ç¼–å†™äº†å‡ ä¸ªæµç¨‹ï¼Œå¼€å‘è°ƒè¯•æ•ˆç‡æ˜¾è‘—æé«˜ï¼Œé¡µé¢éå¸¸æµç•…ï¼Œè®¡åˆ’å°†ä¸€äº›è‡ªåŠ¨åŒ–æµç¨‹åˆ‡æ¢åˆ° difyã€‚",
    "post_summary_en": "ginobefun (@hongming731) expressed interest in dify, deployed services today, and tried writing a few workflows. The development and debugging efficiency improved significantly, and the page is very smooth. Plans to switch some automated workflows to dify.",
    "post_datetime": "2024-06-15T15:55:48-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1901e1be6d4b2dfb": {
    "email_id": "1901e1be6d4b2dfb",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "Leo Xiang (@leeoxiang) posted at 2:14 AM on Sat, Jun 15, 2024:\nåˆå…³æ³¨åˆ°ä¸€æ‰¹ voice agent æ–¹å‘çš„äº§å“ï¼Œè¿™ä¸ªæ–¹å‘åˆ›ä¸šçš„äº§å“è¶Šæ¥è¶Šå¤šï¼š\n\n1ã€\n2ã€\n3ã€\n\néœ€è¦æ€è€ƒçš„ä¸€ä¸ªé—®é¢˜æ˜¯ï¼šå°†æ¥ä½ å¦‚ä½•åˆ†è¾¨ç”µè¯é‚£å¤´æ˜¯çœŸäººè¿˜æ˜¯ AIï¼Ÿ\n(\n)",
    "post_content_en": "Leo Xiang (@leeoxiang) posted at 2:14 AM on Sat, Jun 15, 2024:\nI have noticed a batch of products in the voice agent direction, and more and more products are being developed in this area:\n\n1ã€\n2ã€\n3ã€\n\nA question to consider is: How will you distinguish whether the person on the other end of the phone is a real person or AI in the future?\n(\n)",
    "link_lists": [
      "https://t.co/puwW1f1grAN",
      "https://t.co/6ZF2AGHWBp",
      "https://t.co/3pGCO7mZfP",
      "https://x.com/leeoxiang/status/1801905998736883917?t=eMp57fTPTRyRO49M_nAlFQ&s=03"
    ],
    "post_summary_cn": "Leo Xiang å…³æ³¨åˆ°è¶Šæ¥è¶Šå¤šçš„ voice agent æ–¹å‘äº§å“ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªå€¼å¾—æ€è€ƒçš„é—®é¢˜ï¼šæœªæ¥å¦‚ä½•åˆ†è¾¨ç”µè¯é‚£å¤´æ˜¯çœŸäººè¿˜æ˜¯ AIã€‚",
    "post_summary_en": "Leo Xiang has noticed an increasing number of products in the voice agent direction and raises a thought-provoking question: How to distinguish whether the person on the other end of the phone is a real person or AI in the future.",
    "post_datetime": "2024-06-15T15:54:24-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "18febea25084aa94": {
    "email_id": "18febea25084aa94",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "é˜…è¯»Dr. Varshita Sheråœ¨Mediumä¸Šçš„æ•…äº‹ï¼š",
    "post_content_en": "Read this story from Dr. Varshita Sher on Medium:",
    "link_lists": [
      "https://towardsdatascience.com/using-langchain-react-agents-for-answering-multi-hop-questions-in-rag-systems-893208c1847e"
    ],
    "post_summary_cn": "Dr. Varshita Sheråœ¨Mediumä¸Šåˆ†äº«äº†ä¸€ç¯‡å…³äºä½¿ç”¨LangChain Reactä»£ç†åœ¨RAGç³»ç»Ÿä¸­å›ç­”å¤šè·³é—®é¢˜çš„æ•…äº‹ã€‚",
    "post_summary_en": "Dr. Varshita Sher shares a story on Medium about using LangChain React agents to answer multi-hop questions in RAG systems.",
    "post_datetime": "2024-05-06T21:59:01-07:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "18febcac2a05cf16": {
    "email_id": "18febcac2a05cf16",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "AIGCLINK (@aigclink) äº2024å¹´6æœˆ5æ—¥æ˜ŸæœŸä¸‰æ™šä¸Š8:50å‘å¸ƒï¼š\nCohereçš„ä½¿ç”¨æŒ‡å—\nå¯ä»¥å…¨é¢äº†è§£å¦‚ä½•åœ¨ Cohere ç”Ÿæˆå¼ AI å¹³å°ä¸Šæ„å»ºåº”ç”¨ï¼Œæ¯”å¦‚Agentã€å¼€æºè½¯ä»¶é›†æˆã€æœç´¢/åµŒå…¥ã€äº‘æœåŠ¡ã€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ã€æ‘˜è¦ä»¥åŠç”¨ä¾‹ç­‰",
    "post_content_en": "AIGCLINK (@aigclink) posted at 8:50 PM on Wed, Jun 05, 2024:\nCohere User Guide\nYou can fully understand how to build applications on the Cohere generative AI platform, such as Agent, open source software integration, search/embedding, cloud services, retrieval-augmented generation (RAG), summarization, and use cases.",
    "link_lists": [
      "https://t.co/K3bRZBQXKj",
      "https://t.co/4reZhjQlZ0",
      "https://x.com/aigclink/status/1798563171000824173?t=7a1Aetqo-DGhQy4obJdRnQ&s=03"
    ],
    "post_summary_cn": "AIGCLINKå‘å¸ƒäº†Cohereçš„ä½¿ç”¨æŒ‡å—ï¼Œè¯¦ç»†ä»‹ç»äº†å¦‚ä½•åœ¨Cohereç”Ÿæˆå¼AIå¹³å°ä¸Šæ„å»ºå„ç§åº”ç”¨ã€‚",
    "post_summary_en": "AIGCLINK posted a Cohere user guide, detailing how to build various applications on the Cohere generative AI platform.",
    "post_datetime": "2024-05-06T21:24:44-07:00",
    "source_language": "cn",
    "confidence_score": 1.0
  },
  "191177442664eb60": {
    "email_id": "191177442664eb60",
    "post_labels": [
      "NLP"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 1:12 AM on Sat, Aug 03, 2024:\nğŸ—’txtai  @neumll  8.3kâœ¨\n\ntxtai æ˜¯ä¸€ä¸ªç”¨äºè¯­ä¹‰æœç´¢ã€ LLM ç¼–æ’å’Œå·¥ä½œæµçš„å…¨èƒ½åµŒå…¥æ•°æ®åº“ (embeddings db)\n\nåµŒå…¥æ•°æ®åº“æ˜¯å‘é‡ç´¢å¼•ã€å›¾ç½‘ç»œå’Œå…³ç³»æ•°æ®åº“çš„ç»“åˆä½“ï¼Œè¿™ä½¿å¾—å¯ä»¥ä½¿ç”¨ SQL è¿›è¡Œå‘é‡æœç´¢ã€ä¸»é¢˜å»ºæ¨¡ã€RAG ç­‰ã€‚\nå®ƒå¯ä»¥ç‹¬ç«‹å­˜åœ¨ï¼Œæˆ–è€…ä½œä¸º LLM prompts çš„å¼ºå¤§çŸ¥è¯†æºã€‚\n\nğŸ—’txtai åŠŸèƒ½æ€»ç»“",
    "post_content_en": "meng shao (@shao__meng) posted at 1:12 AM on Sat, Aug 03, 2024:\nğŸ—’txtai  @neumll  8.3kâœ¨\n\ntxtai is an all-in-one embeddings database for semantic search, LLM orchestration, and workflows.\n\nAn embeddings database is a combination of vector indexing, graph networks, and relational databases, enabling vector search, topic modeling, RAG, and more using SQL.\nIt can exist independently or serve as a powerful knowledge source for LLM prompts.\n\nğŸ—’txtai feature summary",
    "link_lists": [
      "https://t.co/ljDXKwBAyI",
      "https://x.com/shao__meng/status/1819647434362151110?t=ZH-gMRb8LIdjatDmV2sIWQ&s=03"
    ],
    "post_summary_cn": "txtai æ˜¯ä¸€ä¸ªå…¨èƒ½åµŒå…¥æ•°æ®åº“ï¼Œç”¨äºè¯­ä¹‰æœç´¢ã€LLM ç¼–æ’å’Œå·¥ä½œæµã€‚å®ƒç»“åˆäº†å‘é‡ç´¢å¼•ã€å›¾ç½‘ç»œå’Œå…³ç³»æ•°æ®åº“ï¼Œæ”¯æŒä½¿ç”¨ SQL è¿›è¡Œå‘é‡æœç´¢ã€ä¸»é¢˜å»ºæ¨¡å’Œ RAG ç­‰æ“ä½œã€‚",
    "post_summary_en": "txtai is an all-in-one embeddings database for semantic search, LLM orchestration, and workflows. It combines vector indexing, graph networks, and relational databases, enabling operations like vector search, topic modeling, and RAG using SQL.",
    "post_datetime": "2024-03-08T01:56:22-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "190a51629638241f": {
    "email_id": "190a51629638241f",
    "post_labels": [
      "NLP"
    ],
    "post_content_cn": "â€œè‡ªå®šä¹‰è¯å½¢è¿˜åŸâ€\n\né˜…è¯» Daniel Kristiyanto åœ¨ Medium ä¸Šçš„æ–‡ç« â€œNLP: æˆ¿äº§ç§Ÿèµåˆ—è¡¨çš„æ–‡æœ¬æ‘˜è¦å’Œå…³é”®è¯æå– â€” ç¬¬1éƒ¨åˆ†â€",
    "post_content_en": "â€œcustom lemmatizationâ€\n\nRead â€œNLP: Text Summarization and Keyword Extraction on Property Rental Listings â€” Part 1â€œ by Daniel Kristiyanto on Medium",
    "link_lists": [
      "https://towardsdatascience.com/nlp-text-summarization-and-keyword-extraction-on-property-rental-listings-part-1-f1b760cc7bbb"
    ],
    "post_summary_cn": "Daniel Kristiyanto åœ¨ Medium ä¸Šå‘å¸ƒäº†ä¸€ç¯‡å…³äº NLP çš„æ–‡ç« ï¼Œè®¨è®ºäº†æˆ¿äº§ç§Ÿèµåˆ—è¡¨çš„æ–‡æœ¬æ‘˜è¦å’Œå…³é”®è¯æå–ã€‚",
    "post_summary_en": "Daniel Kristiyanto published an article on Medium about NLP, discussing text summarization and keyword extraction on property rental listings.",
    "post_datetime": "2024-11-07T20:56:52-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "1902723e66f4eac9": {
    "email_id": "1902723e66f4eac9",
    "post_labels": [
      "NLP"
    ],
    "post_content_cn": "",
    "post_content_en": "",
    "link_lists": [
      "https://medium.com/huggingface/state-of-the-art-neural-coreference-resolution-for-chatbots-3302365dcf30",
      "https://medium.com/aimonks/coreference-resolution-in-natural-language-processing-nlp-5ba4f570bffe"
    ],
    "post_summary_cn": "",
    "post_summary_en": "",
    "post_datetime": "2024-06-17T09:59:42-07:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "193c2d3e278fae79": {
    "email_id": "193c2d3e278fae79",
    "post_labels": [
      "LLM",
      "NotebookLM"
    ],
    "post_content_cn": "orange.ai (@oran_ge) å‘å¸ƒäº 2024å¹´12æœˆ13æ—¥ æ˜ŸæœŸäº” ä¸‹åˆ5:02ï¼š\nNotebookLM æ–°ç‰ˆè¯•ç”¨åœ°å€ï¼š\n(\n)",
    "post_content_en": "orange.ai (@oran_ge) posted at 5:02 PM on Fri, Dec 13, 2024:\nNotebookLM new version trial address:\n(\n)",
    "link_lists": [
      "https://t.co/mUE4qYfqlx",
      "https://x.com/oran_ge/status/1867736778087772657?t=yQhn2FDuPCpJ4vukJgqa_Q&s=03"
    ],
    "post_summary_cn": "orange.ai å‘å¸ƒäº† NotebookLM æ–°ç‰ˆçš„è¯•ç”¨åœ°å€ã€‚",
    "post_summary_en": "orange.ai posted the trial address for the new version of NotebookLM.",
    "post_datetime": "2024-12-13T17:41:27-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1938f161fa11850b": {
    "email_id": "1938f161fa11850b",
    "post_labels": [
      "LLM",
      "NotebookLM"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 7:18 PM on Mon, Dec 02, 2024:\nOllama å³å°†æ”¯æŒ LLM ç»“æ„åŒ–è¾“å‡º ğŸ‰\n\nåœ¨ @github åŠå…¬å®¤ä¸¾åŠçš„ @ollama meetup ä¸­ï¼Œ@thanosthinking å®£å¸ƒ Ollama å³å°†æ”¯æŒ LLM\nç»“æ„åŒ–è¾“å‡ºï¼Œé€šè¿‡ Github æäº¤è®°å½•å¯ä»¥çœ‹åˆ° ğŸ‘‡ğŸ‘‡\n\n1. æ–°åŠŸèƒ½\n\n- æ”¯æŒä¼ å…¥ JSON schema, å¹¶å°†å…¶è½¬æ¢ä¸ºè¯­æ³•è§„åˆ™æ¥è¿›è¡Œé‡‡æ ·\n- å¹³è¡¡æ˜“ç”¨æ€§å’ŒåŠŸèƒ½æ€§ - é€šè¿‡æ”¯æŒ JSON schema",
    "post_content_en": "meng shao (@shao__meng) posted at 7:18 PM on Mon, Dec 02, 2024:\nOllama will soon support structured output for LLM ğŸ‰\n\nAt the @ollama meetup held at the @github office, @thanosthinking announced that Ollama will soon support structured output for LLM, as can be seen from the Github commit records ğŸ‘‡ğŸ‘‡\n\n1. New features\n\n- Support for passing JSON schema and converting it into grammar rules for sampling\n- Balancing ease of use and functionality - by supporting JSON schema",
    "link_lists": [
      "https://t.co/8fDxyk74BW",
      "https://x.com/shao__meng/status/1863784874509017298?t=2f2Tp1_lRUWdsvon6GscZg&s=03"
    ],
    "post_summary_cn": "Ollama å³å°†æ”¯æŒ LLM ç»“æ„åŒ–è¾“å‡ºï¼Œæ”¯æŒä¼ å…¥ JSON schema å¹¶å°†å…¶è½¬æ¢ä¸ºè¯­æ³•è§„åˆ™æ¥è¿›è¡Œé‡‡æ ·ï¼Œå¹³è¡¡æ˜“ç”¨æ€§å’ŒåŠŸèƒ½æ€§ã€‚",
    "post_summary_en": "Ollama will soon support structured output for LLM, allowing JSON schema to be passed and converted into grammar rules for sampling, balancing ease of use and functionality.",
    "post_datetime": "2024-03-12T16:33:32-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192d190af5002103": {
    "email_id": "192d190af5002103",
    "post_labels": [
      "LLM/NotebookLM"
    ],
    "post_content_cn": "ç†Šå¸ƒæœ— (@Stephen4171127) posted at 9:19 AM on Sun, Oct 27, 2024:\nMeta å‘å¸ƒäº†ä¸€ä¸ªå¼€æºçš„ NotebookLM\næ­¥éª¤ 1ï¼šé¢„å¤„ç† PDFã€‚ä½¿ç”¨ Llama-3.2-1B-Instruct æ¥é¢„å¤„ç† PDF å¹¶ä¿å­˜ä¸º .txt æ–‡ä»¶ã€‚\næ­¥éª¤ 2ï¼šè„šæœ¬ç¼–å†™ã€‚ä½¿ç”¨ Llama-3.1-70B-Instruct æ¥ä»æ–‡æœ¬ä¸­ç¼–å†™æ’­å®¢è„šæœ¬ã€‚\næ­¥éª¤ 3ï¼šæˆå‰§åŒ–é‡å†™ã€‚ä½¿ç”¨ Llama-3.1-8B-Instruct æ¨¡å‹ä½¿è„šæœ¬æ›´åŠ æˆå‰§åŒ–ã€‚",
    "post_content_en": "Xiong Brown (@Stephen4171127) posted at 9:19 AM on Sun, Oct 27, 2024:\nMeta has released an open-source NotebookLM\nStep 1: Preprocess PDF. Use Llama-3.2-1B-Instruct to preprocess PDF and save it as a .txt file.\nStep 2: Script writing. Use Llama-3.1-70B-Instruct to write a podcast script from the text.\nStep 3: Dramatic rewriting. Use the Llama-3.1-8B-Instruct model to make the script more dramatic.",
    "link_lists": [
      "https://t.co/S4RgHd2Aef",
      "https://t.co/s2PShRSpMu",
      "https://x.com/Stephen4171127/status/1850572995426717916?t=SNs3S-cNFzqCF36rOQqCFg&s=03"
    ],
    "post_summary_cn": "Meta å‘å¸ƒäº†ä¸€ä¸ªå¼€æºçš„ NotebookLMï¼Œå¹¶è¯¦ç»†ä»‹ç»äº†ä½¿ç”¨ Llama ç³»åˆ—æ¨¡å‹è¿›è¡Œ PDF é¢„å¤„ç†ã€è„šæœ¬ç¼–å†™å’Œæˆå‰§åŒ–é‡å†™çš„æ­¥éª¤ã€‚",
    "post_summary_en": "Meta has released an open-source NotebookLM and detailed the steps for PDF preprocessing, script writing, and dramatic rewriting using the Llama series models.",
    "post_datetime": "2024-10-27T22:19:33-07:00",
    "source_language": "cn",
    "confidence_score": 1.0
  },
  "19231470fd03d7dc": {
    "email_id": "19231470fd03d7dc",
    "post_labels": [
      "LLM",
      "NotebookLM"
    ],
    "post_content_cn": "AIGCLINK (@aigclink) posted at 7:16 PM on Thu, Sep 26, 2024:\nèµï¼ŒNotebookLMæ–°å¢äº†éŸ³é¢‘å’ŒYouTubeæ”¯æŒåŠŸèƒ½ï¼è¿™ä¹ˆç”¨èµ·æ¥å°±æ–¹ä¾¿å¤šäº†ï½\n\n1ã€æ”¯æŒæ·»åŠ YouTubeé“¾æ¥å’ŒéŸ³é¢‘æ–‡ä»¶åˆ°ç¬”è®°æœ¬ä¸­\n2ã€æ”¹è¿›äº†Audio Overviewsçš„åˆ†äº«åŠŸèƒ½\n\nå¯ä»¥åšä¸º\nè§†é¢‘å’Œè®²åº§åˆ†æåŠ©æ‰‹ï¼šæ€»ç»“å…³é”®æ¦‚å¿µï¼Œå¹¶æä¾›å†…è”å¼•ç”¨\néŸ³é¢‘åŠ©æ‰‹ï¼šå¯ä»¥è®©NotebookLM åœ¨è½¬å½•çš„å¯¹è¯ä¸­æœç´¢æŸ¥æ‰¾ç‰¹å®šä¿¡æ¯",
    "post_content_en": "AIGCLINK (@aigclink) posted at 7:16 PM on Thu, Sep 26, 2024:\nGreat, NotebookLM has added support for audio and YouTube! This makes it much more convenient to use.\n\n1. Supports adding YouTube links and audio files to the notebook\n2. Improved the sharing function of Audio Overviews\n\nCan be used as\nVideo and lecture analysis assistant: Summarize key concepts and provide inline references\nAudio assistant: Allows NotebookLM to search for specific information in transcribed conversations",
    "link_lists": [
      "https://t.co/SyhYnl30Kx",
      "https://x.com/aigclink/status/1839489300393869696?t=aBeZDqEwt34C_VTy9wFIwA&s=03"
    ],
    "post_summary_cn": "NotebookLMæ–°å¢äº†éŸ³é¢‘å’ŒYouTubeæ”¯æŒåŠŸèƒ½ï¼Œæ–¹ä¾¿ç”¨æˆ·æ·»åŠ YouTubeé“¾æ¥å’ŒéŸ³é¢‘æ–‡ä»¶ï¼Œå¹¶æ”¹è¿›äº†Audio Overviewsçš„åˆ†äº«åŠŸèƒ½ã€‚å¯ä½œä¸ºè§†é¢‘å’Œè®²åº§åˆ†æåŠ©æ‰‹ï¼Œæ€»ç»“å…³é”®æ¦‚å¿µå¹¶æä¾›å†…è”å¼•ç”¨ï¼›ä¹Ÿå¯ä½œä¸ºéŸ³é¢‘åŠ©æ‰‹ï¼Œåœ¨è½¬å½•çš„å¯¹è¯ä¸­æœç´¢ç‰¹å®šä¿¡æ¯ã€‚",
    "post_summary_en": "NotebookLM has added support for audio and YouTube, allowing users to add YouTube links and audio files, and improved the sharing function of Audio Overviews. It can be used as a video and lecture analysis assistant to summarize key concepts and provide inline references, or as an audio assistant to search for specific information in transcribed conversations.",
    "post_datetime": "2024-09-26T19:19:53-07:00",
    "source_language": "cn",
    "confidence_score": 1.0
  },
  "19221e49089695d5": {
    "email_id": "19221e49089695d5",
    "post_labels": [
      "LLM",
      "NotebookLM"
    ],
    "post_content_cn": "AIGCLINK (@aigclink) äº 2024å¹´9æœˆ23æ—¥æ˜ŸæœŸä¸€ä¸Šåˆ7:56å‘å¸ƒï¼š\nPDFè½¬éŸ³é¢‘å·¥å…·ï¼šPDF2Audioï¼ŒNotebookLMçš„å¼€æºæ›¿ä»£æ–¹æ¡ˆ\nå¯ä»¥PDFè½¬æ’­å®¢ã€è®²åº§ã€è®¨è®ºã€çŸ­/é•¿æ–‡æ‘˜è¦ç­‰\n\næ”¯æŒä¸Šä¼ å¤šä¸ª PDF æ–‡ä»¶\næ”¯æŒä¸åŒæŒ‡ä»¤æ¨¡æ¿ï¼ŒåŒ…æ‹¬æ’­å®¢ã€è®²åº§ã€æ‘˜è¦ç­‰\nè‡ªå®šä¹‰æ–‡æœ¬ç”Ÿæˆå’ŒéŸ³é¢‘æ¨¡å‹\næ”¯æŒä¸åŒå£°éŸ³é€‰æ‹©\næ”¯æŒè‡ªå®šä¹‰éŸ³é¢‘é•¿åº¦ã€è¯­æ°”ã€é£æ ¼ç­‰",
    "post_content_en": "AIGCLINK (@aigclink) posted at 7:56 AM on Mon, Sep 23, 2024:\nPDF to Audio Tool: PDF2Audio, an open-source alternative to NotebookLM\nCan convert PDFs to podcasts, lectures, discussions, short/long text summaries, etc.\n\nSupports uploading multiple PDF files\nSupports different command templates, including podcasts, lectures, summaries, etc.\nCustom text generation and audio models\nSupports different voice options\nSupports custom audio length, tone, style, etc.",
    "link_lists": [
      "https://t.co/lywPfFAHzg",
      "https://t.co/tdwWRDiYXw",
      "https://x.com/aigclink/status/1838231005800624372?t=RKGMCNlu7-IljkjW8tB_Tw&s=03"
    ],
    "post_summary_cn": "AIGCLINKå‘å¸ƒäº†ä¸€ä¸ªåä¸ºPDF2Audioçš„å¼€æºå·¥å…·ï¼Œå¯ä»¥å°†PDFè½¬æ¢ä¸ºéŸ³é¢‘ï¼Œæ”¯æŒå¤šç§æ ¼å¼å’Œè‡ªå®šä¹‰é€‰é¡¹ã€‚",
    "post_summary_en": "AIGCLINK released an open-source tool called PDF2Audio that converts PDFs to audio, supporting various formats and customization options.",
    "post_datetime": "2024-09-23T19:38:01-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1923996e5a914c84": {
    "email_id": "1923996e5a914c84",
    "post_labels": [
      "LLM/ppt-generation",
      "life"
    ],
    "post_content_cn": "Jeffery Kaneda é‡‘ç”°é”ä¹Ÿ (@JefferyTatsuya) posted at 11:32 PM on Fri, Sep 27, 2024: è°è¿˜éœ€è¦officeå‘¢ğŸ˜›",
    "post_content_en": "Jeffery Kaneda Tatsuya Kanda (@JefferyTatsuya) posted at 11:32 PM on Fri, Sep 27, 2024: Who still needs office?ğŸ˜›",
    "link_lists": [
      "https://x.com/JefferyTatsuya/status/1839916194243195345?t=8l6rAjSo1TS0jF958oEfMQ&s=03"
    ],
    "post_summary_cn": "Jeffery Kaneda é‡‘ç”°é”ä¹Ÿ (@JefferyTatsuya) åœ¨2024å¹´9æœˆ27æ—¥æ™šä¸Š11:32å‘å¸ƒäº†ä¸€æ¡å¸–å­ï¼Œè´¨ç–‘è°è¿˜éœ€è¦Officeã€‚",
    "post_summary_en": "Jeffery Kaneda Tatsuya Kanda (@JefferyTatsuya) posted at 11:32 PM on Fri, Sep 27, 2024, questioning who still needs Office.",
    "post_datetime": "2024-09-28T10:04:05-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "19236767ca6262b0": {
    "email_id": "19236767ca6262b0",
    "post_labels": [
      "LLM/ppt-generation",
      "LLM"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 4:45 PM on Fri, Sep 27, 2024:\nAI PPT åŠ©æ‰‹ @KaranVaidya6\n\nåŸºäº Google Sheets æ•°æ®æ„å»º PPT æ–‡ç¨¿çš„ AI Agent, åˆ©ç”¨äº† LlamaIndex\n@llama_indexã€Composio @composiohqã€CrewAI @crewAIIncã€AgentOps @AgentOpsAI å’Œ\nChatGPT ç­‰æŠ€æœ¯\n\nåŠŸèƒ½åŒ…æ‹¬è¯»å–è¡¨æ ¼ã€ç»˜åˆ¶å›¾è¡¨ã€å‘ç°å…³é”®æ´å¯Ÿå¹¶åˆ›å»º PPT æ–‡ç¨¿ã€‚",
    "post_content_en": "meng shao (@shao__meng) posted at 4:45 PM on Fri, Sep 27, 2024:\nAI PPT Assistant @KaranVaidya6\n\nAn AI Agent that builds PPT documents based on Google Sheets data, utilizing technologies such as LlamaIndex\n@llama_index, Composio @composiohq, CrewAI @crewAIInc, AgentOps @AgentOpsAI, and\nChatGPT.\n\nFeatures include reading tables, drawing charts, discovering key insights, and creating PPT documents.",
    "link_lists": [
      "https://x.com/shao__meng/status/1839813614263517295?t=e24CpHpjE5MqkIz9jt62uA&s=03"
    ],
    "post_summary_cn": "meng shao å‘å¸ƒäº†ä¸€ä¸ªåŸºäº Google Sheets æ•°æ®æ„å»º PPT æ–‡ç¨¿çš„ AI åŠ©æ‰‹ï¼Œåˆ©ç”¨äº†å¤šç§æŠ€æœ¯ï¼ŒåŒ…æ‹¬ LlamaIndexã€Composioã€CrewAIã€AgentOps å’Œ ChatGPTã€‚è¯¥åŠ©æ‰‹èƒ½å¤Ÿè¯»å–è¡¨æ ¼ã€ç»˜åˆ¶å›¾è¡¨ã€å‘ç°å…³é”®æ´å¯Ÿå¹¶åˆ›å»º PPT æ–‡ç¨¿ã€‚",
    "post_summary_en": "meng shao posted about an AI PPT Assistant that builds PPT documents based on Google Sheets data, utilizing technologies such as LlamaIndex, Composio, CrewAI, AgentOps, and ChatGPT. The assistant can read tables, draw charts, discover key insights, and create PPT documents.",
    "post_datetime": "2024-09-27T19:29:48-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1905f0edb6c42abf": {
    "email_id": "1905f0edb6c42abf",
    "post_labels": [
      "LLM/ppt-generation"
    ],
    "post_content_cn": "orange.ai (@oran_ge) posted at 7:53 PM on Wed, Jun 26, 2024:\nFigma ä¹Ÿæ€å…¥ PPT äº†\nPPT æ˜¯æµ·å†…å¤–é€šæ€çš„åˆšéœ€",
    "post_content_en": "orange.ai (@oran_ge) posted at 7:53 PM on Wed, Jun 26, 2024:\nFigma has also entered the PPT market\nPPT is a universal necessity both domestically and internationally",
    "link_lists": [
      "https://x.com/oran_ge/status/1806158860593528922?t=uE6LPFvrGWwSg1ERBn94nQ&s=03"
    ],
    "post_summary_cn": "Figma è¿›å…¥ PPT å¸‚åœºï¼ŒPPT æ˜¯å›½å†…å¤–éƒ½éœ€è¦çš„å·¥å…·ã€‚",
    "post_summary_en": "Figma has entered the PPT market, and PPT is a tool needed both domestically and internationally.",
    "post_datetime": "2024-06-28T06:35:29-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "18f924a987299d8d": {
    "email_id": "18f924a987299d8d",
    "post_labels": [
      "kids"
    ],
    "post_content_cn": "é£›é³¥ (@askaiwy) posted at 5:29 PM on Sat, May 18, 2024:\nã€Šè§’é²¨è‚æ²¹çš„çŸ¥è¯†ã€‹\n\nå†™è¿™ç¯‡å…³äºè§’é²¨è‚æ²¹çš„ä»‹ç»çš„æ—¶å€™ï¼Œ\nå…‰æ˜¯æŸ¥èµ„æ–™å°±ç”¨äº†å·®ä¸å¤šå¤§åŠä¸ªæœˆçš„æ—¶é—´ã€‚\nå…¶é—´ä¸ºäº†å‡†ç¡®æŸ¥å‡ºå¯¹åº”çš„ä¸“ä¸šåè¯ï¼Œ\nä¸­ã€æ—¥ã€è‹±ä¸‰å›½çš„ç½‘ç«™é‡Œé¢åå¤åˆ‡æ¢ã€‚\næ‰€ä»¥ï¼Œ\nè¯¸ä½ä¸€å®šè¦æœ‰è€å¿ƒçœ‹åˆ°æœ€åå•Šï¼\n\né¦–å…ˆæˆ‘ä»¬è¦åˆ†æ¸…æ¥šï¼Œ\né±¼æ²¹è·Ÿé±¼è‚æ²¹çš„ä¸åŒã€‚\né±¼æ²¹ï¼Œâ€¦",
    "post_content_en": "Asuka (@askaiwy) posted at 5:29 PM on Sat, May 18, 2024:\nã€ŠKnowledge of Shark Liver Oilã€‹\n\nWhen writing this introduction about shark liver oil,\nI spent almost half a month just researching.\nDuring this time, in order to accurately find the corresponding professional terms,\nI repeatedly switched between Chinese, Japanese, and English websites.\nSo,\neveryone must be patient and read to the end!\n\nFirst, we need to distinguish between\nfish oil and fish liver oil.\nFish oil,â€¦",
    "link_lists": [
      "https://t.co/eM82FWxyRm",
      "https://x.com/askaiwy/status/1791989619753640168?t=fkURtChNKqWSXinAmtR7lQ&s=03"
    ],
    "post_summary_cn": "é£›é³¥åˆ†äº«äº†å…³äºè§’é²¨è‚æ²¹çš„çŸ¥è¯†ï¼Œå¼ºè°ƒäº†é±¼æ²¹å’Œé±¼è‚æ²¹çš„åŒºåˆ«ï¼Œå¹¶æåˆ°ä¸ºäº†å‡†ç¡®æŸ¥æ‰¾ä¸“ä¸šåè¯ï¼ŒèŠ±è´¹äº†å¤§é‡æ—¶é—´åœ¨ä¸­ã€æ—¥ã€è‹±ä¸‰å›½ç½‘ç«™é—´åˆ‡æ¢ã€‚",
    "post_summary_en": "Asuka shared knowledge about shark liver oil, emphasizing the difference between fish oil and fish liver oil, and mentioned spending a lot of time switching between Chinese, Japanese, and English websites to accurately find professional terms.",
    "post_datetime": "2024-05-19T12:18:33-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "18f6fef7ec95cb5c": {
    "email_id": "18f6fef7ec95cb5c",
    "post_labels": [
      "good_material",
      "kids"
    ],
    "post_content_cn": "",
    "post_content_en": "",
    "link_lists": [
      "https://twitter.com/essen_ai/status/1789471688121274678",
      "https://immersivemath.com/ila/index.html#"
    ],
    "post_summary_cn": "æ¨èä¸€ä¸ªæ²‰æµ¸å¼æ•°å­¦ç½‘ç«™immersivemathï¼Œç‰¹åˆ«é€‚åˆæœ‰å°å­©åœ¨å¿µä¹¦çš„å®¶é•¿ï¼Œå°¤å…¶æ˜¯æµ·å¤–åäººã€‚",
    "post_summary_en": "Recommends an immersive math website, immersivemath, especially helpful for parents with school-going children, particularly overseas Chinese.",
    "post_datetime": "2024-12-05T20:11:57-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1922a3e859b891b1": {
    "email_id": "1922a3e859b891b1",
    "post_labels": [
      "LLM/git-project"
    ],
    "post_content_cn": "AIGCLINK (@aigclink) äº2024å¹´9æœˆ24æ—¥æ˜ŸæœŸäºŒæ™šä¸Š7:03å‘å¸ƒï¼š\nMarkdownæ–‡æœ¬è½¬æ€ç»´å¯¼å›¾å·¥å…·ï¼šmarkmap\né€šè¿‡è§£æMarkdownè¯­æ³•ï¼Œå®æ—¶ç”Ÿæˆç»“æ„åŒ–æ€ç»´å¯¼å›¾\n\nè½»é‡çº§ï¼Œå¯ä¸VS Codeã€Vim/Neovimã€Emacsé›†æˆ\næ”¯æŒå®æ—¶æ¸²æŸ“ã€å¯å®šåˆ¶å¯äº¤äº’ï¼ŒåµŒå…¥æ€§å¼º",
    "post_content_en": "AIGCLINK (@aigclink) posted at 7:03 PM on Tue, Sep 24, 2024:\nMarkdown to mind map tool: markmap\nBy parsing Markdown syntax, it generates structured mind maps in real-time\n\nLightweight, integrates with VS Code, Vim/Neovim, Emacs\nSupports real-time rendering, customizable, interactive, and highly embeddable",
    "link_lists": [
      "https://t.co/lPYJJ0X8mu",
      "https://t.co/X0FtksjoTV",
      "https://x.com/aigclink/status/1838761274420900103?t=9f2VNJK7kFQIDpbLp_pG6w&s=03"
    ],
    "post_summary_cn": "AIGCLINKå‘å¸ƒäº†ä¸€æ¬¾åä¸ºmarkmapçš„å·¥å…·ï¼Œå¯å°†Markdownæ–‡æœ¬å®æ—¶è½¬æ¢ä¸ºç»“æ„åŒ–æ€ç»´å¯¼å›¾ã€‚è¯¥å·¥å…·è½»é‡çº§ï¼Œæ”¯æŒä¸VS Codeã€Vim/Neovimã€Emacsé›†æˆï¼Œå¹¶å…·æœ‰å®æ—¶æ¸²æŸ“ã€å¯å®šåˆ¶ã€å¯äº¤äº’å’Œå¼ºåµŒå…¥æ€§ç­‰ç‰¹ç‚¹ã€‚",
    "post_summary_en": "AIGCLINK introduced a tool called markmap that converts Markdown text into structured mind maps in real-time. The tool is lightweight, integrates with VS Code, Vim/Neovim, Emacs, and features real-time rendering, customization, interactivity, and strong embeddability.",
    "post_datetime": "2024-09-25T10:33:14-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "191704314e946803": {
    "email_id": "191704314e946803",
    "post_labels": [
      "LLM/git-project"
    ],
    "post_content_cn": "ä¸€ä¸ªåŸºäºçŸ¥è¯†å›¾è°±çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼šfact-finder\nåˆ©ç”¨LLMå’Œ Neo4j æ•°æ®åº“å®ç°è‡ªåŠ¨åŒ–æŸ¥è¯¢ä¸å›ç­”ï¼Œå®ç°äº†ä»ç”¨æˆ·é—®é¢˜åˆ°è‡ªç„¶è¯­è¨€ç­”æ¡ˆçš„è‡ªåŠ¨åŒ–è½¬æ¢è¿‡ç¨‹\n\nç‰¹ç‚¹ï¼š\n1ã€åŸºäºçŸ¥è¯†å›¾è°±ï¼šä½¿ç”¨Neo4j æ•°æ®åº“å­˜å‚¨å’Œç®¡ç†çŸ¥è¯†å›¾è°±ï¼Œå¹¶åˆ©ç”¨å®ƒæ¥å›ç­”é—®é¢˜",
    "post_content_en": "A knowledge graph-based intelligent Q&A system: fact-finder\nUtilizes LLM and Neo4j database to achieve automated querying and answering, realizing the automated conversion process from user questions to natural language answers.\n\nFeatures:\n1. Knowledge graph-based: Uses Neo4j database to store and manage the knowledge graph, and leverages it to answer questions.",
    "link_lists": [
      "https://t.co/MdTaBB3CBf",
      "https://x.com/aigclink/status/1825808691075100687?t=wjaCDJi7PUSj_VlUZeYnug&s=03"
    ],
    "post_summary_cn": "ä»‹ç»äº†ä¸€ä¸ªåŸºäºçŸ¥è¯†å›¾è°±çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿfact-finderï¼Œåˆ©ç”¨LLMå’ŒNeo4jæ•°æ®åº“å®ç°è‡ªåŠ¨åŒ–æŸ¥è¯¢ä¸å›ç­”ã€‚",
    "post_summary_en": "Introduces a knowledge graph-based intelligent Q&A system, fact-finder, which utilizes LLM and Neo4j database for automated querying and answering.",
    "post_datetime": "2024-08-20T07:48:50-07:00",
    "source_language": "cn",
    "confidence_score": 1.0
  },
  "1916db2af63b5ffa": {
    "email_id": "1916db2af63b5ffa",
    "post_labels": [
      "LLM",
      "git-project"
    ],
    "post_content_cn": "Tom Huang (@tuturetom) posted at 6:13 PM on Sun, Aug 18, 2024:\næ›´å¿«ï¼ŒåŒæ—¶æ€§èƒ½æŸå¤±é™åˆ°æœ€ä½ï¼Ÿ800 è¡Œä»£ç è½»é‡çº§ GraphRAG æ¥äº† âš¡ï¸ ğŸ¤¯ğŸ¤¯\n\nnano-GraphRAG æŠ½ç¦» GraphRAG æœ€æ ¸å¿ƒå®ç°å¹¶å…è®¸ä½ æ›¿æ¢ LLMã€Embedding\næ¨¡å—ï¼Œæä¾›å¼‚æ­¥å’Œç±»å‹å®‰å…¨çš„å®ç°ï¼Œéå¸¸é€‚åˆç ”ç©¶å­¦ä¹  GraphRAG æºç å¹¶é€‚é…è‡ªèº«ä¸šåŠ¡ğŸ”¥",
    "post_content_en": "Tom Huang (@tuturetom) posted at 6:13 PM on Sun, Aug 18, 2024:\nFaster, with minimal performance loss? The lightweight GraphRAG with 800 lines of code is here âš¡ï¸ ğŸ¤¯ğŸ¤¯\n\nnano-GraphRAG extracts the core implementation of GraphRAG and allows you to replace the LLM and Embedding\nmodules, providing asynchronous and type-safe implementations, making it ideal for studying GraphRAG source code and adapting it to your own businessğŸ”¥",
    "link_lists": [
      "https://t.co/FpWEV0viyU",
      "https://t.co/eohTiVAaUJ",
      "https://x.com/tuturetom/status/1825340242578317732?t=1QSmehD__de6w8LbAkBr-g&s=03"
    ],
    "post_summary_cn": "Tom Huang å‘å¸ƒäº†ä¸€ä¸ªè½»é‡çº§çš„ GraphRAG å®ç°ï¼Œä»…éœ€ 800 è¡Œä»£ç ï¼Œæ€§èƒ½æŸå¤±æœ€å°ï¼Œé€‚åˆç ”ç©¶å’Œä¸šåŠ¡é€‚é…ã€‚",
    "post_summary_en": "Tom Huang released a lightweight GraphRAG implementation with only 800 lines of code, minimizing performance loss, ideal for research and business adaptation.",
    "post_datetime": "2024-08-19T19:51:54-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "193b3651694b78cf": {
    "email_id": "193b3651694b78cf",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "å®ç‰ (@dotey) posted at 11:24 PM on Sat, Dec 07, 2024:\nå¾ˆå¤šäººè¿˜ä¸çŸ¥é“ AIStudio å¯ä»¥å…è´¹ä½“éªŒ Gemini çš„",
    "post_content_en": "Baoyu (@dotey) posted at 11:24 PM on Sat, Dec 07, 2024:\nMany people still don't know that AIStudio offers a free trial of Gemini.",
    "link_lists": [
      "https://t.co/nitrFrnNP9",
      "https://x.com/dotey/status/1865658660703068195?t=9OG5PDRYFx5WPKUGae5FQg&s=03"
    ],
    "post_summary_cn": "å®ç‰æé†’å¤§å®¶AIStudioæä¾›Geminiçš„å…è´¹ä½“éªŒã€‚",
    "post_summary_en": "Baoyu reminds everyone that AIStudio offers a free trial of Gemini.",
    "post_datetime": "2024-10-12T17:46:08-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1939256722b39736": {
    "email_id": "1939256722b39736",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "å®ç‰ (@dotey) posted at 6:56 PM on Tue, Dec 03, 2024:\nClaude æ–°çš„ MCP åè®®çš„è¶…é…·æ¡ˆä¾‹ï¼Œç”¨æˆ·ç›´æ¥ä» Claude\nå®¢æˆ·ç«¯å‘æ¶ˆæ¯ï¼Œå°±å¯ä»¥å¯¹å¾®ä¿¡ç¾¤çš„å†å²æ€»ç»“ã€æŸ¥è¯¢ã€‚æ¯”å¦‚ä½ æ—©ä¸Šèµ·æ¥ä¸€çœ‹ç¾¤é‡Œä¸Šåƒæ¡æ¶ˆæ¯ï¼Œå°±ç»™ Claude å‘ä¸€æ¡æ¶ˆæ¯ï¼šâ€œä»–ä»¬ä¸€å¤§æ—©åœ¨èŠå•¥ï¼Ÿâ€ï¼Œäºæ˜¯\nClaude å°±è®¿é—® MCP Server å»æŸ¥è¯¢æœ€æ–°çš„æ¶ˆæ¯ï¼Œå¹¶æ€»ç»“å›å¤ç»™ä½ ã€‚",
    "post_content_en": "Baoyu (@dotey) posted at 6:56 PM on Tue, Dec 03, 2024:\nA super cool case of Claude's new MCP protocol, where users can directly send messages from the Claude client to summarize and query the history of WeChat groups. For example, when you wake up in the morning and see thousands of messages in the group, you can send a message to Claude: 'What were they talking about this morning?' Then Claude will access the MCP Server to query the latest messages and summarize them for you.",
    "link_lists": [
      "https://x.com/dotey/status/1864141603096678658?t=J4H0DCMMFEZrkZcWcidePQ&s=03"
    ],
    "post_summary_cn": "Claudeçš„æ–°MCPåè®®å…è®¸ç”¨æˆ·é€šè¿‡å®¢æˆ·ç«¯ç›´æ¥æŸ¥è¯¢å’Œæ€»ç»“å¾®ä¿¡ç¾¤çš„å†å²æ¶ˆæ¯ã€‚",
    "post_summary_en": "Claude's new MCP protocol allows users to directly query and summarize the history of WeChat group messages through the client.",
    "post_datetime": "2024-04-12T07:42:40-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1937fa3373dc97e1": {
    "email_id": "1937fa3373dc97e1",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Tom DÃ¶rr (@tom_doerr) äº2024å¹´11æœˆ29æ—¥æ˜ŸæœŸäº”æ™šä¸Š9:49å‘å¸ƒï¼š\nâ€œå¼€æºçš„LLMOpså¹³å°ï¼šæç¤ºæ¸¸ä¹åœºã€æç¤ºç®¡ç†ã€LLMè¯„ä¼°å’ŒLLMå¯è§‚å¯Ÿæ€§ä¸€ç«™å¼æœåŠ¡ã€‚â€",
    "post_content_en": "Tom DÃ¶rr (@tom_doerr) posted at 9:49 PM on Fri, Nov 29, 2024:\n\"The open-source LLMOps platform: prompt playground, prompt management, LLM evaluation, and LLM Observability all in one place.\"",
    "link_lists": [
      "https://t.co/ShiUzBlcuo",
      "https://x.com/tom_doerr/status/1862735724006523039?t=27wXm3TgjFO1w6TGGxWDVg&s=03"
    ],
    "post_summary_cn": "Tom DÃ¶rr å‘å¸ƒäº†ä¸€ä¸ªå¼€æºçš„LLMOpså¹³å°ï¼Œé›†æˆäº†æç¤ºæ¸¸ä¹åœºã€æç¤ºç®¡ç†ã€LLMè¯„ä¼°å’ŒLLMå¯è§‚å¯Ÿæ€§åŠŸèƒ½ã€‚",
    "post_summary_en": "Tom DÃ¶rr announced an open-source LLMOps platform that integrates prompt playground, prompt management, LLM evaluation, and LLM Observability.",
    "post_datetime": "2024-11-30T16:33:43-08:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "193460a549478438": {
    "email_id": "193460a549478438",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 11:08 PM on Mon, Nov 18, 2024:\nLLM ç”Ÿæˆæ–‡æœ¬çš„å››ç§æ€§æ ¼ï¼šä»ä¿å®ˆæ´¾åˆ°åˆ›æ–°è€…\n\n// LLM ç”Ÿæˆæ–‡æœ¬çš„å››ç§ç­–ç•¥(è´ªå©ªã€å¤šé¡¹å¼é‡‡æ ·ã€é›†æŸæœç´¢ã€å¯¹æ¯”æœç´¢)ï¼Œå°±åƒä¸åŒæ€§æ ¼çš„å†™æ‰‹ï¼Œé€šè¿‡è°ƒèŠ‚æ¸©åº¦ã€Top-K\nç­‰å‚æ•°ï¼Œåœ¨\"ä¸¥è°¨-åˆ›æ„\"å…‰è°±ä¸Šæ‰¾åˆ°æœ€é€‚åˆå½“å‰ä»»åŠ¡çš„å¹³è¡¡ç‚¹\n\n1. è´ªå©ªç­–ç•¥(Greedy)å°±åƒä¸€ä¸ªè°¨æ…çš„äººï¼š\n- æ°¸è¿œé€‰æœ€ç¨³çš„é€‰é¡¹",
    "post_content_en": "meng shao (@shao__meng) posted at 11:08 PM on Mon, Nov 18, 2024:\nFour personalities of LLM-generated text: From conservatives to innovators\n\n// Four strategies for LLM-generated text (greedy, polynomial sampling, beam search, contrastive search), like writers with different personalities, find the most suitable balance for the current task on the \"rigorous-creative\" spectrum by adjusting parameters such as temperature and Top-K\n\n1. The greedy strategy is like a cautious person:\n- Always choose the safest option",
    "link_lists": [
      "https://t.co/6zYys7czFq",
      "https://x.com/shao__meng/status/1858769277983379519?t=WYlJj5oFYTzhuxuEL5CDMw&s=03"
    ],
    "post_summary_cn": "meng shao è®¨è®ºäº†LLMç”Ÿæˆæ–‡æœ¬çš„å››ç§ç­–ç•¥ï¼ŒåŒ…æ‹¬è´ªå©ªã€å¤šé¡¹å¼é‡‡æ ·ã€é›†æŸæœç´¢å’Œå¯¹æ¯”æœç´¢ï¼Œè¿™äº›ç­–ç•¥é€šè¿‡è°ƒèŠ‚å‚æ•°åœ¨ä¸¥è°¨ä¸åˆ›æ„ä¹‹é—´æ‰¾åˆ°å¹³è¡¡ã€‚",
    "post_summary_en": "meng shao discussed four strategies for LLM-generated text, including greedy, polynomial sampling, beam search, and contrastive search, which find a balance between rigor and creativity by adjusting parameters.",
    "post_datetime": "2024-11-19T12:08:22-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1930f733da07e48b": {
    "email_id": "1930f733da07e48b",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Rohan Paul (@rohanpaul_ai) äº2024å¹´11æœˆ8æ—¥æ˜ŸæœŸäº”ä¸Šåˆ10:02å‘å¸ƒï¼š\nå…³äºåŸºç¡€æ¨¡å‹ä»‹ç»çš„å¥½è¯¾ç¨‹",
    "post_content_en": "Rohan Paul (@rohanpaul_ai) posted at 10:02 AM on Fri, Nov 08, 2024:\nA good course on Introduction to Foundation Models",
    "link_lists": [
      "https://t.co/8YEWg6aflQ",
      "https://x.com/rohanpaul_ai/status/1854947658689134924?t=RWcKwZyJfPp72N6StQUXOg&s=03"
    ],
    "post_summary_cn": "Rohan Paul æ¨èäº†ä¸€é—¨å…³äºåŸºç¡€æ¨¡å‹ä»‹ç»çš„è¯¾ç¨‹ã€‚",
    "post_summary_en": "Rohan Paul recommended a course on Introduction to Foundation Models.",
    "post_datetime": "2024-08-11T21:43:51-08:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "192b5400ca9339f7": {
    "email_id": "192b5400ca9339f7",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "æ­¸è—(guizang.ai) (@op7418) posted at 0:17 AM on Tue, Oct 22, 2024:\nMeta ä¸Šå‘¨å¼€æºäº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„è¯­éŸ³æ¨¡å‹ Spirit LMã€‚\n\nè¿™ä¸ªå¤ªé‡è¦äº†ï¼Œå±…ç„¶æ²¡æ³¨æ„åˆ°ã€‚\n\nè¿™ä¸ªæ¨¡å‹æœ‰ä¸¤ä¸ªç‰ˆæœ¬ï¼š\n\nåŸºç¡€ç‰ˆï¼š é€‚åˆè¿›è¡Œä¸€èˆ¬çš„è¯­éŸ³è¯†åˆ«å’Œç”Ÿæˆï¼Œä¸åŒ…å«æƒ…æ„Ÿå˜åŒ–ã€‚\n\né«˜è¡¨ç°åŠ›ç‰ˆï¼šå¯ä»¥æ•æ‰è¯­éŸ³ä¸­çš„æƒ…æ„Ÿç‰¹å¾ï¼Œèƒ½å¤Ÿç”ŸæˆåŒ…å«å¿«ä¹ã€æ„¤æ€’æˆ–å…´å¥‹ç­‰æƒ…æ„Ÿçš„è¯­éŸ³ã€‚\n\nä¸»è¦ç‰¹ç‚¹æœ‰ï¼š\n\nSpirit LM\n(\n)",
    "post_content_en": "Guizang (guizang.ai) (@op7418) posted at 0:17 AM on Tue, Oct 22, 2024:\nMeta open-sourced an end-to-end speech model called Spirit LM last week.\n\nThis is so important, I can't believe I missed it.\n\nThe model has two versions:\n\nBasic version: Suitable for general speech recognition and generation, without emotional variations.\n\nHigh expressiveness version: Can capture emotional characteristics in speech and generate speech with emotions such as happiness, anger, or excitement.\n\nMain features include:\n\nSpirit LM\n(\n)",
    "link_lists": [
      "https://t.co/KPKitdbJD6",
      "https://x.com/op7418/status/1848624774785986676?t=GmUamkm_SYS_WzHtuXtqyw&s=03"
    ],
    "post_summary_cn": "Meta ä¸Šå‘¨å¼€æºäº†ç«¯åˆ°ç«¯è¯­éŸ³æ¨¡å‹ Spirit LMï¼ŒåŒ…å«åŸºç¡€ç‰ˆå’Œé«˜è¡¨ç°åŠ›ç‰ˆï¼Œåè€…èƒ½ç”Ÿæˆå¸¦æƒ…æ„Ÿçš„è¯­éŸ³ã€‚",
    "post_summary_en": "Meta open-sourced the end-to-end speech model Spirit LM last week, which includes a basic version and a high expressiveness version capable of generating emotional speech.",
    "post_datetime": "2024-10-22T10:22:08-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192aff7f75df9191": {
    "email_id": "192aff7f75df9191",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "linear uncle (@LinearUncle) posted at 8:43 PM on Sun, Oct 20, 2024:\nå¥½ä¹…æ²¡å†™æ¨ç‰¹äº†ï¼Œä»Šå¤©åˆ†äº«å¦‚ä½•åœ¨Macæœ¬åœ°è¿è¡Œåƒé—®Qwen2-VL-7Bæ¨¡å‹ğŸ’»ã€‚\n\nOllamaæœ‰äº›è½åï¼Œç°åœ¨LM Studioæ”¯æŒMLXæ ¼å¼æ¨¡å‹å¹¶è‡ªå¸¦èŠå¤©UIğŸ› ï¸ã€‚\n\næµ‹è¯•äº†åƒé—®çš„è§†è§‰æ¨¡å‹çš„ 3 ä¸ªå‹å·ï¼Œå¤æ‚è¯†åˆ«ä¸€èˆ¬ï¼Œç®€å•åœºæ™¯è¿˜è¡ŒğŸ‘€ã€‚\n\nç°åœ¨MLXçš„å¼€æºåº“å‘å±•ç”Ÿæœºå‹ƒå‹ƒï¼Œä¾‹å¦‚mlx-lm, mlx-whisperã€‚\n\nollamaä¸è¦å·æ‡’å•Šï¼",
    "post_content_en": "linear uncle (@LinearUncle) posted at 8:43 PM on Sun, Oct 20, 2024:\nIt's been a while since I last tweeted. Today, I'll share how to run the Qwen2-VL-7B model locally on a MacğŸ’».\n\nOllama is a bit outdated. Now, LM Studio supports MLX format models and comes with a chat UIğŸ› ï¸.\n\nTested three models of Qwen's visual model. Complex recognition is average, but simple scenes are okayğŸ‘€.\n\nThe MLX open-source libraries are thriving, such as mlx-lm, mlx-whisper.\n\nOllama, don't be lazy!",
    "link_lists": [
      "https://t.co/5AQ5R2a7VO",
      "https://x.com/LinearUncle/status/1848208380655255719?t=DClXsk6SURi4s_sLyJ71RA&s=03"
    ],
    "post_summary_cn": "Linear Uncleåˆ†äº«äº†åœ¨Macæœ¬åœ°è¿è¡ŒQwen2-VL-7Bæ¨¡å‹çš„æ–¹æ³•ï¼Œæåˆ°LM Studioæ”¯æŒMLXæ ¼å¼æ¨¡å‹å¹¶è‡ªå¸¦èŠå¤©UIã€‚æµ‹è¯•äº†åƒé—®è§†è§‰æ¨¡å‹çš„ä¸‰ä¸ªå‹å·ï¼Œå¤æ‚è¯†åˆ«ä¸€èˆ¬ï¼Œç®€å•åœºæ™¯è¿˜è¡Œã€‚MLXå¼€æºåº“å‘å±•è¿…é€Ÿï¼Œå¦‚mlx-lmå’Œmlx-whisperã€‚",
    "post_summary_en": "Linear Uncle shared how to run the Qwen2-VL-7B model locally on a Mac, mentioning that LM Studio supports MLX format models and comes with a chat UI. Tested three models of Qwen's visual model, with complex recognition being average and simple scenes being okay. MLX open-source libraries are thriving, such as mlx-lm and mlx-whisper.",
    "post_datetime": "2024-10-21T09:45:17-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1928e2aef24d00cb": {
    "email_id": "1928e2aef24d00cb",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "TuringPost (@TheTuringPost) å‘å¸ƒäº 2024å¹´10æœˆ14æ—¥æ˜ŸæœŸä¸€ ä¸‹åˆ6:11:\nBaichuan Inc, @Westlake_Uni, @ZJU_China",
    "post_content_en": "TuringPost (@TheTuringPost) posted at 6:11 PM on Mon, Oct 14, 2024:\nBaichuan Inc, @Westlake_Uni, @ZJU_China",
    "link_lists": [
      "https://t.co/fHrj6mSqsN",
      "https://t.co/iTXMquVHRv",
      "https://t.co/IxwqGV3nEf",
      "https://x.com/TheTuringPost/status/1845995803862773910?t=Hd_Dsm-YztU1HMhm-oCufg&s=03"
    ],
    "post_summary_cn": "TuringPost åœ¨2024å¹´10æœˆ14æ—¥å‘å¸ƒäº†ä¸€æ¡å…³äºBaichuan Incã€è¥¿æ¹–å¤§å­¦å’Œæµ™æ±Ÿå¤§å­¦çš„å¸–å­ã€‚",
    "post_summary_en": "TuringPost posted about Baichuan Inc, Westlake University, and Zhejiang University on October 14, 2024.",
    "post_datetime": "2024-10-14T20:13:52-07:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "1923998e7242c0be": {
    "email_id": "1923998e7242c0be",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Tom Huang (@tuturetom) äº 2024 å¹´ 9 æœˆ 27 æ—¥æ˜ŸæœŸäº”ä¸‹åˆ 6:35 å‘å¸ƒï¼š\n10 è¡Œä»£ç å³å¯åŸºäº Meta æœ€æ–°çš„ Llama 3.2 è¿›è¡Œåè®­ç»ƒï¼Ÿè¿˜èƒ½ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†ï¼âš¡ï¸\n\nHuggingface å‘å¸ƒçš„ trl å¼€æºåº“æ”¯æŒäº† sft_vlm è„šæœ¬ï¼æ”¯æŒå¯¹ 11B çš„å¤šæ¨¡æ€æ¨¡å‹è¿›è¡Œå¾®è°ƒğŸ”¥",
    "post_content_en": "Tom Huang (@tuturetom) posted at 6:35 PM on Fri, Sep 27, 2024:\nJust 10 lines of code to perform post-training based on Meta's latest Llama 3.2? You can even use your own dataset! âš¡ï¸\n\nHuggingface's trl open-source library now supports the sft_vlm script! Supports fine-tuning of 11B multimodal modelsğŸ”¥",
    "link_lists": [
      "https://t.co/o1seLclUjc",
      "https://t.co/fgrlg5n3GZ",
      "https://x.com/tuturetom/status/1839841204315566399?t=p5GeGLwnadbQVhVdC-p-iQ&s=03"
    ],
    "post_summary_cn": "Tom Huang å‘å¸ƒäº†ä¸€æ¡å…³äºä½¿ç”¨ 10 è¡Œä»£ç åŸºäº Meta çš„ Llama 3.2 è¿›è¡Œåè®­ç»ƒçš„æ¶ˆæ¯ï¼Œå¹¶æåˆ° Huggingface çš„ trl å¼€æºåº“æ”¯æŒå¯¹ 11B å¤šæ¨¡æ€æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚",
    "post_summary_en": "Tom Huang posted about using just 10 lines of code for post-training based on Meta's Llama 3.2, and mentioned that Huggingface's trl open-source library supports fine-tuning of 11B multimodal models.",
    "post_datetime": "2024-09-28T10:06:16-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "19239720ee4d8e1a": {
    "email_id": "19239720ee4d8e1a",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Kalyan KS (@kalyan_kpl) äº2024å¹´9æœˆ27æ—¥æ™šä¸Š7:32å‘å¸ƒï¼š\n7ä¸ªéœ€è¦äº†è§£çš„LLMç”Ÿæˆå‚æ•°\n\n- max_tokens\n- temperature\n- top_p\n- top_k\n- frequency penalty\n- presence penalty\n- stop sequence\n\n#llms #parameters #nlproc #textgeneration #deeplearning",
    "post_content_en": "Kalyan KS (@kalyan_kpl) posted at 7:32 PM on Fri, Sep 27, 2024:\n7 LLM Generation Parameters To Know\n\n- max_tokens\n- temperature\n- top_p\n- top_k\n- frequency penalty\n- presence penalty\n- stop sequence\n\n#llms #parameters #nlproc #textgeneration #deeplearning",
    "link_lists": [
      "https://t.co/LEixr3a1Nv",
      "https://x.com/kalyan_kpl/status/1839855780130107462?t=2b9-a94nPH_3OylvyvALUg&s=03"
    ],
    "post_summary_cn": "Kalyan KS åˆ†äº«äº†7ä¸ªéœ€è¦äº†è§£çš„LLMç”Ÿæˆå‚æ•°ï¼ŒåŒ…æ‹¬max_tokensã€temperatureã€top_pã€top_kã€frequency penaltyã€presence penaltyå’Œstop sequenceã€‚",
    "post_summary_en": "Kalyan KS shared 7 key LLM generation parameters to know, including max_tokens, temperature, top_p, top_k, frequency penalty, presence penalty, and stop sequence.",
    "post_datetime": "2024-09-28T09:23:51-07:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "1923148621b83746": {
    "email_id": "1923148621b83746",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Yangqing Jia (@jiayq) äº2024å¹´9æœˆ26æ—¥æ˜ŸæœŸå››ä¸Šåˆ10:59å‘å¸ƒï¼š\næˆ‘ä»¬å¯¹@OpenAIçš„è¯­éŸ³æ¨¡å¼ä½“éªŒå’Œ@AIatMetaçš„llama 3.2å‘å¸ƒæ„Ÿåˆ°éå¸¸æƒŠè®¶ã€‚é‚£ä¹ˆå°†å®ƒä»¬ç»“åˆèµ·æ¥ä¼šæ€æ ·å‘¢ï¼Ÿ\n\nå¾ˆé«˜å…´åˆ†äº«Lepton LLMå¼•æ“ç°åœ¨åŸç”Ÿæ”¯æŒå¼€æºæ¨¡å‹çš„è¯­éŸ³è¾“å…¥å’Œè¾“å‡º - é¦–æ¬¡éŸ³é¢‘ç”Ÿæˆæ—¶é—´",
    "post_content_en": "Yangqing Jia (@jiayq) posted at 10:59 AM on Thu, Sep 26, 2024:\nWe've been amazed by the @OpenAI voice mode experience and the @AIatMeta llama 3.2 release. And how about combining them together?\n\nExcited to share that the Lepton LLM engine now natively supports voice input and output for open source models - with a time to first audio",
    "link_lists": [
      "https://x.com/jiayq/status/1839364177485607185?t=5sOb9dNlRrCaYBw_ENhI3Q&s=03"
    ],
    "post_summary_cn": "Yangqing Jiaå¯¹OpenAIçš„è¯­éŸ³æ¨¡å¼å’ŒMetaçš„llama 3.2å‘å¸ƒè¡¨ç¤ºèµèµï¼Œå¹¶åˆ†äº«äº†Lepton LLMå¼•æ“ç°åœ¨æ”¯æŒå¼€æºæ¨¡å‹çš„è¯­éŸ³è¾“å…¥å’Œè¾“å‡ºã€‚",
    "post_summary_en": "Yangqing Jia expressed admiration for OpenAI's voice mode and Meta's llama 3.2 release, and shared that the Lepton LLM engine now supports voice input and output for open source models.",
    "post_datetime": "2024-09-26T19:21:20-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "1922fd75f4b1b31a": {
    "email_id": "1922fd75f4b1b31a",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "AIGCLINK (@aigclink) äº2024å¹´9æœˆ26æ—¥æ˜ŸæœŸå››å‡Œæ™¨2:15å‘å¸ƒï¼š\nå¾ˆæœ‰æ„æ€çš„ä¸€ä¸ªé¡¹ç›®ï¼Œç”¨Excelæ‰‹åŠ¨å®ç°AIç®—æ³•ç»ƒä¹ ï¼šai-by-hand-excelï¼Œåœ¨Excelé‡Œä½“éªŒAIçš„é­…åŠ›\n\nç›®å‰åŒ…å«äº†softmaxã€LeakyReLUã€åå‘ä¼ æ’­ã€Transformer å’Œå¾ªç¯ç¥ç»ç½‘ç»œ (RNN) ç­‰\n\nåé¢ä¼šå¢åŠ è‡ªæ³¨æ„åŠ›ã€å¤šå±‚æ„ŸçŸ¥å™¨ (MLP) å’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) ç­‰\n\n#AIç®—æ³• #AIç®—æ³•å­¦ä¹ ",
    "post_content_en": "AIGCLINK (@aigclink) posted at 2:15 AM on Thu, Sep 26, 2024:\nA very interesting project, manually implementing AI algorithm exercises in Excel: ai-by-hand-excel, experience the charm of AI in Excel.\n\nCurrently includes softmax, LeakyReLU, backpropagation, Transformer, and Recurrent Neural Networks (RNN), etc.\n\nLater, self-attention, Multi-Layer Perceptron (MLP), and Generative Adversarial Networks (GAN) will be added.\n\n#AI algorithms #AI algorithm learning",
    "link_lists": [
      "https://t.co/GcHbjVFi0y",
      "https://t.co/CwvCEPl3e6",
      "https://x.com/aigclink/status/1839232237558182076?t=eGwR_9gJFCQPSe4I1-hSRg&s=03"
    ],
    "post_summary_cn": "AIGCLINKå‘å¸ƒäº†ä¸€ä¸ªæœ‰è¶£çš„é¡¹ç›®ï¼Œé€šè¿‡Excelæ‰‹åŠ¨å®ç°AIç®—æ³•ç»ƒä¹ ï¼Œç›®å‰åŒ…å«å¤šç§ç®—æ³•ï¼Œæœªæ¥å°†å¢åŠ æ›´å¤šåŠŸèƒ½ã€‚",
    "post_summary_en": "AIGCLINK posted an interesting project manually implementing AI algorithm exercises in Excel, currently including various algorithms, with more features to be added in the future.",
    "post_datetime": "2024-09-26T12:38:15-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1922d0a8e8c01cc0": {
    "email_id": "1922d0a8e8c01cc0",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 5:21 PM on Wed, Sep 25, 2024:\nLlama 3.2 è§†è§‰æ¨¡å‹æœ€æ–°åº”ç”¨æ–¹å‘: Napkins\n\næ˜¯ä¸€ä¸ªå¼€æºçš„çº¿æ¡†å›¾åˆ°åº”ç”¨ç”Ÿæˆå™¨, å®ƒçš„æ ¸å¿ƒåŠŸèƒ½æ˜¯æ¥æ”¶ç”¨æˆ·ä¸Šä¼ çš„çº¿æ¡†å›¾æˆ–è‰å›¾, ç„¶ååˆ©ç”¨ AI\næŠ€æœ¯å°†å…¶è½¬æ¢ä¸ºå¯è¿è¡Œçš„ Web åº”ç”¨ç¨‹åº, å¤§å¤§åŠ é€ŸåŸå‹è®¾è®¡å’Œå¼€å‘è¿‡ç¨‹ã€‚\n\næŠ€æœ¯æ ˆ:\n- Meta Llama 3.1 405B ä½œä¸ºä¸»è¦è¯­è¨€æ¨¡å‹\n- Meta Llama",
    "post_content_en": "meng shao (@shao__meng) posted at 5:21 PM on Wed, Sep 25, 2024:\nLlama 3.2 Visual Model Latest Application Direction: Napkins\n\nIt is an open-source wireframe-to-application generator. Its core function is to receive user-uploaded wireframes or sketches and then use AI\ntechnology to convert them into runnable web applications, greatly accelerating the prototyping and development process.\n\nTech Stack:\n- Meta Llama 3.1 405B as the main language model\n- Meta Llama",
    "link_lists": [
      "https://t.co/xmBywgvBLW",
      "https://t.co/3TCEDzHsMk",
      "https://x.com/shao__meng/status/1839097896970629193?t=1WaM4Y6LNVAU_KPX7yJNCA&s=03"
    ],
    "post_summary_cn": "meng shao (@shao__meng) å‘å¸ƒäº†å…³äº Llama 3.2 è§†è§‰æ¨¡å‹åœ¨ Napkins åº”ç”¨ä¸­çš„æœ€æ–°è¿›å±•ã€‚è¯¥åº”ç”¨æ˜¯ä¸€ä¸ªå¼€æºçš„çº¿æ¡†å›¾åˆ°åº”ç”¨ç”Ÿæˆå™¨ï¼Œåˆ©ç”¨ AI æŠ€æœ¯å°†çº¿æ¡†å›¾æˆ–è‰å›¾è½¬æ¢ä¸ºå¯è¿è¡Œçš„ Web åº”ç”¨ç¨‹åºï¼ŒåŠ é€ŸåŸå‹è®¾è®¡å’Œå¼€å‘è¿‡ç¨‹ã€‚æŠ€æœ¯æ ˆåŒ…æ‹¬ Meta Llama 3.1 405B ä½œä¸ºä¸»è¦è¯­è¨€æ¨¡å‹ã€‚",
    "post_summary_en": "meng shao (@shao__meng) posted about the latest application direction of the Llama 3.2 visual model in Napkins. The application is an open-source wireframe-to-application generator that uses AI technology to convert wireframes or sketches into runnable web applications, speeding up the prototyping and development process. The tech stack includes Meta Llama 3.1 405B as the main language model.",
    "post_datetime": "2024-09-25T23:35:20-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1922d0a64f799829": {
    "email_id": "1922d0a64f799829",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Tom Huang (@tuturetom) posted at 7:00 PM on Wed, Sep 25, 2024:\nMeta æ­£åœ¨å®šä¹‰ LLM æ—¶ä»£çš„ PyTorchï¼Ÿâš¡ï¸ğŸ¤¯ğŸ¤¯ å®£å¸ƒæ­£å¼å¼€æº Llama Stackï¼ŒçŸ­æ—¶é—´é£™å‡ 648 Star ğŸ”¥\n\nLlama Stack å°† LLM åº”ç”¨æ„å»ºç”Ÿæˆå‘¨æœŸçš„æ‰€æœ‰ç»„ä»¶æ‰“åŒ…ï¼ŒåŒ…æ‹¬è®­ç»ƒã€å¾®è°ƒã€äº§å“è¯„ä¼°ã€è§‚æµ‹ã€Agent &\nMemoryã€åˆæˆæ•°æ®ç”Ÿæˆç­‰ï¼Œå¹¶æ”¯æŒ 9+ æä¾›å•†ğŸ’ª",
    "post_content_en": "Tom Huang (@tuturetom) posted at 7:00 PM on Wed, Sep 25, 2024:\nIs Meta defining PyTorch for the LLM era? âš¡ï¸ğŸ¤¯ğŸ¤¯ Announced the official open-source of Llama Stack, which skyrocketed 648 Stars in a short time ğŸ”¥\n\nLlama Stack packages all components of the LLM application build lifecycle, including training, fine-tuning, product evaluation, observation, Agent &\nMemory, synthetic data generation, etc., and supports 9+ providersğŸ’ª",
    "link_lists": [
      "https://t.co/fcsGWb7JMm",
      "https://x.com/tuturetom/status/1839122960948539415?t=53Rk8TcILjSGEQR4RLlWsA&s=03"
    ],
    "post_summary_cn": "Meta å®£å¸ƒå¼€æº Llama Stackï¼Œè¯¥å·¥å…·åŒ…å°† LLM åº”ç”¨æ„å»ºç”Ÿæˆå‘¨æœŸçš„æ‰€æœ‰ç»„ä»¶æ‰“åŒ…ï¼Œæ”¯æŒ 9+ æä¾›å•†ï¼ŒçŸ­æ—¶é—´å†…è·å¾— 648 Starã€‚",
    "post_summary_en": "Meta announced the open-source of Llama Stack, which packages all components of the LLM application build lifecycle, supports 9+ providers, and gained 648 Stars in a short time.",
    "post_datetime": "2024-09-25T23:35:10-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1922d09f40b85f3c": {
    "email_id": "1922d09f40b85f3c",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Kai-Fu Lee (@kaifulee) äº2024å¹´9æœˆ25æ—¥æ˜ŸæœŸä¸‰æ™šä¸Š9:01å‘å¸ƒï¼š\nOpenAIåˆšåˆšå‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿï¼Ÿï¼Ÿ è¿™æ˜¯æˆ‘æœ€å–œæ¬¢çš„â€œè®°è€…â€æŠ¥é“å’Œæ€»ç»“æœ€è¿‘çš„äº‹ä»¶ã€‚",
    "post_content_en": "Kai-Fu Lee (@kaifulee) posted at 9:01 PM on Wed, Sep 25, 2024:\nWhat just happened at OpenAI??? Here is my favorite 'reporter' reporting and summarizing recent events.",
    "link_lists": [
      "https://t.co/I3rsBQm2mE",
      "https://x.com/kaifulee/status/1839153300572352921?t=HRwn6Q0-mb9SyfpL-agMhA&s=03"
    ],
    "post_summary_cn": "æå¼€å¤åœ¨2024å¹´9æœˆ25æ—¥æ™šä¸Š9:01å‘å¸ƒäº†ä¸€æ¡å…³äºOpenAIæœ€è¿‘äº‹ä»¶çš„å¸–å­ï¼Œå¹¶æ¨èäº†ä»–æœ€å–œæ¬¢çš„è®°è€…çš„æŠ¥é“ã€‚",
    "post_summary_en": "Kai-Fu Lee posted on September 25, 2024, at 9:01 PM about recent events at OpenAI and recommended his favorite reporter's coverage.",
    "post_datetime": "2024-09-25T23:34:41-07:00",
    "source_language": "en",
    "confidence_score": 1.0
  },
  "1922cfe391bc3ff1": {
    "email_id": "1922cfe391bc3ff1",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Tom Huang (@tuturetom) posted at 7:07 PM on Wed, Sep 25, 2024:\nLlama Stack æŠ€æœ¯æ¶æ„ä¸€è§ˆ âš¡ï¸ æ–°ä¸€è½® LLMOps & Infra å¼€å§‹è§’é€ ğŸ¤”",
    "post_content_en": "Tom Huang (@tuturetom) posted at 7:07 PM on Wed, Sep 25, 2024:\nLlama Stack technical architecture overview âš¡ï¸ A new round of LLMOps & Infra competition begins ğŸ¤”",
    "link_lists": [
      "https://t.co/fcsGWb7JMm",
      "https://t.co/fnBu4Swfbn",
      "https://x.com/tuturetom/status/1839124585670947023?t=9To-rc9HKkCHYft-JBqQvw&s=03"
    ],
    "post_summary_cn": "Tom Huang å‘å¸ƒäº†å…³äº Llama Stack æŠ€æœ¯æ¶æ„çš„å¸–å­ï¼Œå¹¶æåˆ°æ–°ä¸€è½® LLMOps & Infra çš„ç«äº‰å·²ç»å¼€å§‹ã€‚",
    "post_summary_en": "Tom Huang posted about the Llama Stack technical architecture and mentioned that a new round of LLMOps & Infra competition has begun.",
    "post_datetime": "2024-09-25T23:21:52-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1922a965beb632df": {
    "email_id": "1922a965beb632df",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Jim Fan (@DrJimFan) äº2024å¹´9æœˆ25æ—¥æ˜ŸæœŸä¸‰ä¸Šåˆ11:42å‘å¸ƒï¼š\næˆ‘åˆšåˆšæŸ¥çœ‹äº†Llama-3.2-11Bï¼ˆè§†è§‰ï¼‰åœ¨è§†è§‰è¯­è¨€åŸºå‡†æµ‹è¯•ä¸­çš„è¡¨ç°ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œå¼€æºç¤¾åŒºåœ¨è½»é‡çº§æ¨¡å‹ç±»åˆ«ä¸­å¹¶ä¸è½åï¼Pixtralã€Qwen2-VLã€Molmoå’ŒInternVL2éƒ½è¡¨ç°å¼ºåŠ²ã€‚å¼€æºAIæ¨¡å‹ä»æœªå¦‚æ­¤å¼ºå¤§ã€‚",
    "post_content_en": "Jim Fan (@DrJimFan) posted at 11:42 AM on Wed, Sep 25, 2024:\nI just pulled the numbers on vision-language benchmarks for Llama-3.2-11B (vision). Surprisingly, the open-source community at large isn't behind in the lightweight model class! Pixtral, Qwen2-VL, Molmo, and InternVL2 all stand strong. OSS AI models have never been stronger.",
    "link_lists": [
      "https://t.co/NQaVVggNcU",
      "https://x.com/DrJimFan/status/1839012622441787430?t=T3bmOCbh0H26HRaPM7SAiw&s=03"
    ],
    "post_summary_cn": "Jim Fanåˆ†äº«äº†Llama-3.2-11Båœ¨è§†è§‰è¯­è¨€åŸºå‡†æµ‹è¯•ä¸­çš„è¡¨ç°ï¼ŒæŒ‡å‡ºå¼€æºç¤¾åŒºåœ¨è½»é‡çº§æ¨¡å‹ç±»åˆ«ä¸­è¡¨ç°å¼ºåŠ²ï¼ŒPixtralã€Qwen2-VLã€Molmoå’ŒInternVL2ç­‰æ¨¡å‹è¡¨ç°çªå‡ºã€‚",
    "post_summary_en": "Jim Fan shared the performance of Llama-3.2-11B on vision-language benchmarks, noting that the open-source community is strong in the lightweight model class, with Pixtral, Qwen2-VL, Molmo, and InternVL2 performing well.",
    "post_datetime": "2024-09-25T12:09:10-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "19222379902e02e8": {
    "email_id": "19222379902e02e8",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Tom Huang (@tuturetom) posted at 7:02 PM on Sun, Sep 22, 2024:\né˜¿é‡Œæœ€è¿‘å‘å¸ƒçš„ QWen 2.5 70B æœ‰ç‚¹ç‰›é€¼ğŸ‚ğŸº åœ¨ LiveBench Coding æ¦œå•ä¸Šå·²ç»æ‹¿ä¸‹ç¬¬äºŒï¼è¶…è¶Š gpt-4o\nå’Œæœ€è¿‘å‘å¸ƒçš„åŠæˆå“ O1-preview ğŸ¤ª\n\nLiveBench æ˜¯è‹±ä¼Ÿè¾¾ï¼ŒNYUï¼Œ@ylecun ç­‰äººå‘èµ·çš„æƒå¨æ¦œå•ï¼Œè¯„å®šæœ‰æŒ‘æˆ˜æ€§ä»»åŠ¡çš„æ¨¡å‹å¾—åˆ†",
    "post_content_en": "Tom Huang (@tuturetom) posted at 7:02 PM on Sun, Sep 22, 2024:\nAli recently released QWen 2.5 70B, which is quite impressive ğŸ‚ğŸº. It has already secured the second place on the LiveBench Coding leaderboard, surpassing gpt-4o\nand the recently released semi-finished product O1-preview ğŸ¤ª\n\nLiveBench is an authoritative leaderboard initiated by NVIDIA, NYU, @ylecun, and others, evaluating model scores on challenging tasks.",
    "link_lists": [
      "https://t.co/7Z2FixtvB2",
      "https://t.co/SYVWB1lZ0r",
      "https://x.com/tuturetom/status/1838036239603397071?t=UIO_Wv1KHiBCJK-1SuznSg&s=03"
    ],
    "post_summary_cn": "é˜¿é‡Œå‘å¸ƒçš„ QWen 2.5 70B åœ¨ LiveBench Coding æ¦œå•ä¸Šæ’åç¬¬äºŒï¼Œè¶…è¶Šäº† gpt-4o å’Œ O1-previewã€‚LiveBench æ˜¯ç”±è‹±ä¼Ÿè¾¾ã€NYU å’Œ @ylecun ç­‰å‘èµ·çš„æƒå¨æ¦œå•ã€‚",
    "post_summary_en": "Ali's QWen 2.5 70B has ranked second on the LiveBench Coding leaderboard, surpassing gpt-4o and O1-preview. LiveBench is an authoritative leaderboard initiated by NVIDIA, NYU, and @ylecun.",
    "post_datetime": "2024-09-23T21:08:43-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "19221f2c71f8d36e": {
    "email_id": "19221f2c71f8d36e",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 4:54 PM on Mon, Sep 23, 2024:\nä» LLM åˆ° LRM: OpenAI O1 æ¨¡å‹åœ¨ PlanBench ä¸Šçš„è§„åˆ’èƒ½åŠ›è¯„ä¼°\n\næœ€æ–° LLMs ä»ç„¶æ— æ³•è§„åˆ’, å¤§å‹æ¨ç†æ¨¡å‹ (LRM, OpenAI o1) å¯ä»¥å—? ä¸€èµ·çœ‹çœ‹ ğŸ‘‡\n\nLLMs çš„è§„åˆ’è¡¨ç°:\n- æœ€æ–°çš„ LLMs åœ¨æ™®é€š Blocksworld ä¸Šæœ‰æ‰€è¿›æ­¥, æœ€ä½³æ¨¡å‹ (LLaMA 3.1 405B) è¾¾åˆ° 62.5% çš„å‡†ç¡®ç‡\n- ä½†åœ¨æ··æ·†ç‰ˆæœ¬ (Mystery Blocksworld)",
    "post_content_en": "meng shao (@shao__meng) posted at 4:54 PM on Mon, Sep 23, 2024:\nFrom LLM to LRM: Evaluation of OpenAI O1 Model's Planning Capability on PlanBench\n\nLatest LLMs still cannot plan, can large reasoning models (LRM, OpenAI o1) do it? Let's take a look ğŸ‘‡\n\nPlanning performance of LLMs:\n- The latest LLMs have made progress on the standard Blocksworld, with the best model (LLaMA 3.1 405B) achieving 62.5% accuracy\n- But on the confusing version (Mystery Blocksworld)",
    "link_lists": [
      "https://t.co/8YZg0v2yK3",
      "https://x.com/shao__meng/status/1838366411389063616?t=jbXqWLf--KmI0_KDrC2vcg&s=03"
    ],
    "post_summary_cn": "meng shao è®¨è®ºäº†ä» LLM åˆ° LRM çš„è½¬å˜ï¼Œç‰¹åˆ«æ˜¯ OpenAI O1 æ¨¡å‹åœ¨ PlanBench ä¸Šçš„è§„åˆ’èƒ½åŠ›è¯„ä¼°ã€‚æœ€æ–°çš„ LLMs åœ¨æ™®é€š Blocksworld ä¸Šæœ‰æ‰€è¿›æ­¥ï¼Œä½†åœ¨æ··æ·†ç‰ˆæœ¬ä¸Šè¡¨ç°ä¸ä½³ã€‚",
    "post_summary_en": "meng shao discussed the transition from LLM to LRM, specifically evaluating the planning capability of the OpenAI O1 model on PlanBench. The latest LLMs have improved on the standard Blocksworld but perform poorly on the confusing version.",
    "post_datetime": "2024-09-23T19:53:32-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192124fc66236e00": {
    "email_id": "192124fc66236e00",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Tom Huang (@tuturetom) äº 2024 å¹´ 9 æœˆ 16 æ—¥æ˜ŸæœŸä¸€æ™šä¸Š 8:16 å‘å¸ƒï¼š\n275+ æ’ç”»ï¼Œ12+ ç« èŠ‚ï¼Œå´æ©è¾¾åŠ›èï¼âš¡ï¸å®Œç¾å‘ˆç° LLM å·¥ä¸šçº§åº”ç”¨ï¼Œæä¾›å®Œæ•´å¯è¿è¡Œçš„ä»£ç å’Œ Paper å¼•ç”¨ğŸ¤¯ğŸ¤¯ï¼Œè¿™æœ¬\nã€Šå®è·µå¤§è¯­è¨€æ¨¡å‹ã€‹ä¹Ÿå¤ªå¥½äº†ğŸ”¥\n\nä»‹ç»åŒ…æ‹¬è¯­è¨€æ¨¡å‹ã€Prompt Engineeringã€RAGã€å¤šæ¨¡æ€ã€å¾®è°ƒç­‰æ ¸å¿ƒå·¥ç¨‹å®è·µæŠ€æœ¯ï¼Œæ¯ç« æä¾›å®Œæ•´å¯è¿è¡Œçš„ä»£ç å’Œç¯å¢ƒé…ç½®",
    "post_content_en": "Tom Huang (@tuturetom) posted at 8:16 PM on Mon, Sep 16, 2024:\n275+ illustrations, 12+ chapters, highly recommended by Andrew Ng! âš¡ï¸ Perfectly presents industrial-level applications of LLM, providing complete runnable code and paper references ğŸ¤¯ğŸ¤¯, this book\n\"Practical Large Language Models\" is amazing ğŸ”¥\n\nIntroduces core engineering practices including language models, Prompt Engineering, RAG, multimodal, fine-tuning, etc., with complete runnable code and environment configuration for each chapter",
    "link_lists": [
      "https://t.co/QTcuP31CjZ",
      "https://t.co/HY8Q9SJrIw",
      "https://x.com/tuturetom/status/1835880356475724141?t=KldLH9XhzZ6TVotOPrUbeA&s=03"
    ],
    "post_summary_cn": "Tom Huang æ¨èäº†ä¸€æœ¬åä¸ºã€Šå®è·µå¤§è¯­è¨€æ¨¡å‹ã€‹çš„ä¹¦ç±ï¼Œè¯¥ä¹¦åŒ…å« 275+ æ’ç”»å’Œ 12+ ç« èŠ‚ï¼Œç”±å´æ©è¾¾åŠ›èã€‚ä¹¦ä¸­è¯¦ç»†ä»‹ç»äº†è¯­è¨€æ¨¡å‹ã€Prompt Engineeringã€RAGã€å¤šæ¨¡æ€ã€å¾®è°ƒç­‰æ ¸å¿ƒå·¥ç¨‹å®è·µæŠ€æœ¯ï¼Œå¹¶æä¾›äº†å®Œæ•´å¯è¿è¡Œçš„ä»£ç å’Œç¯å¢ƒé…ç½®ã€‚",
    "post_summary_en": "Tom Huang recommended a book titled \"Practical Large Language Models,\" which includes 275+ illustrations and 12+ chapters, highly recommended by Andrew Ng. The book details core engineering practices such as language models, Prompt Engineering, RAG, multimodal, fine-tuning, etc., and provides complete runnable code and environment configuration.",
    "post_datetime": "2024-09-20T19:01:11-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  }
}