{
  "192eab2db6236874": {
    "email_id": "192eab2db6236874",
    "post_labels": [
      "LLM/inference"
    ],
    "post_content_cn": "Tom DÃ¶rr (@tom_doerr) åœ¨ 2024 å¹´ 10 æœˆ 31 æ—¥æ˜ŸæœŸå››ä¸‹åˆ 5:19 å‘å¸ƒï¼šè™½ç„¶æˆ‘ç¡®ä¿¡ 405B é…å¤‡ 8GB vram ä¸ä¼šä»¥ç«ç®­é€Ÿåº¦è¿è¡Œ",
    "post_content_en": "Tom DÃ¶rr (@tom_doerr) posted at 5:19 PM on Thu, Oct 31, 2024: Though I'm sure 405B with 8GB vram won't be running at rocket speed",
    "link_lists": [
      "https://t.co/1AztdJExTZ",
      "https://x.com/tom_doerr/status/1852143317636780044?t=xpEu7KWNWjCXmHqHBnTc2g&s=03"
    ],
    "post_summary_cn": "Tom DÃ¶rr è®¤ä¸º 405B é…å¤‡ 8GB vram çš„é€Ÿåº¦ä¸ä¼šå¾ˆå¿«ã€‚",
    "post_summary_en": "Tom DÃ¶rr believes that 405B with 8GB vram won't run very fast.",
    "post_datetime": "2024-11-01T19:27:22-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "192f3dbdcbf233dd": {
    "email_id": "192f3dbdcbf233dd",
    "post_labels": [
      "LLM/OCR"
    ],
    "post_content_cn": "é˜…è¯»Datadriftersåœ¨Mediumä¸Šçš„æ–‡ç« â€œLlama 3.2-Vision for High-Precision OCR with Ollamaâ€ã€‚",
    "post_content_en": "Read â€œLlama 3.2-Vision for High-Precision OCR with Ollamaâ€œ by Datadrifters on Medium.",
    "link_lists": [
      "https://medium.com/@datadrifters/llama-3-2-vision-for-high-precision-ocr-with-ollama-472222da0ab5"
    ],
    "post_summary_cn": "Datadriftersåœ¨Mediumä¸Šå‘å¸ƒäº†ä¸€ç¯‡å…³äºLlama 3.2ä¸Ollamaç»“åˆè¿›è¡Œé«˜ç²¾åº¦OCRçš„æ–‡ç« ã€‚",
    "post_summary_en": "Datadrifters published an article on Medium about Llama 3.2 combined with Ollama for high-precision OCR.",
    "post_datetime": "2024-03-11T13:08:45-08:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "192895e02386c8fd": {
    "email_id": "192895e02386c8fd",
    "post_labels": [
      "LLM/OCR"
    ],
    "post_content_cn": "Tom DÃ¶rr (@tom_doerr) äº 2024å¹´10æœˆ13æ—¥æ˜ŸæœŸæ—¥ä¸Šåˆ11:08å‘å¸ƒï¼š\nOCR å·¥å…·åŒ…",
    "post_content_en": "Tom DÃ¶rr (@tom_doerr) posted at 11:08 AM on Sun, Oct 13, 2024:\nOCR toolkit",
    "link_lists": [
      "https://t.co/ui7ScfoEFD",
      "https://x.com/tom_doerr/status/1845527077795311623?t=YJ2DVR1JKU6RdtUvBMaN-w&s=03"
    ],
    "post_summary_cn": "Tom DÃ¶rr å‘å¸ƒäº†ä¸€ä¸ª OCR å·¥å…·åŒ…ã€‚",
    "post_summary_en": "Tom DÃ¶rr posted an OCR toolkit.",
    "post_datetime": "2024-10-13T21:51:32-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "192017092e1b4935": {
    "email_id": "192017092e1b4935",
    "post_labels": [
      "LLM",
      "OCR"
    ],
    "post_content_cn": "è¿™ä¸ªå¾ˆæœ‰æ„æ€ï¼åŸºäº QWen2 0.5 B æ¨¡å‹ã€‚å·ç§° OCR 2.0ï¼Œ580M å‚æ•°çš„ç«¯åˆ°ç«¯ OCR æ¨¡å‹ï¼Œæ‹¿åˆ°äº† BLEU 0.972 åˆ†æ•°ğŸ”¥\n\n0.58B æ¨¡å‹ï¼Œè¿˜æ˜¯ç«¯åˆ°ç«¯çš„å¤šæ¨¡æ€ğŸ¤” è¿™ä¸ªæ•ˆæœæœ‰ç‚¹ç¦»è°±ï¼Œæ„Ÿå…´è¶£çš„å¯ä»¥è¯•è¯•\n\nåœ¨çº¿ä½“éªŒ ğŸ‘‰  \nå¼€æºåœ°å€ ",
    "post_content_en": "This is very interesting! Based on the QWen2 0.5 B model. Known as OCR 2.0, the end-to-end OCR model with 580M parameters achieved a BLEU score of 0.972 ğŸ”¥\n\n0.58B model, and it's end-to-end multimodal ğŸ¤” The effect is a bit outrageous, those interested can try it out\n\nOnline experience ğŸ‘‰  \nOpen source address ",
    "link_lists": [
      "https://t.co/TxM511I8vV",
      "https://t.co/WIiiaZEXxY",
      "https://t.co/YD9kAfMiBS",
      "https://x.com/tuturetom/status/1835166243323887646?t=G3ScUkhJVkIyx5scb7oj-w&s=03"
    ],
    "post_summary_cn": "Tom Huang ä»‹ç»äº†ä¸€ä¸ªåŸºäº QWen2 0.5B æ¨¡å‹çš„ OCR 2.0ï¼Œå…·æœ‰580Må‚æ•°ï¼Œè·å¾—äº†é«˜åˆ†çš„ BLEU 0.972ã€‚",
    "post_summary_en": "Tom Huang introduced an OCR 2.0 based on the QWen2 0.5B model with 580M parameters, achieving a high BLEU score of 0.972.",
    "post_datetime": "2024-09-17T12:23:27-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1922d0d014b9e3ae": {
    "email_id": "1922d0d014b9e3ae",
    "post_labels": [
      "LLM/edge"
    ],
    "post_content_cn": "é«˜é€šæºæ‰‹ Meta æ¨ Llama 3.2: è®¾å¤‡ç«¯ AI çš„é‡å¤§çªç ´\né«˜é€šä¸ Meta åˆä½œ, ä¼˜åŒ–äº† Llama 3.2 ç³»åˆ—æ¨¡å‹, ä½¿å®ƒèƒ½åœ¨æ­è½½éªé¾™å¹³å°çš„è®¾å¤‡ä¸Šè¿è¡Œ, è¿™ä¸€åˆä½œæ—¨åœ¨æ¨è¿›è®¾å¤‡ç«¯AI çš„å‘å±•ã€‚\né«˜é€šæä¾›äº†å¤šç§å·¥å…·å’Œèµ„æº, å¸®åŠ©å¼€å‘è€…åœ¨éªé¾™å¹³å°ä¸Šä¼˜åŒ–å’Œéƒ¨ç½² Llama 3.2:",
    "post_content_en": "Qualcomm and Meta launch Llama 3.2: A major breakthrough in on-device AI\nQualcomm and Meta have collaborated to optimize the Llama 3.2 series models, enabling them to run on devices equipped with the Snapdragon platform. This collaboration aims to advance the development of on-device AI.\nQualcomm provides various tools and resources to help developers optimize and deploy Llama 3.2 on the Snapdragon platform.",
    "link_lists": [
      "https://t.co/yNjiw0hBDs",
      "https://x.com/shao__meng/status/1839095670571151753?t=3VzOSQaBw1PJSIc8mTGnFw&s=03"
    ],
    "post_summary_cn": "é«˜é€šä¸ Meta åˆä½œæ¨å‡º Llama 3.2ï¼Œæ—¨åœ¨æ¨è¿›è®¾å¤‡ç«¯ AI çš„å‘å±•ï¼Œå¹¶æä¾›å·¥å…·å¸®åŠ©å¼€å‘è€…åœ¨éªé¾™å¹³å°ä¸Šä¼˜åŒ–å’Œéƒ¨ç½²ã€‚",
    "post_summary_en": "Qualcomm and Meta have launched Llama 3.2 to advance on-device AI development, providing tools to help developers optimize and deploy on the Snapdragon platform.",
    "post_datetime": "2024-09-25T23:38:00-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1911a21f6ff55c59": {
    "email_id": "1911a21f6ff55c59",
    "post_labels": [
      "LLM/edge"
    ],
    "post_content_cn": "ç›´æ¥åœ¨æ ‘è“æ´¾ä¸Šè¿è¡Œç«¯ä¾§å‘é‡æ•°æ®åº“å¹¶è¿›è¡Œç«¯ä¾§çš„ ã€Œè¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…ã€ğŸ¤¯ğŸ¤¯\n\nSQLite-vec ä¹Ÿå¤ªé…·äº†ï¼å…¼å®¹ OpenAI Embedding æ¥å£çš„å®ç°ï¼Œæ”¯æŒç¦»çº¿ Embedding",
    "post_content_en": "Running an edge vector database directly on Raspberry Pi and performing edge-side 'semantic similarity matching' ğŸ¤¯ğŸ¤¯\n\nSQLite-vec is so cool! It implements compatibility with the OpenAI Embedding interface and supports offline Embedding",
    "link_lists": [
      "https://t.co/jccppCPBX6",
      "https://x.com/tuturetom/status/1819768397900681355?t=scoy-2K5x_I5bxaZ4Qomzg&s=03"
    ],
    "post_summary_cn": "åœ¨æ ‘è“æ´¾ä¸Šè¿è¡Œå‘é‡æ•°æ®åº“è¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…ï¼ŒSQLite-vec æ”¯æŒ OpenAI Embedding æ¥å£å’Œç¦»çº¿ Embeddingã€‚",
    "post_summary_en": "Running a vector database on Raspberry Pi for semantic similarity matching, SQLite-vec supports OpenAI Embedding interface and offline Embedding.",
    "post_datetime": "2024-03-08T14:25:15-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192eab0114bb7dc3": {
    "email_id": "192eab0114bb7dc3",
    "post_labels": [
      "LLM/meeting"
    ],
    "post_content_cn": "ä¸€æ¬¾åŸºäºLangflowã€Groqã€OpenAIæ„å»ºçš„æ™ºèƒ½ä¼šè®®åˆ†æåŠ©æ‰‹ï¼šmeetingmindï¼Œå®ƒå¯ä»¥ç”¨30ç§’åˆ†æä¸€å°æ—¶çš„ä¼šè®®ï¼Œè‡ªåŠ¨ç”Ÿæˆä¼šè®®è®°å½•å’Œå…³é”®ä¿¡æ¯\n\nç‰¹ç‚¹ï¼š\n1ã€æä¾›ä»ªè¡¨æ¿æŸ¥çœ‹åˆ†æç»“æœ\n2ã€æ”¯æŒéŸ³é¢‘å½•åˆ¶å’Œæ–‡ä»¶ä¸Šä¼ ï¼Œè‡ªåŠ¨è½¬å½•\n3ã€è‡ªåŠ¨æå–å…³é”®ä¿¡æ¯ï¼Œä»»åŠ¡ã€å†³ç­–ã€é—®é¢˜ã€æ´å¯Ÿã€æˆªæ­¢æ—¥æœŸã€å‚ä¸è€…ã€åç»­è¡ŒåŠ¨ã€é£é™©å’Œè®®ç¨‹ç­‰",
    "post_content_en": "An intelligent meeting analysis assistant built on Langflow, Groq, and OpenAI: meetingmind, which can analyze a one-hour meeting in 30 seconds and automatically generate meeting minutes and key information.\n\nFeatures:\n1. Provides a dashboard to view analysis results\n2. Supports audio recording and file upload, automatic transcription\n3. Automatically extracts key information such as tasks, decisions, issues, insights, deadlines, participants, follow-up actions, risks, and agenda.",
    "link_lists": [
      "https://t.co/5qHx8eY9Pi",
      "https://x.com/aigclink/status/1852252263877873898?t=HVSOB8RG7YQ2AKgKTfRMlQ&s=03"
    ],
    "post_summary_cn": "ä»‹ç»äº†ä¸€æ¬¾åä¸ºmeetingmindçš„æ™ºèƒ½ä¼šè®®åˆ†æåŠ©æ‰‹ï¼Œèƒ½å¤Ÿå¿«é€Ÿåˆ†æä¼šè®®å¹¶ç”Ÿæˆè®°å½•ï¼Œå…·æœ‰ä»ªè¡¨æ¿æŸ¥çœ‹ã€éŸ³é¢‘å½•åˆ¶å’Œè‡ªåŠ¨æå–å…³é”®ä¿¡æ¯ç­‰åŠŸèƒ½ã€‚",
    "post_summary_en": "Introduces an intelligent meeting analysis assistant called meetingmind, capable of quickly analyzing meetings and generating minutes, with features like dashboard viewing, audio recording, and automatic key information extraction.",
    "post_datetime": "2024-01-11T19:24:20-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192fad0282d9a104": {
    "email_id": "192fad0282d9a104",
    "post_labels": [
      "LLM/annotation"
    ],
    "post_content_cn": "Tom DÃ¶rr (@tom_doerr) åœ¨ 2024 å¹´ 11 æœˆ 4 æ—¥æ˜ŸæœŸä¸€ä¸Šåˆ 7:39 å‘å¸ƒï¼š\"Label Studio æ˜¯ä¸€ä¸ªå¤šç±»å‹æ•°æ®æ ‡æ³¨å’Œæ³¨é‡Šå·¥å…·ï¼Œå…·æœ‰æ ‡å‡†åŒ–çš„è¾“å‡ºæ ¼å¼\"",
    "post_content_en": "Tom DÃ¶rr (@tom_doerr) posted at 7:39 AM on Mon, Nov 04, 2024: \"Label Studio is a multi-type data labeling and annotation tool with standardized output format\"",
    "link_lists": [
      "https://t.co/l8jmkviFfd",
      "https://x.com/tom_doerr/status/1853462058387583234?t=v0RtFooqGnIyJ327Ggzo0w&s=03"
    ],
    "post_summary_cn": "Tom DÃ¶rr ä»‹ç»äº† Label Studioï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šç±»å‹æ•°æ®æ ‡æ³¨å·¥å…·ã€‚",
    "post_summary_en": "Tom DÃ¶rr introduced Label Studio, a multi-type data labeling tool.",
    "post_datetime": "2024-04-11T21:33:20-08:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "1936c211dd9acd6f": {
    "email_id": "1936c211dd9acd6f",
    "post_labels": [
      "LLM/front-end"
    ],
    "post_content_cn": "èš‚èšé›†å›¢å¼€æºçš„ä¸€ä¸ªå¯ä»¥å¿«é€Ÿæ„å»ºAIèŠå¤©ç•Œé¢çš„å·¥å…·åŒ…ï¼šAnt Design Xï¼Œç”¨å®ƒå¯ä»¥å¿«é€Ÿæ­å»ºå‡ºç±»ä¼¼ChatGPTé‚£ç§ä¸“ä¸šçš„å¯¹è¯ç•Œé¢ï¼Œä¸”å¯ä»¥è½»æ¾æ¥å…¥AIæ¨¡å‹\n\nä¸ç”¨ä»é›¶å¼€å§‹å†™ä»£ç ï¼Œç•Œé¢è®¾è®¡å·²ç»åšå¥½äº†ï¼Œç›´æ¥ç”¨å°±è¡Œ\næ”¯æŒè‡ªå®šä¹‰æ ·å¼\n\nå®ƒå¯ä»¥ç”¨äºå„ç§éœ€è¦å’ŒAIå¯¹è¯çš„åº”ç”¨ï¼Œæ¯”å¦‚æ™ºèƒ½å®¢æœç³»ç»Ÿã€AIåŠ©æ‰‹ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿç­‰",
    "post_content_en": "Ant Group has open-sourced a toolkit called Ant Design X that allows for the rapid construction of AI chat interfaces. It can be used to quickly build professional dialogue interfaces similar to ChatGPT and can easily integrate AI models.\n\nNo need to write code from scratch, the interface design is already done, just use it directly.\nSupports custom styles.\n\nIt can be used for various applications that require AI dialogue, such as intelligent customer service systems, AI assistants, and intelligent Q&A systems.",
    "link_lists": [
      "https://t.co/XqYqi9nbSN",
      "https://x.com/aigclink/status/1861594072743583942?t=-W8h4dOt5c3ZoQy7L4EEQg&s=03"
    ],
    "post_summary_cn": "èš‚èšé›†å›¢æ¨å‡ºäº†ä¸€ä¸ªåä¸ºAnt Design Xçš„å¼€æºå·¥å…·åŒ…ï¼Œç”¨äºå¿«é€Ÿæ„å»ºAIèŠå¤©ç•Œé¢ï¼Œæ”¯æŒè‡ªå®šä¹‰æ ·å¼ï¼Œé€‚ç”¨äºæ™ºèƒ½å®¢æœã€AIåŠ©æ‰‹ç­‰åº”ç”¨ã€‚",
    "post_summary_en": "Ant Group has released an open-source toolkit called Ant Design X for quickly building AI chat interfaces, supporting custom styles, suitable for applications like intelligent customer service and AI assistants.",
    "post_datetime": "2024-11-26T21:38:50-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "19074e4198617737": {
    "email_id": "19074e4198617737",
    "post_labels": [
      "LLM/front-end"
    ],
    "post_content_cn": "åœ¨ Medium ä¸Šé˜…è¯» Om Kamath çš„æ–‡ç« â€œGoogle åˆšåˆšæ€æ­»äº† Streamlit å—ï¼Ÿâ€",
    "post_content_en": "Read â€œDid Google Just Kill Streamlit?â€œ by Om Kamath on Medium",
    "link_lists": [
      "https://medium.com/google-cloud/did-google-just-kill-streamlit-76f719d9e275"
    ],
    "post_summary_cn": "è¿™æ˜¯ä¸€ç¯‡å…³äº Google æ˜¯å¦å½±å“äº† Streamlit çš„æ–‡ç« ã€‚",
    "post_summary_en": "This is an article about whether Google has impacted Streamlit.",
    "post_datetime": "2024-02-07T12:20:25-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "1905f6b02ef2f58e": {
    "email_id": "1905f6b02ef2f58e",
    "post_labels": [
      "LLM/front-end"
    ],
    "post_content_cn": "é˜…è¯» Preston Blackburn åœ¨ Medium ä¸Šçš„æ–‡ç« â€œStreamlit vs HTMX â€” LLM Streaming Chatbotsâ€ã€‚",
    "post_content_en": "Read â€œStreamlit vs HTMX â€” LLM Streaming Chatbotsâ€œ by Preston Blackburn on Medium.",
    "link_lists": [
      "https://medium.com/@prestonblckbrn/streamlit-vs-htmx-llm-streaming-chatbots-783708e3cddb"
    ],
    "post_summary_cn": "è¿™æ˜¯ä¸€ç¯‡å…³äº Streamlit å’Œ HTMX åœ¨ LLM æµå¼èŠå¤©æœºå™¨äººä¸­çš„æ¯”è¾ƒçš„æ–‡ç« ã€‚",
    "post_summary_en": "This is an article comparing Streamlit and HTMX in the context of LLM streaming chatbots.",
    "post_datetime": "2024-06-28T08:16:06-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "18fe678380223406": {
    "email_id": "18fe678380223406",
    "post_labels": [
      "LLM",
      "front-end"
    ],
    "post_content_cn": "Jintao Zhang (@zhangjintao9020) posted at 5:50 AM on Tue, Jun 04, 2024: Google å¼€æºäº†ä¸ªåŸºäº Python çš„ UI æ¡†æ¶ Mesop, æœ‰ç‚¹ç±»ä¼¼äº streamlit å’Œ Gradio ä¹‹ç±»çš„ç»„ä»¶ã€‚å…¶ä¸­çš„ç¤ºä¾‹çœ‹èµ·æ¥å°±æ˜¯ Gemini çš„æ ·å­äº†ã€‚è¿™ç±»ç»„ä»¶å¯èƒ½æ›´å¤šå°±æ˜¯ä¸ºäº†èƒ½è®©äºº å¿«é€Ÿæ„å»ºä¸€ä¸ªä½¿ç”¨ #LLM API çš„åº”ç”¨å§",
    "post_content_en": "Jintao Zhang (@zhangjintao9020) posted at 5:50 AM on Tue, Jun 04, 2024: Google has open-sourced a Python-based UI framework called Mesop, which is somewhat similar to components like streamlit and Gradio. The examples look like Gemini. These components are probably more for quickly building an application using the #LLM API.",
    "link_lists": [
      "https://t.co/yWksBInzPh",
      "https://x.com/zhangjintao9020/status/1797974187375821287?t=drGARnhWrdR5g0HPLsPeLg&s=03"
    ],
    "post_summary_cn": "Google å¼€æºäº†ä¸€ä¸ªç±»ä¼¼ streamlit å’Œ Gradio çš„ Python UI æ¡†æ¶ Mesopï¼Œé€‚ç”¨äºå¿«é€Ÿæ„å»ºä½¿ç”¨ LLM API çš„åº”ç”¨ã€‚",
    "post_summary_en": "Google has open-sourced a Python UI framework called Mesop, similar to streamlit and Gradio, for quickly building applications using the LLM API.",
    "post_datetime": "2024-04-06T20:36:30-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "193070131f9b93fb": {
    "email_id": "193070131f9b93fb",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "é˜…è¯» Dr. Leon Eversberg åœ¨ Medium ä¸Šçš„æ–‡ç« ã€Šå¦‚ä½•ä»æ–‡æ¡£ä¸­åˆ›å»º RAG è¯„ä¼°æ•°æ®é›†ã€‹ã€‚",
    "post_content_en": "Read â€œHow to Create a RAG Evaluation Dataset From Documentsâ€œ by Dr. Leon Eversberg on Medium.",
    "link_lists": [
      "https://towardsdatascience.com/how-to-create-a-rag-evaluation-dataset-from-documents-140daa3cbe71"
    ],
    "post_summary_cn": "Dr. Leon Eversberg åœ¨ Medium ä¸Šæ’°å†™äº†ä¸€ç¯‡å…³äºå¦‚ä½•ä»æ–‡æ¡£ä¸­åˆ›å»º RAG è¯„ä¼°æ•°æ®é›†çš„æ–‡ç« ã€‚",
    "post_summary_en": "Dr. Leon Eversberg wrote an article on Medium about how to create a RAG evaluation dataset from documents.",
    "post_datetime": "2024-07-11T06:22:20-08:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "192def19a6b15af6": {
    "email_id": "192def19a6b15af6",
    "post_labels": [
      "LLM/RAG/evaluation"
    ],
    "post_content_cn": "Braintrust (@braintrustdata) äº 2024å¹´10æœˆ29æ—¥æ˜ŸæœŸäºŒä¸Šåˆ9:17å‘å¸ƒï¼š",
    "post_content_en": "Braintrust (@braintrustdata) posted at 9:17 AM on Tue, Oct 29, 2024:",
    "link_lists": [
      "https://t.co/fdU8HG6Lql",
      "https://x.com/braintrustdata/status/1851297307775623465?t=xtQh7SFyixLynAebI9FVMg&s=03"
    ],
    "post_summary_cn": "Braintrust åœ¨ç¤¾äº¤åª’ä½“ä¸Šå‘å¸ƒäº†ä¸€æ¡æ¶ˆæ¯ã€‚",
    "post_summary_en": "Braintrust posted a message on social media.",
    "post_datetime": "2024-10-30T12:40:29-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "192deef375b504b3": {
    "email_id": "192deef375b504b3",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "Jason Wei (@_jasonwei) äº 2024å¹´10æœˆ30æ—¥æ˜ŸæœŸä¸‰ä¸Šåˆ10:45å‘å¸ƒï¼š\nå¾ˆé«˜å…´å¼€æºä¸€ä¸ªæ–°çš„å¹»è§‰è¯„ä¼°å·¥å…·ï¼Œåä¸ºSimpleQAï¼ä¸€æ®µæ—¶é—´ä»¥æ¥ï¼Œä¼¼ä¹æ²¡æœ‰ä¸€ä¸ªå¾ˆå¥½çš„äº‹å®æ€§åŸºå‡†ï¼Œå› æ­¤æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªç®€å•ã€å¯é ä¸”æ˜“äºç ”ç©¶äººå‘˜ä½¿ç”¨çš„è¯„ä¼°å·¥å…·ã€‚SimpleQAçš„ä¸»è¦ç‰¹ç‚¹ï¼š\n\n1. éå¸¸ç®€å•çš„è®¾ç½®ï¼š",
    "post_content_en": "Jason Wei (@_jasonwei) posted at 10:45 AM on Wed, Oct 30, 2024:\nExcited to open-source a new hallucinations eval called SimpleQA! For a\nwhile it felt like there was no great benchmark for factuality, and so we\ncreated an eval that was simple, reliable, and easy-to-use for researchers.\nMain features of SimpleQA:\n\n1. Very simple setup:",
    "link_lists": [
      "https://t.co/ffsC9yshiF",
      "https://x.com/_jasonwei/status/1851681730845118799?t=LOpHX_GGQJDKXjzpVIgunA&s=03"
    ],
    "post_summary_cn": "Jason Weiå®£å¸ƒå¼€æºä¸€ä¸ªåä¸ºSimpleQAçš„æ–°è¯„ä¼°å·¥å…·ï¼Œæ—¨åœ¨æä¾›ä¸€ä¸ªç®€å•ã€å¯é ä¸”æ˜“äºä½¿ç”¨çš„äº‹å®æ€§åŸºå‡†ã€‚",
    "post_summary_en": "Jason Wei announced the open-source release of a new evaluation tool called SimpleQA, designed to provide a simple, reliable, and easy-to-use benchmark for factuality.",
    "post_datetime": "2024-10-30T12:37:52-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "192d6bd3eb6f9a0d": {
    "email_id": "192d6bd3eb6f9a0d",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "è®© AI æ›´æ‡‚æŒ‡ä»¤: RAG ç³»ç»Ÿçš„æ™ºèƒ½å¯¹é½æ–¹æ¡ˆ\n\nè¿™ä¸ªé¡¹ç›®åŒ…å«äº†è®ºæ–‡ã€æ•°æ®å’Œä»£ç å®ç°, ä¸»è¦æ˜¯ RAG é¢†åŸŸçš„æŒ‡ä»¤å¯¹é½ç®¡é“ç³»ç»Ÿå’Œè‡ªåŠ¨è¯„ä¼°åŸºå‡†æµ‹è¯•ç³»ç»Ÿ:\nâ€» VIF-RAG: ä¸€ä¸ªåˆ›æ–°çš„æŒ‡ä»¤å¯¹é½ç®¡é“ç³»ç»Ÿ\nâ€» FollowRAG: ä¸€ä¸ªè‡ªåŠ¨è¯„ä¼°åŸºå‡†æµ‹è¯•ç³»ç»Ÿ\n\nä¸»è¦å†…å®¹:\n- VIF-RAG æ˜¯é¦–ä¸ªè‡ªåŠ¨åŒ–ã€å¯æ‰©å±•ã€å¯éªŒè¯çš„æ•°æ®åˆæˆç®¡é“",
    "post_content_en": "Make AI better understand instructions: Intelligent alignment scheme of RAG system\n\nThis project includes papers, data, and code implementations, mainly focusing on the instruction alignment pipeline system and automatic evaluation benchmark system in the RAG field:\nâ€» VIF-RAG: An innovative instruction alignment pipeline system\nâ€» FollowRAG: An automatic evaluation benchmark system\n\nMain content:\n- VIF-RAG is the first automated, scalable, and verifiable data synthesis pipeline",
    "link_lists": [
      "https://t.co/fiviPvzQSv",
      "https://x.com/shao__meng/status/1850802644761391420?t=imDLlCeUMOP_I-6jnNJ7Qg&s=03"
    ],
    "post_summary_cn": "ä»‹ç»äº† RAG ç³»ç»Ÿçš„æ™ºèƒ½å¯¹é½æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ VIF-RAG å’Œ FollowRAG ç³»ç»Ÿã€‚",
    "post_summary_en": "Introduces the intelligent alignment scheme of the RAG system, including the VIF-RAG and FollowRAG systems.",
    "post_datetime": "2024-10-28T22:26:20-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192d185f6bde68e6": {
    "email_id": "192d185f6bde68e6",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "RAGChecker: ç»†ç²’åº¦ RAG è¯Šæ–­è¯„ä¼°æ¡†æ¶\n\n@AmazonScience å¼€æºçš„ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼° RAG ç³»ç»Ÿçš„ç»¼åˆæ€§è‡ªåŠ¨è¯„ä¼°æ¡†æ¶, æä¾›äº†ä¸€å¥—å®Œæ•´çš„æŒ‡æ ‡å’Œå·¥å…·, ç”¨äºæ·±å…¥åˆ†æ RAG æ€§èƒ½ã€‚\n\nâ€» ä¸»è¦ç‰¹è‰²åŠŸèƒ½ â€»\n\nå…¨é¢çš„è¯„ä¼°ä½“ç³»:\n- æ•´ä½“æŒ‡æ ‡: è¯„ä¼°å®Œæ•´ RAG æµç¨‹\n- è¯Šæ–­æ€§æŒ‡æ ‡: åˆ†åˆ«é’ˆå¯¹æ£€ç´¢ç»„ä»¶å’Œç”Ÿæˆç»„ä»¶\n- ç»†ç²’åº¦è¯„ä¼°:",
    "post_content_en": "RAGChecker: Fine-grained RAG diagnostic evaluation framework\n\n@AmazonScience has open-sourced a comprehensive automatic evaluation framework specifically for assessing RAG systems, providing a complete set of metrics and tools for in-depth analysis of RAG performance.\n\nâ€» Main Features â€»\n\nComprehensive evaluation system:\n- Overall metrics: Evaluate the complete RAG process\n- Diagnostic metrics: Specifically for retrieval and generation components\n- Fine-grained evaluation:",
    "link_lists": [
      "https://t.co/0qX6oZOO5j",
      "https://x.com/shao__meng/status/1850512837711659211?t=gMoftwD44-YANOdjqYhHow&s=03"
    ],
    "post_summary_cn": "RAGChecker æ˜¯ä¸€ä¸ªç”± @AmazonScience å¼€æºçš„è¯„ä¼° RAG ç³»ç»Ÿçš„æ¡†æ¶ï¼Œæä¾›å…¨é¢çš„æŒ‡æ ‡å’Œå·¥å…·ï¼Œç”¨äºæ·±å…¥åˆ†æ RAG æ€§èƒ½ã€‚",
    "post_summary_en": "RAGChecker is a framework open-sourced by @AmazonScience for evaluating RAG systems, offering comprehensive metrics and tools for in-depth performance analysis.",
    "post_datetime": "2024-10-27T22:07:50-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192c6fb5e9da181b": {
    "email_id": "192c6fb5e9da181b",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "å­é—®é¢˜è¦†ç›–é©±åŠ¨çš„ RAG ç³»ç»Ÿä¼˜åŒ–\n\næ¥è‡ª @SFResearch çš„è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„è¯„ä¼°æ¡†æ¶, ä¸»è¦èšç„¦äº \"å­é—®é¢˜è¦†ç›–ç‡\" è¿™ä¸ªç»´åº¦æ¥è¯„ä¼° RAG ç³»ç»Ÿ, ä¸»è¦å†…å®¹:\n- å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºæ ¸å¿ƒã€èƒŒæ™¯å’Œåç»­ä¸‰ç±»å­é—®é¢˜\n- æå‡ºäº†ä¸€ä¸ªåŸºäºå­é—®é¢˜è¦†ç›–çš„ç»†ç²’åº¦è¯„ä¼°åè®®",
    "post_content_en": "Sub-question coverage-driven RAG system optimization\n\nA paper from @SFResearch proposes a novel evaluation framework, focusing mainly on the dimension of \"sub-question coverage\" to evaluate RAG systems. The main content includes:\n- Decomposing complex questions into three types of sub-questions: core, background, and follow-up\n- Proposing a fine-grained evaluation protocol based on sub-question coverage",
    "link_lists": [
      "https://t.co/9lLn0EAFhe",
      "https://x.com/shao__meng/status/1849605989894672821?t=Lo2Sv_lmVyNroW9J2HA6BA&s=03"
    ],
    "post_summary_cn": "è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„è¯„ä¼°æ¡†æ¶ï¼Œä¸“æ³¨äºé€šè¿‡å­é—®é¢˜è¦†ç›–ç‡æ¥è¯„ä¼° RAG ç³»ç»Ÿï¼ŒåŒ…å«å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºä¸‰ç±»å­é—®é¢˜ï¼Œå¹¶æå‡ºäº†ç»†ç²’åº¦è¯„ä¼°åè®®ã€‚",
    "post_summary_en": "The paper proposes a new evaluation framework focusing on evaluating RAG systems through sub-question coverage, including decomposing complex questions into three types of sub-questions and proposing a fine-grained evaluation protocol.",
    "post_datetime": "2024-10-25T21:00:16-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192c1d52c1896f13": {
    "email_id": "192c1d52c1896f13",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "å­é—®é¢˜è¦†ç›–é©±åŠ¨çš„ RAG ç³»ç»Ÿä¼˜åŒ–\n\næ¥è‡ª @SFResearch çš„è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„è¯„ä¼°æ¡†æ¶, ä¸»è¦èšç„¦äº \"å­é—®é¢˜è¦†ç›–ç‡\" è¿™ä¸ªç»´åº¦æ¥è¯„ä¼° RAG ç³»ç»Ÿ, ä¸»è¦å†…å®¹:\n- å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºæ ¸å¿ƒã€èƒŒæ™¯å’Œåç»­ä¸‰ç±»å­é—®é¢˜\n- æå‡ºäº†ä¸€ä¸ªåŸºäºå­é—®é¢˜è¦†ç›–çš„ç»†ç²’åº¦è¯„ä¼°åè®®",
    "post_content_en": "Sub-question coverage-driven RAG system optimization\n\nA paper from @SFResearch proposes a novel evaluation framework, focusing mainly on the dimension of \"sub-question coverage\" to evaluate RAG systems. Main content:\n- Decomposing complex questions into three types of sub-questions: core, background, and follow-up\n- Proposing a fine-grained evaluation protocol based on sub-question coverage",
    "link_lists": [
      "https://t.co/9lLn0EAFhe",
      "https://x.com/shao__meng/status/1849605989894672821?t=-AZKGS_2LX-TgL5Vwtde-A&s=03"
    ],
    "post_summary_cn": "è®ºæ–‡æå‡ºäº†ä¸€ä¸ªè¯„ä¼° RAG ç³»ç»Ÿçš„æ–°æ¡†æ¶ï¼Œé‡ç‚¹åœ¨äºå­é—®é¢˜è¦†ç›–ç‡ï¼ŒåŒ…å«å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºä¸‰ç±»å­é—®é¢˜å’Œä¸€ä¸ªç»†ç²’åº¦è¯„ä¼°åè®®ã€‚",
    "post_summary_en": "The paper proposes a new framework for evaluating RAG systems, focusing on sub-question coverage, including decomposing complex questions into three types of sub-questions and a fine-grained evaluation protocol.",
    "post_datetime": "2024-10-24T21:00:27-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192bd0e74d6cf141": {
    "email_id": "192bd0e74d6cf141",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "è¿™ç¯‡æ–‡æ¡£ä¸»è¦ä»‹ç»äº†å¦‚ä½•å°† Ragas ä¸ Opik å¹³å°ç»“åˆä½¿ç”¨æ¥ç›‘æ§å’Œè¯„ä¼° RAG pipeline.\n\nä¸¤ç§è¯„ä¼°æ–¹æ³•\n\n1. å¯¹è¿½è¸ª(Traces)è¿›è¡Œè¯„åˆ†\n- é€‚ç”¨äºç”Ÿäº§ç¯å¢ƒä¸­çš„å®æ—¶è¯„ä¼°\n- å¯ä»¥è¿½è¸ªå•ä¸ªæŸ¥è¯¢çš„å®Œæ•´å¤„ç†æµç¨‹\n- èƒ½å¤Ÿå®æ—¶è·å–è¯„åˆ†ç»“æœ",
    "post_content_en": "This document mainly introduces how to integrate Ragas with the Opik platform to monitor and evaluate the RAG pipeline.\n\nTwo evaluation methods\n\n1. Scoring of Traces\n- Suitable for real-time evaluation in production environments\n- Can track the complete processing flow of a single query\n- Able to obtain scoring results in real-time",
    "link_lists": [
      "https://t.co/sFPDbPHxdG",
      "https://x.com/shao__meng/status/1849241214635356232?t=QNGdK49fbYqo_uH17Agg6A&s=03"
    ],
    "post_summary_cn": "æ–‡æ¡£ä»‹ç»äº†å¦‚ä½•å°† Ragas ä¸ Opik å¹³å°ç»“åˆä½¿ç”¨æ¥ç›‘æ§å’Œè¯„ä¼° RAG pipelineï¼Œæä¾›äº†ä¸¤ç§è¯„ä¼°æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯å¯¹è¿½è¸ªè¿›è¡Œè¯„åˆ†çš„å®æ—¶è¯„ä¼°ã€‚",
    "post_summary_en": "The document introduces how to integrate Ragas with the Opik platform to monitor and evaluate the RAG pipeline, providing two evaluation methods, especially real-time evaluation of traces.",
    "post_datetime": "2024-10-23T22:44:54-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192b5441bf9af40a": {
    "email_id": "192b5441bf9af40a",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "Ragas v0.2 å‘å¸ƒ: ä» RAG è¿ˆå‘å…¨æ–¹ä½ LLM åº”ç”¨è¯„ä¼°\n\nLLM åº”ç”¨è¯„ä¼°æ¡†æ¶ Ragas @ragas_io äº 2023 å¹´ä¸­æœŸå¼€æº, æœ€åˆç›®æ ‡æ˜¯ä¸º RAG åº”ç”¨æä¾›è¯„ä¼°å·¥å…·, ä¸€å¹´å LLM åº”ç”¨å·²ç»å‘å±•è¶…è¶Šäº† RAG çš„èŒƒç•´ã€‚\n\nRagas v0.2 å¼€å§‹æ‰©å±•ä»¥æ”¯æŒæ›´å¹¿æ³›çš„ LLM åº”ç”¨è¯„ä¼°éœ€æ±‚, ç‰¹åˆ«æ˜¯ Agentic å·¥ä½œæµ, ä¸»è¦æ›´æ–° ğŸ‘‡ğŸ‘‡",
    "post_content_en": "Ragas v0.2 Released: Moving from RAG to Comprehensive LLM Application Evaluation\n\nThe LLM application evaluation framework Ragas @ragas_io was open-sourced in mid-2023, initially aimed at providing evaluation tools for RAG applications. A year later, LLM applications have developed beyond the scope of RAG.\n\nRagas v0.2 begins to expand to support broader LLM application evaluation needs, especially Agentic workflows, main updates ğŸ‘‡ğŸ‘‡",
    "link_lists": [
      "https://t.co/IZErsBN7b3",
      "https://x.com/shao__meng/status/1848618137044062224?t=pJXbYaZEkh5ZXy-xxvD42A&s=03"
    ],
    "post_summary_cn": "Ragas v0.2 å‘å¸ƒï¼Œæ‰©å±•æ”¯æŒæ›´å¹¿æ³›çš„ LLM åº”ç”¨è¯„ä¼°éœ€æ±‚ï¼Œç‰¹åˆ«æ˜¯ Agentic å·¥ä½œæµã€‚",
    "post_summary_en": "Ragas v0.2 released, expanding to support broader LLM application evaluation needs, especially Agentic workflows.",
    "post_datetime": "2024-10-22T10:26:34-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "191f8f965132937e": {
    "email_id": "191f8f965132937e",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "RAG å’Œ Long Context ä¹‹äº‰ï¼Œç»ˆäºæœ‰äº†é‡åŒ–çš„ç»“è®ºï¼š\n\nä¸ºé•¿ä¸Šä¸‹æ–‡è¯­è¨€æ¨¡å‹æ—¶ä»£çš„ RAG è¾©æŠ¤",
    "post_content_en": "The debate between RAG and Long Context has finally reached a quantitative conclusion:\n\nIn Defense of RAG in the Era of Long-Context Language Models",
    "link_lists": [
      "https://t.co/5tEacB9LJn",
      "https://t.co/djTITRMcVh",
      "https://x.com/oran_ge/status/1835313228416696371?t=j1_1XWSUaHH7SdzQuV3huA&s=03"
    ],
    "post_summary_cn": "RAG å’Œé•¿ä¸Šä¸‹æ–‡è¯­è¨€æ¨¡å‹çš„äº‰è®ºæœ‰äº†é‡åŒ–ç»“è®ºï¼Œæ–‡ç« ä¸º RAG è¾©æŠ¤ã€‚",
    "post_summary_en": "The debate between RAG and long-context language models has reached a quantitative conclusion, defending RAG.",
    "post_datetime": "2024-09-15T20:56:19-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1915f7118677a8ed": {
    "email_id": "1915f7118677a8ed",
    "post_labels": [
      "LLM/RAG/evaluation"
    ],
    "post_content_cn": "Kalyan KS (@kalyan_kpl) äº 2024å¹´8æœˆ16æ—¥æ˜ŸæœŸäº”ä¸Šåˆ9:47å‘å¸ƒï¼š\nRAGChecker - è¯Šæ–­RAGç³»ç»Ÿ\n\nRAGCheckeræ¡†æ¶\n\nRAGCheckeræ˜¯ä¸€ä¸ªç”¨äºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿçš„ç»†ç²’åº¦è¯„ä¼°æ¡†æ¶ã€‚\n\nè¯¥æ¡†æ¶åŒ…æ‹¬æ£€ç´¢å’Œç”Ÿæˆæ¨¡å—çš„è¯Šæ–­æŒ‡æ ‡ã€‚\n\næé«˜çš„è¯„ä¼°å‡†ç¡®æ€§",
    "post_content_en": "Kalyan KS (@kalyan_kpl) posted at 9:47 AM on Fri, Aug 16, 2024:\nRAGChecker - Diagnosing RAG Systems\n\nRAGChecker Framework\n\nRAGChecker is a fine-grained evaluation framework for Retrieval-Augmented Generation (RAG) systems.\n\nThis framework includes diagnostic metrics for both retrieval and generation modules.\n\nImproved Evaluation Accuracy",
    "link_lists": [
      "https://t.co/MnBLtV1GVE",
      "https://x.com/kalyan_kpl/status/1824488109637243094?t=Gln7pJSw5qA7Y8CSa4Tygw&s=03"
    ],
    "post_summary_cn": "RAGCheckeræ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°RAGç³»ç»Ÿçš„æ¡†æ¶ï¼Œæä¾›æ£€ç´¢å’Œç”Ÿæˆæ¨¡å—çš„è¯Šæ–­æŒ‡æ ‡ï¼Œä»¥æé«˜è¯„ä¼°å‡†ç¡®æ€§ã€‚",
    "post_summary_en": "RAGChecker is a framework for evaluating RAG systems, providing diagnostic metrics for retrieval and generation modules to improve evaluation accuracy.",
    "post_datetime": "2024-08-17T01:25:34-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "1915e8ff7f829004": {
    "email_id": "1915e8ff7f829004",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "elvis (@omarsar0) äº 2024å¹´8æœˆ16æ—¥æ˜ŸæœŸäº”ä¸Šåˆ7:56å‘å¸ƒï¼šRAGCheckerï¼šä¸€ä¸ªç”¨äºè¯Šæ–­RAGä¸­æ£€ç´¢å’Œç”Ÿæˆæ¨¡å—çš„ç»†ç²’åº¦è¯„ä¼°æ¡†æ¶ã€‚æ˜¾ç¤ºRAGCheckerä¸äººç±»åˆ¤æ–­æœ‰æ›´å¥½çš„ç›¸å…³æ€§ã€‚æŠ¥å‘Šäº†RAGæ¶æ„è®¾è®¡é€‰æ‹©ä¸­çš„å‡ ä¸ªæ­ç¤ºæ€§è§è§£æ¨¡å¼å’Œæƒè¡¡ã€‚",
    "post_content_en": "elvis (@omarsar0) posted at 7:56 AM on Fri, Aug 16, 2024: RAGChecker: a fine-grained evaluation framework for diagnosing retrieval and generation modules in RAG. Shows that RAGChecker has better correlations with human judgment. Reports several revealing insightful patterns and trade-offs in design choices of RAG architectures.",
    "link_lists": [
      "https://t.co/ZgwCJQszVM",
      "https://x.com/omarsar0/status/1824460245051081216?t=OCzDcZdcdJqpdueMzu5xnw&s=03"
    ],
    "post_summary_cn": "RAGCheckeræ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°RAGä¸­æ£€ç´¢å’Œç”Ÿæˆæ¨¡å—çš„æ¡†æ¶ï¼Œæ˜¾ç¤ºå‡ºä¸äººç±»åˆ¤æ–­çš„è‰¯å¥½ç›¸å…³æ€§ï¼Œå¹¶æ­ç¤ºäº†RAGæ¶æ„è®¾è®¡ä¸­çš„ä¸€äº›æ¨¡å¼å’Œæƒè¡¡ã€‚",
    "post_summary_en": "RAGChecker is a framework for evaluating retrieval and generation modules in RAG, showing good correlation with human judgment and revealing patterns and trade-offs in RAG architecture design.",
    "post_datetime": "2024-08-16T21:19:40-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "1913b8985d0a921e": {
    "email_id": "1913b8985d0a921e",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "Kalyan KS (@kalyan_kpl) äº 2024å¹´8æœˆ9æ—¥æ˜ŸæœŸäº”ä¸Šåˆ9:11å‘å¸ƒï¼š\nWalledEval - LLMå®‰å…¨è¯„ä¼°å·¥å…·åŒ…\n\nWalledEval æ˜¯ä¸€ä¸ªå…¨é¢çš„AIå®‰å…¨æµ‹è¯•å·¥å…·åŒ…ï¼Œæ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚\n\nè¯¥å·¥å…·åŒ…åŠŸèƒ½å¤šæ ·ï¼Œé€‚ç”¨äºå¤šç§æ¨¡å‹ã€‚\n\nå®ƒå¯ä»¥è¯„ä¼°å¼€æ”¾æƒé‡æ¨¡å‹ä»¥åŠé€šè¿‡ https://t.co/e4VRmnDYxa è®¿é—®çš„æ¨¡å‹ã€‚\n(https://x.com/kalyan_kpl/status/1821942405970772397?t=wBmtMR3AafpOGZ457r7fiQ&s=03)",
    "post_content_en": "Kalyan KS (@kalyan_kpl) posted at 9:11 AM on Fri, Aug 09, 2024:\nWalledEval - LLM Safety Evaluation Toolkit\n\nWalledEval is a comprehensive AI safety testing toolkit designed to evaluate large language models (LLMs).\n\nThe toolkit is versatile, accommodating a wide range of models.\n\nIt can evaluate both open-weight models and those accessed via https://t.co/e4VRmnDYxa\n(https://x.com/kalyan_kpl/status/1821942405970772397?t=wBmtMR3AafpOGZ457r7fiQ&s=03)",
    "link_lists": [
      "https://t.co/e4VRmnDYxa",
      "https://x.com/kalyan_kpl/status/1821942405970772397?t=wBmtMR3AafpOGZ457r7fiQ&s=03"
    ],
    "post_summary_cn": "WalledEval æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å…¨é¢AIå®‰å…¨æµ‹è¯•å·¥å…·åŒ…ï¼Œé€‚ç”¨äºå¤šç§æ¨¡å‹ã€‚",
    "post_summary_en": "WalledEval is a comprehensive AI safety testing toolkit for evaluating large language models (LLMs), suitable for various models.",
    "post_datetime": "2024-10-08T02:05:55-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "1913b886d4cbc848": {
    "email_id": "1913b886d4cbc848",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "Kalyan KS (@kalyan_kpl) äº 2024å¹´8æœˆ8æ—¥æ˜ŸæœŸå››æ™šä¸Š11:57å‘å¸ƒï¼š\nRAGEval - è‡ªåŠ¨ç”ŸæˆLLMè¯„ä¼°æ•°æ®é›†çš„æ–°æ¡†æ¶\n\nç°æœ‰RAGåŸºå‡†çš„å±€é™æ€§\n\nå½“å‰çš„RAGåŸºå‡†ä¸»è¦è¯„ä¼°LLMå›ç­”ä¸€èˆ¬çŸ¥è¯†é—®é¢˜çš„èƒ½åŠ›ã€‚\n\nå®ƒä»¬ä¸èƒ½æœ‰æ•ˆè¯„ä¼°RAGç³»ç»Ÿåœ¨ä¸åŒé¢†åŸŸçš„è¡¨ç°ã€‚",
    "post_content_en": "Kalyan KS (@kalyan_kpl) posted at 11:57 PM on Thu, Aug 08, 2024:\nRAGEval - Novel framework for automatically generating LLM evaluation datasets\n\nLimitations of existing RAG benchmarks\n\nCurrent RAG benchmarks primarily assess LLMs' ability to answer general knowledge questions.\n\nThey don't effectively evaluate RAG systems' performance across different domains.",
    "link_lists": [
      "https://t.co/CocwzlCkRM",
      "https://x.com/kalyan_kpl/status/1821803072177516736?t=JkUU25223YbEsNAAGZYLCQ&s=03"
    ],
    "post_summary_cn": "Kalyan KSä»‹ç»äº†RAGEvalï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè‡ªåŠ¨ç”ŸæˆLLMè¯„ä¼°æ•°æ®é›†çš„æ–°æ¡†æ¶ï¼ŒæŒ‡å‡ºç°æœ‰RAGåŸºå‡†çš„å±€é™æ€§åœ¨äºä¸»è¦è¯„ä¼°LLMå›ç­”ä¸€èˆ¬çŸ¥è¯†é—®é¢˜çš„èƒ½åŠ›ï¼Œè€Œä¸èƒ½æœ‰æ•ˆè¯„ä¼°RAGç³»ç»Ÿåœ¨ä¸åŒé¢†åŸŸçš„è¡¨ç°ã€‚",
    "post_summary_en": "Kalyan KS introduced RAGEval, a new framework for automatically generating LLM evaluation datasets, highlighting the limitations of existing RAG benchmarks which mainly assess LLMs' ability to answer general knowledge questions and do not effectively evaluate RAG systems' performance across different domains.",
    "post_datetime": "2024-10-08T02:04:43-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "1906a75dc2188234": {
    "email_id": "1906a75dc2188234",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "æœ¬å‘¨ï¼Œæˆ‘ä»¬ç»§ç»­æµ‹è¯„å„ ai search äº§å“çš„å‡†ç¡®ç‡ã€‚æœ¬æ¬¡æµ‹è¯„ï¼Œé‡ç‚¹å…³æ³¨å„äº§å“åœ¨ã€Šå¤æ‚æŸ¥è¯¢ã€‹ä¸‹çš„è¡¨ç°ï¼Œå³å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„å¤šå®ä½“æˆ–å¤šç›®æ ‡çš„æŸ¥è¯¢ã€‚ä¾‹å¦‚ï¼Œ- è‡ºç£2022å¹´GDPç¸½é‡ç›¸æ¯”2012å¹´å¢åŠ äº†å¤šå°‘ç¾å…ƒï¼Ÿ- Which movie is longer, Hamlet or Gone with the Wind",
    "post_content_en": "This week, we continue to evaluate the accuracy of various AI search products. This evaluation focuses on the performance of each product under 'complex queries', which involve multi-entity or multi-target queries in a multilingual environment. For example, - How much did Taiwan's GDP in 2022 increase in USD compared to 2012? - Which movie is longer, Hamlet or Gone with the Wind",
    "link_lists": [
      "https://t.co/Ymv6Qm5SX5",
      "https://x.com/YRSM_Simon/status/1789466458772378085?t=U5NqRxmd3Uoc6AdTMxPyrA&s=03"
    ],
    "post_summary_cn": "æœ¬å‘¨çš„æµ‹è¯„å…³æ³¨å¤šè¯­è¨€ç¯å¢ƒä¸‹å¤æ‚æŸ¥è¯¢çš„è¡¨ç°ã€‚",
    "post_summary_en": "This week's evaluation focuses on the performance of complex queries in a multilingual environment.",
    "post_datetime": "2024-06-30T11:43:49-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1902f3def2a9b305": {
    "email_id": "1902f3def2a9b305",
    "post_labels": [
      "LLM",
      "RAG",
      "evaluation"
    ],
    "post_content_cn": "LangChain (@LangChainAI) äº 2024å¹´6æœˆ18æ—¥æ˜ŸæœŸäºŒä¸Šåˆ11:18å‘å¸ƒï¼š\nä»£ç†è¯„ä¼° ğŸ¤–ï¼šè¯„ä¼°ä»£ç†çš„ç«¯åˆ°ç«¯æ€§èƒ½\n\nå°†LLMé©±åŠ¨çš„è‡ªåŠ¨åŒ–ä»£ç†æŠ•å…¥ç”Ÿäº§å…·æœ‰æŒ‘æˆ˜æ€§ã€‚éšç€æ”¹è¿›çš„å·¥å…·è°ƒç”¨LLMå’Œä»£ç†ç¼–æ’å·¥å…·ï¼Œå¼€å‘äººå‘˜éœ€è¦ç³»ç»Ÿçš„æ–¹æ³•æ¥è¯„ä¼°ä»£ç†æ€§èƒ½ã€‚\n\næˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªæ•™ç¨‹ï¼Œâ€¦",
    "post_content_en": "LangChain (@LangChainAI) posted at 11:18 AM on Tue, Jun 18, 2024:\nAgent evaluations ğŸ¤–: Evaluating an agent's end-to-end performance\n\nProductionizing LLM-powered automated agents is challenging. With improved\ntool-calling LLMs and agent orchestration tools, developers need systematic\nways to evaluate agent performance.\n\nWe've added a tutorial,â€¦",
    "link_lists": [
      "https://t.co/1bhUjNJC1n",
      "https://x.com/LangChainAI/status/1803130164718739573?t=e0Wk2D1cpq0M7CH98raNTg&s=03"
    ],
    "post_summary_cn": "LangChain è®¨è®ºäº†è¯„ä¼° LLM é©±åŠ¨çš„è‡ªåŠ¨åŒ–ä»£ç†çš„ç«¯åˆ°ç«¯æ€§èƒ½ï¼Œå¹¶ä»‹ç»äº†ä¸€ä¸ªæ–°æ•™ç¨‹ã€‚",
    "post_summary_en": "LangChain discusses evaluating the end-to-end performance of LLM-powered automated agents and introduces a new tutorial.",
    "post_datetime": "2024-06-18T23:45:08-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "193c3827ce66e248": {
    "email_id": "193c3827ce66e248",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "ä»¥ä¸‹æ˜¯è¿‘æœŸAIä»£ç†é¢†åŸŸå‘ç”Ÿçš„æ‰€æœ‰äº‹æƒ… ğŸ§µ\n\nï¼ˆæ”¶è—ä»¥å¤‡åç”¨ï¼‰",
    "post_content_en": "Here is everything that has happened recently in the field of AI agents ğŸ§µ\n\n(Save for later use)",
    "link_lists": [
      "https://t.co/GAieNzErQC",
      "https://x.com/FinanceYF5/status/1867777385653055823?t=-VF3zdFhHVkhUsIv_esTeQ&s=03"
    ],
    "post_summary_cn": "æ€»ç»“äº†è¿‘æœŸAIä»£ç†é¢†åŸŸçš„åŠ¨æ€ï¼Œå»ºè®®æ”¶è—ä»¥å¤‡åç”¨ã€‚",
    "post_summary_en": "Summarizes recent developments in the field of AI agents, suggesting to save for later use.",
    "post_datetime": "2024-12-13T20:52:08-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "193c0c0092687f54": {
    "email_id": "193c0c0092687f54",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "Tom DÃ¶rr (@tom_doerr) åœ¨ 2024 å¹´ 12 æœˆ 11 æ—¥æ˜ŸæœŸä¸‰ä¸Šåˆ 11:09 å‘å¸ƒï¼šWren AI æ˜¯ä¸€ä¸ªå¼€æºçš„ SQL AI ä»£ç†ï¼Œå®ƒå°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸º SQL æŸ¥è¯¢ï¼Œé›†æˆäº†å„ç§æ•°æ®åº“å’Œ LLMï¼Œå¹¶æä¾›äº†ç”¨äºæ•°æ®åˆ†æå’ŒæŸ¥è¯¢ç”Ÿæˆçš„ç”¨æˆ·ç•Œé¢ã€‚",
    "post_content_en": "Tom DÃ¶rr (@tom_doerr) posted at 11:09 AM on Wed, Dec 11, 2024: Wren AI is an open-source SQL AI agent that converts natural language questions into SQL queries, integrates with various databases and LLMs, and provides a user interface for data analysis and query generation.",
    "link_lists": [
      "https://t.co/nGehrQTWjk",
      "https://x.com/tom_doerr/status/1866923282081124684?t=QW9PMhOH-UrPYwUTUV0URg&s=03"
    ],
    "post_summary_cn": "Wren AI æ˜¯ä¸€ä¸ªå¼€æºçš„ SQL AI ä»£ç†ï¼Œèƒ½å¤Ÿå°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸º SQL æŸ¥è¯¢ï¼Œå¹¶æä¾›æ•°æ®åˆ†æå’ŒæŸ¥è¯¢ç”Ÿæˆçš„ç”¨æˆ·ç•Œé¢ã€‚",
    "post_summary_en": "Wren AI is an open-source SQL AI agent that converts natural language into SQL queries and provides a user interface for data analysis and query generation.",
    "post_datetime": "2024-12-13T08:00:32-08:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "193bcbdddee5d289": {
    "email_id": "193bcbdddee5d289",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "ä½¿ç”¨DSPyå¾®è°ƒRAGï¼Œè§£é‡Šæ¸…æ¥šã€‚",
    "post_content_en": "Finetuning RAG using DSPy, clearly explained.",
    "link_lists": [
      "https://t.co/MKuLx5Y9hN",
      "https://x.com/DailyDoseOfDS_/status/1867195101002584355?t=1TzYsZRk8CivgPBFniY6XQ&s=03"
    ],
    "post_summary_cn": "ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨DSPyå¾®è°ƒRAGã€‚",
    "post_summary_en": "Explains how to finetune RAG using DSPy.",
    "post_datetime": "2024-12-12T13:19:40-08:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "193b913a081e63aa": {
    "email_id": "193b913a081e63aa",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "Michael Ryan (@michaelryan207) äº 2024å¹´12æœˆ10æ—¥æ˜ŸæœŸäºŒä¸Šåˆ8:34å‘å¸ƒï¼š\nä½¿ç”¨@_rchaves_çš„LangWatchå¯è§†åŒ–æ‚¨çš„è¯­è¨€ç¨‹åºä¼˜åŒ–ï¼\nè¶…çº§é…·çš„ç•Œé¢ï¼Œç”¨äºæŸ¥çœ‹å’Œä¼˜åŒ–è¯­è¨€ç¨‹åºä¸#DSPyï¼\n\nMIPROv2åœ¨å‘å¸ƒè§†é¢‘ä¸­äº®ç›¸ ğŸ‘€",
    "post_content_en": "Michael Ryan (@michaelryan207) posted at 8:34 AM on Tue, Dec 10, 2024:\nVisualize your Language Program Optimization with @_rchaves_â€™s LangWatch!\nSuper cool interface for viewing and optimizing Language Programs with\n#DSPy!\n\nMIPROv2 makes an appearance in the launch video ğŸ‘€",
    "link_lists": [
      "https://x.com/michaelryan207/status/1866521952086823138?t=T0g8-8g-S3S1hJt2zql8iQ&s=03"
    ],
    "post_summary_cn": "Michael Ryanä»‹ç»äº†LangWatchå·¥å…·ï¼Œç”¨äºè¯­è¨€ç¨‹åºä¼˜åŒ–ï¼Œå¹¶æåˆ°MIPROv2åœ¨å‘å¸ƒè§†é¢‘ä¸­äº®ç›¸ã€‚",
    "post_summary_en": "Michael Ryan introduced the LangWatch tool for language program optimization and mentioned MIPROv2 appearing in the launch video.",
    "post_datetime": "2024-11-12T20:14:50-08:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "1939c788ff081e3a": {
    "email_id": "1939c788ff081e3a",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "ä¸Šäº†ä¸€ä¸ª MCP Servers åº”ç”¨å•†åº—ï¼Œæ¬¢è¿æ¥æŸ¥æ‰¾å’Œæäº¤å¥½ç©çš„ MCP Servers",
    "post_content_en": "A MCP Servers app store has been launched, welcome to find and submit fun MCP Servers",
    "link_lists": [
      "https://t.co/uZVqggsjnN",
      "https://x.com/idoubicc/status/1864866694302437503?t=FxEeLb8EArA3-tZsJL71NA&s=03"
    ],
    "post_summary_cn": "MCP Servers åº”ç”¨å•†åº—ä¸Šçº¿ï¼Œæ¬¢è¿æŸ¥æ‰¾å’Œæäº¤æœ‰è¶£çš„ MCP Serversã€‚",
    "post_summary_en": "MCP Servers app store is online, inviting users to find and submit interesting MCP Servers.",
    "post_datetime": "2024-06-12T06:56:07-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "19337a37aa365f6b": {
    "email_id": "19337a37aa365f6b",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "meng shao (@shao__meng) å‘å¸ƒäº 2024å¹´11æœˆ16æ—¥æ˜ŸæœŸå…­å‡Œæ™¨1:21ï¼š\nAI Agents æŠ€æœ¯æ ˆå…¨æ™¯ï¼šä» LLM åˆ° Agents çš„æŠ€æœ¯æ¼”è¿›\n\n// @Letta_AI å›¢é˜Ÿå‘å¸ƒçš„æ·±åº¦åˆ†æï¼ŒAI Agents æ­£ä»ç®€å•çš„ LLM\nåº”ç”¨æ¼”å˜ä¸ºé›†çŠ¶æ€ç®¡ç†ã€å·¥å…·è°ƒç”¨å’Œè‡ªä¸»å†³ç­–äºä¸€ä½“çš„å®Œæ•´æŠ€æœ¯æ ˆï¼Œè¿™ä¸€æ¼”è¿›è¿‡ç¨‹æ­£é‡å¡‘ AI åº”ç”¨çš„å¼€å‘æ¨¡å¼ï¼Œå¹¶å°†æ¨åŠ¨ä¸‹ä¸€ä»£ AI æœåŠ¡çš„æ ‡å‡†åŒ–éƒ¨ç½²\n\n// AI Agents çš„æ¼”è¿›ï¼š\n- 2022-2023",
    "post_content_en": "meng shao (@shao__meng) posted at 1:21 AM on Sat, Nov 16, 2024:\nAI Agents Technology Stack Overview: The Evolution from LLM to Agents\n\n// In-depth analysis released by the @Letta_AI team, AI Agents are evolving from simple LLM applications to a complete technology stack integrating state management, tool invocation, and autonomous decision-making. This evolution is reshaping the development model of AI applications and will drive the standardized deployment of next-generation AI services.\n\n// Evolution of AI Agents:\n- 2022-2023",
    "link_lists": [
      "https://t.co/guBG6CKIZu",
      "https://x.com/shao__meng/status/1857715647217807712?t=AavHyWDG2LcGCamFiLegNw&s=03"
    ],
    "post_summary_cn": "AI Agents æŠ€æœ¯æ ˆæ­£åœ¨ä»ç®€å•çš„ LLM åº”ç”¨æ¼”å˜ä¸ºé›†æˆçŠ¶æ€ç®¡ç†ã€å·¥å…·è°ƒç”¨å’Œè‡ªä¸»å†³ç­–çš„å®Œæ•´æŠ€æœ¯æ ˆï¼Œæ¨åŠ¨ AI åº”ç”¨å¼€å‘æ¨¡å¼çš„å˜é©ã€‚",
    "post_summary_en": "AI Agents technology stack is evolving from simple LLM applications to a complete stack integrating state management, tool invocation, and autonomous decision-making, driving changes in AI application development.",
    "post_datetime": "2024-11-16T17:01:20-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "193378cb0ed494b3": {
    "email_id": "193378cb0ed494b3",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "elvis (@omarsar0) äº 2024å¹´11æœˆ15æ—¥æ˜ŸæœŸäº”ä¸Šåˆ4:30å‘å¸ƒï¼š\nä¸€ç§ç”¨äºå®ç°åŸºç¡€æ¨¡å‹ä»£ç†å¯è§‚å¯Ÿæ€§çš„AgentOpsåˆ†ç±»æ³•\n\næ–°çš„ç ”ç©¶åˆ†æäº†AgentOpså¹³å°å’Œå·¥å…·ï¼Œå¼ºè°ƒäº†éœ€è¦å…¨é¢çš„å¯è§‚å¯Ÿæ€§å’Œå¯è¿½æº¯æ€§åŠŸèƒ½ï¼Œä»¥ç¡®ä¿åŸºç¡€æ¨¡å‹è‡ªä¸»ä»£ç†çš„å¯é æ€§ã€‚",
    "post_content_en": "elvis (@omarsar0) posted at 4:30 AM on Fri, Nov 15, 2024:\nA Taxonomy of AgentOps for Enabling Observability of Foundation Model based Agents\n\nNew research analyzes AgentOps platforms and tools, highlighting the need for comprehensive observability and traceability features to ensure reliability in foundation model-based autonomous agent",
    "link_lists": [
      "https://t.co/pHmey3pcWC",
      "https://x.com/omarsar0/status/1857400667318702118?t=7ZAi5P3KyezavFd_EkQpxw&s=03"
    ],
    "post_summary_cn": "ç ”ç©¶åˆ†æäº†AgentOpså¹³å°å’Œå·¥å…·ï¼Œå¼ºè°ƒäº†åŸºç¡€æ¨¡å‹è‡ªä¸»ä»£ç†éœ€è¦å…¨é¢çš„å¯è§‚å¯Ÿæ€§å’Œå¯è¿½æº¯æ€§åŠŸèƒ½ä»¥ç¡®ä¿å¯é æ€§ã€‚",
    "post_summary_en": "Research analyzes AgentOps platforms and tools, emphasizing the need for comprehensive observability and traceability features to ensure reliability in foundation model-based autonomous agents.",
    "post_datetime": "2024-11-16T16:36:26-08:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "193378b7a8487a78": {
    "email_id": "193378b7a8487a78",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "æç¤ºè¯å·¥ç¨‹å…¨æ™¯å›¾ï¼šAI æç¤ºè¯è®¾è®¡ä¸ç®¡ç†çš„ç³»ç»Ÿæ¡†æ¶\n\nåˆ†äº«çš„æ¡†æ¶å›¾å…¨é¢æ¶µç›–äº†æç¤ºè¯å·¥ç¨‹çš„å„ä¸ªç¯èŠ‚ï¼Œä»è®¾è®¡ã€ä¼˜åŒ–åˆ°éƒ¨ç½²å’Œç»´æŠ¤ï¼Œæ˜¯ä¸€ä¸ªç³»ç»Ÿæ€§çš„æ–¹æ³•è®ºå‚è€ƒï¼Œå¯¹äºæƒ³è¦ç³»ç»Ÿå­¦ä¹ å’Œåº”ç”¨æç¤ºå·¥ç¨‹çš„æœ‹å‹ä»¬æ¥è¯´æ˜¯å¾ˆæœ‰ä»·å€¼çš„æŒ‡å¯¼ã€‚\n\n1. æç¤ºè®¾è®¡(Prompt Design)",
    "post_content_en": "Panorama of Prompt Engineering: A Systematic Framework for AI Prompt Design and Management\n\nThe shared framework diagram comprehensively covers all aspects of prompt engineering, from design, optimization to deployment and maintenance. It serves as a systematic methodological reference, providing valuable guidance for those who wish to systematically learn and apply prompt engineering.\n\n1. Prompt Design",
    "link_lists": [
      "https://t.co/tWyLPjL6JR",
      "https://x.com/shao__meng/status/1857433449298296956?t=84ziroLJ2ApfnPjWerMx5w&s=03"
    ],
    "post_summary_cn": "è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ä¸ªå…¨é¢çš„æç¤ºè¯å·¥ç¨‹æ¡†æ¶ï¼Œæ¶µç›–è®¾è®¡ã€ä¼˜åŒ–ã€éƒ¨ç½²å’Œç»´æŠ¤ç­‰ç¯èŠ‚ï¼Œæ˜¯å­¦ä¹ å’Œåº”ç”¨æç¤ºå·¥ç¨‹çš„æœ‰ä»·å€¼å‚è€ƒã€‚",
    "post_summary_en": "This post introduces a comprehensive framework for prompt engineering, covering design, optimization, deployment, and maintenance, serving as a valuable reference for learning and applying prompt engineering.",
    "post_datetime": "2024-11-16T16:35:07-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "19330972819b334c": {
    "email_id": "19330972819b334c",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "é˜…è¯» Mehul Gupta åœ¨ Medium ä¸Šçš„æ–‡ç« â€œç£æ€§ä¸€å·ã€AutoGenã€LangGraphã€CrewAI æˆ– OpenAI Swarmï¼šå“ªä¸ªå¤š AI ä»£ç†æ¡†æ¶æœ€å¥½ï¼Ÿâ€",
    "post_content_en": "Read â€œMagentic-One, AutoGen, LangGraph, CrewAI, or OpenAI Swarm: Which Multi-AI Agent Framework is Best?â€œ by Mehul Gupta on Medium:",
    "link_lists": [
      "https://medium.com/data-science-in-your-pocket/magentic-one-autogen-langgraph-crewai-or-openai-swarm-which-multi-ai-agent-framework-is-best-6629d8bd9509"
    ],
    "post_summary_cn": "Mehul Gupta åœ¨ Medium ä¸Šè®¨è®ºäº†å¤š AI ä»£ç†æ¡†æ¶çš„æ¯”è¾ƒã€‚",
    "post_summary_en": "Mehul Gupta discusses a comparison of multi-AI agent frameworks on Medium.",
    "post_datetime": "2024-11-15T08:10:31-08:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "1932deb53555c3b8": {
    "email_id": "1932deb53555c3b8",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "Harrison Chase (@hwchase17) äº 2024å¹´11æœˆ14æ—¥æ˜ŸæœŸå››ä¸‹åˆ1:14å‘å¸ƒï¼š\né¡¶çº§ä»£ç†ä½¿ç”¨æ¡ˆä¾‹ï¼š\n\n- ç ”ç©¶å’Œæ€»ç»“\n- ä¸ªäººåŠ©ç†\n- å®¢æˆ·æœåŠ¡\n- ä»£ç ç”Ÿæˆ\n\næœ‰è¶£çš„æ˜¯ï¼Œå¤§å¤šæ•°æ–°å…´çš„ä»£ç†åˆåˆ›å…¬å¸ä¼¼ä¹é›†ä¸­åœ¨å®¢æˆ·æœåŠ¡å’Œç¼–ç é¢†åŸŸã€‚",
    "post_content_en": "Harrison Chase (@hwchase17) posted at 1:14 PM on Thu, Nov 14, 2024:\nTop agent use cases:\n\n- research and summarization\n- personal assistant\n- customer service\n- code gen\n\ninteresting that most agent startups popping up seem to be in customer service and coding",
    "link_lists": [
      "https://t.co/4oqJmPNBj3",
      "https://t.co/lbRa1PRCEE",
      "https://x.com/hwchase17/status/1857170293061742743?t=3bVDdniynzynGTo4GkNNuw&s=03"
    ],
    "post_summary_cn": "Harrison Chase è®¨è®ºäº†ä»£ç†çš„ä¸»è¦ä½¿ç”¨æ¡ˆä¾‹ï¼ŒåŒ…æ‹¬ç ”ç©¶ã€ä¸ªäººåŠ©ç†ã€å®¢æˆ·æœåŠ¡å’Œä»£ç ç”Ÿæˆï¼Œå¹¶æŒ‡å‡ºå¤§å¤šæ•°æ–°å…´å…¬å¸é›†ä¸­åœ¨å®¢æˆ·æœåŠ¡å’Œç¼–ç é¢†åŸŸã€‚",
    "post_summary_en": "Harrison Chase discusses top agent use cases such as research, personal assistant, customer service, and code generation, noting that most emerging startups focus on customer service and coding.",
    "post_datetime": "2024-11-14T19:43:36-08:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "1932bb33822de5e4": {
    "email_id": "1932bb33822de5e4",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "å‘Šåˆ« RPA: æ™ºèƒ½è‡ªåŠ¨åŒ–çš„æ–°çºªå…ƒ\nä½œè€… - @kimberlywtan(@a16z)\n\néšç€ AI æŠ€æœ¯çš„æˆç†Ÿï¼Œç‰¹åˆ«æ˜¯ LLM çš„å‡ºç°ï¼Œæ–°ä¸€ä»£æ™ºèƒ½è‡ªåŠ¨åŒ–æ­£åœ¨å–ä»£ä¼ ç»Ÿçš„ RPA æµç¨‹è‡ªåŠ¨åŒ–å·¥å…·ï¼Œè¿™ä¸ä»…èƒ½çœŸæ­£å®ç°ä¼ä¸šå†…éƒ¨è¿è¥çš„å…¨é¢è‡ªåŠ¨åŒ–ï¼Œæ›´å¼€åˆ›äº†ä¸€ä¸ªä¼°å€¼è¶…è¿‡2500äº¿ç¾å…ƒçš„å…¨æ–°åˆ›ä¸šè“æµ·å¸‚åœº\n\nä¼ ç»Ÿ RPA çš„å±€é™æ€§\n- è™½ç„¶åƒ UiPath",
    "post_content_en": "Farewell to RPA: A New Era of Intelligent Automation\nAuthor - @kimberlywtan(@a16z)\n\nWith the maturity of AI technology, especially the emergence of LLM, a new generation of intelligent automation is replacing traditional RPA process automation tools. This not only truly realizes comprehensive automation of internal enterprise operations but also creates a new entrepreneurial blue ocean market valued at over $250 billion.\n\nLimitations of traditional RPA\n- Although like UiPath",
    "link_lists": [
      "https://t.co/xX72THYqj7",
      "https://x.com/shao__meng/status/1856839145412596001?t=54tsROvBBai9YvjKWLMgWA&s=03"
    ],
    "post_summary_cn": "éšç€ AI æŠ€æœ¯çš„è¿›æ­¥ï¼ŒLLM çš„å‡ºç°æ­£åœ¨å–ä»£ä¼ ç»Ÿ RPAï¼Œæ¨åŠ¨ä¼ä¸šå…¨é¢è‡ªåŠ¨åŒ–ï¼Œå¹¶åˆ›é€ äº†ä¸€ä¸ªæ–°çš„å¸‚åœºæœºä¼šã€‚",
    "post_summary_en": "With advancements in AI technology, the emergence of LLM is replacing traditional RPA, driving comprehensive enterprise automation and creating a new market opportunity.",
    "post_datetime": "2024-11-14T09:23:05-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1931cdfadb549992": {
    "email_id": "1931cdfadb549992",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 8:09 AM on Sun, Nov 10, 2024:\nRD-Agent: å¾®è½¯å¼€æºçš„ç ”å‘è‡ªåŠ¨åŒ–å·¥å…·, ä¸“æ³¨äºæ•°æ®é©±åŠ¨çš„ AI ç ”å‘æµç¨‹, ç”¨ AI æ¥è‡ªåŠ¨åŒ– AI ç›¸å…³çš„ç ”å‘å·¥ä½œ\n\n# æ ¸å¿ƒæ¡†æ¶ç»„æˆ\n- \"R\"(Research)æ¨¡å—: è´Ÿè´£æå‡ºæ–°æƒ³æ³•\n- \"D\"(Development)æ¨¡å—: è´Ÿè´£å®ç°è¿™äº›æƒ³æ³•\n- æ”¯æŒæŒç»­è¿›åŒ–: é€šè¿‡åé¦ˆä¸æ–­æ”¹è¿›æ€§èƒ½\n\n# ä¸»è¦åº”ç”¨åœºæ™¯\n- ğŸ¤– æ•°æ®æŒ–æ˜Agent",
    "post_content_en": "meng shao (@shao__meng) posted at 8:09 AM on Sun, Nov 10, 2024:\nRD-Agent: Microsoft's open-source R&D automation tool, focusing on data-driven AI R&D processes, using AI to automate AI-related R&D work\n\n# Core Framework Components\n- \"R\"(Research) module: Responsible for proposing new ideas\n- \"D\"(Development) module: Responsible for implementing these ideas\n- Supports continuous evolution: Constantly improving performance through feedback\n\n# Main Application Scenarios\n- ğŸ¤– Data Mining Agent",
    "link_lists": [
      "https://t.co/SfeEwdtND4",
      "https://x.com/shao__meng/status/1855643962679472215?t=_ZstkgKp4YLmBR1AOR7EWQ&s=03"
    ],
    "post_summary_cn": "å¾®è½¯å¼€æºçš„ç ”å‘è‡ªåŠ¨åŒ–å·¥å…·RD-Agentï¼Œä¸“æ³¨äºæ•°æ®é©±åŠ¨çš„AIç ”å‘æµç¨‹ï¼ŒåŒ…å«ç ”ç©¶å’Œå¼€å‘æ¨¡å—ï¼Œæ”¯æŒæŒç»­è¿›åŒ–ã€‚ä¸»è¦åº”ç”¨äºæ•°æ®æŒ–æ˜ã€‚",
    "post_summary_en": "Microsoft's open-source R&D automation tool RD-Agent focuses on data-driven AI R&D processes, including research and development modules, supporting continuous evolution. Mainly applied in data mining.",
    "post_datetime": "2024-11-11T12:17:22-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1931a68971305413": {
    "email_id": "1931a68971305413",
    "post_labels": [
      "LLM",
      "agent"
    ],
    "post_content_cn": "#AI #æ•°å­—äºº å®æ—¶è¯­éŸ³äº¤äº’æ•°å­—äººï¼Œæ”¯æŒç«¯åˆ°ç«¯è¯­éŸ³æ–¹æ¡ˆï¼ˆGLM-4-Voice - THGï¼‰å’Œçº§è”æ–¹æ¡ˆï¼ˆASR-LLM-TTS-THGï¼‰ã€‚å¯è‡ªå®šä¹‰å½¢è±¡ä¸éŸ³è‰²ï¼Œæ— é¡»è®­ç»ƒï¼Œæ”¯æŒéŸ³è‰²å…‹éš†ï¼Œé¦–åŒ…å»¶è¿Ÿä½è‡³3s",
    "post_content_en": "#AI #DigitalHuman Real-time voice interaction digital human, supporting end-to-end voice solutions (GLM-4-Voice - THG) and cascade solutions (ASR-LLM-TTS-THG). Customizable appearance and voice, no training required, supports voice cloning, with initial packet delay as low as 3s",
    "link_lists": [
      "https://t.co/8TjVCQzxjV",
      "https://x.com/liangwenhao3/status/1855656585072177364?t=s45_eqfjOD2qBsySS38kbA&s=03"
    ],
    "post_summary_cn": "ä»‹ç»äº†ä¸€ç§æ”¯æŒç«¯åˆ°ç«¯å’Œçº§è”è¯­éŸ³æ–¹æ¡ˆçš„å®æ—¶è¯­éŸ³äº¤äº’æ•°å­—äººï¼Œå…·æœ‰è‡ªå®šä¹‰å’ŒéŸ³è‰²å…‹éš†åŠŸèƒ½ã€‚",
    "post_summary_en": "Introduces a real-time voice interaction digital human supporting end-to-end and cascade voice solutions, with customizable and voice cloning features.",
    "post_datetime": "2024-11-11T00:48:03-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "19309ff5d98bffba": {
    "email_id": "19309ff5d98bffba",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "LLM æ™ºèƒ½ Agent: æ„å»ºå…·æœ‰æŒä¹…è®°å¿†çš„ AI ç³»ç»Ÿ\n# æŒæ¡å¦‚ä½•è®© AI Agent åƒæ“ä½œç³»ç»Ÿèˆ¬æ™ºèƒ½ç®¡ç†è®°å¿†, ä»è€Œæ„å»ºèƒ½æŒç»­å­¦ä¹ ã€è‡ªä¸»å†³ç­–çš„ä¸‹ä¸€ä»£ LLM åº”ç”¨\n@DeepLearningAI x @Letta_AI\n# è¯¾ç¨‹è®²å¸ˆ: @charlespacker @sarahwooders\n\n# ä¸»è¦å­¦ä¹ å†…å®¹\n- å­¦ä¹ å¦‚ä½•æ„å»ºå…·æœ‰é•¿æœŸã€æŒä¹…æ€§è®°å¿†çš„ Agent\n- äº†è§£å¦‚ä½•å°†",
    "post_content_en": "LLM Intelligent Agent: Building AI systems with persistent memory\n# Learn how to make AI Agents manage memory intelligently like an operating system, thereby building the next generation of LLM applications that can continuously learn and make autonomous decisions\n@DeepLearningAI x @Letta_AI\n# Course instructors: @charlespacker @sarahwooders\n\n# Main learning content\n- Learn how to build agents with long-term, persistent memory\n- Understand how to",
    "link_lists": [
      "https://t.co/P0Q5aGUNCg",
      "https://x.com/shao__meng/status/1854673617898160297?t=rTUcYTD-Uk1OqE2pG4RYzg&s=03"
    ],
    "post_summary_cn": "ä»‹ç»äº†å¦‚ä½•æ„å»ºå…·æœ‰æŒä¹…è®°å¿†çš„ LLM æ™ºèƒ½ Agentï¼Œè¯¾ç¨‹ç”± @DeepLearningAI å’Œ @Letta_AI æä¾›ï¼Œè®²å¸ˆåŒ…æ‹¬ @charlespacker å’Œ @sarahwoodersã€‚",
    "post_summary_en": "Introduces how to build LLM intelligent agents with persistent memory, offered by @DeepLearningAI and @Letta_AI, with instructors @charlespacker and @sarahwooders.",
    "post_datetime": "2024-08-11T04:19:10+00:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192facf148e7279f": {
    "email_id": "192facf148e7279f",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "AFLOWçš„ä»£ç æ€»ç®—æ˜¯å¼€æºäº†ï¼Œæ‰‹åŠ¨å·¥ä½œæµå˜è‡ªåŠ¨æ™ºèƒ½å·¥ä½œæµçš„ç¥å™¨",
    "post_content_en": "The code for AFLOW has finally been open-sourced, a magic tool for transforming manual workflows into automated intelligent workflows.",
    "link_lists": [
      "https://t.co/gPJJg8T8tV",
      "https://t.co/HJ2jLZBXaK",
      "https://x.com/aigclink/status/1853617774901551395?t=CM0vmGkrkh9p2VckZGiMSA&s=03"
    ],
    "post_summary_cn": "AFLOWä»£ç å¼€æºï¼Œæå‡å·¥ä½œæµè‡ªåŠ¨åŒ–å’Œæ™ºèƒ½åŒ–ã€‚",
    "post_summary_en": "AFLOW code is open-sourced, enhancing workflow automation and intelligence.",
    "post_datetime": "2024-05-11T05:58:00+00:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192b7826e44c98d1": {
    "email_id": "192b7826e44c98d1",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "Dify å‘å¸ƒäº† NotebookLM å·¥ä½œæµï¼å¼€å‘è€…ç›´æ¥ Copyï¼Œä¸ç”¨é‡å¤åŠ³åŠ¨äº† ğŸ˜‚",
    "post_content_en": "Dify has released the NotebookLM workflow! Developers can directly copy without repeated labor ğŸ˜‚",
    "link_lists": [
      "https://x.com/oran_ge/status/1848928586264416551?t=9cL3hXhm7ko9RnEZSizveg&s=03"
    ],
    "post_summary_cn": "Dify å‘å¸ƒäº†æ–°çš„ NotebookLM å·¥ä½œæµï¼Œç®€åŒ–äº†å¼€å‘è€…çš„å·¥ä½œã€‚",
    "post_summary_en": "Dify released a new NotebookLM workflow, simplifying developers' work.",
    "post_datetime": "2024-10-22T20:53:50-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192b260433731315": {
    "email_id": "192b260433731315",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "ä»æ–°æ‰‹åˆ°ä¸“å®¶: 12 æ­¥æŒæ¡ AI Agent å¼€å‘\n\næ–‡ç« æä¾›äº†ä¸€ä¸ªå…¨é¢çš„ AI Agent å­¦ä¹ è·¯å¾„, æ¶µç›–ä»ç”Ÿæˆå¼ AI åŸºç¡€åˆ°é«˜çº§ Agentic RAG ç³»ç»Ÿçš„ 12ä¸ªå…³é”®æ­¥éª¤ã€‚å®ƒä¸ºè¯»è€…æä¾›äº†ç†è®ºçŸ¥è¯†å’Œå®è·µæŒ‡å¯¼, åŒ…æ‹¬ç¼–ç¨‹åŸºç¡€ã€å¤§è¯­è¨€æ¨¡å‹ã€æç¤ºå·¥ç¨‹ã€å„ç§æ¡†æ¶çš„ä½¿ç”¨ï¼Œä»¥åŠä»æ— ä»£ç å·¥å…·åˆ° Pythonç¼–ç¨‹çš„å®é™…å¼€å‘ç»éªŒã€‚",
    "post_content_en": "From novice to expert: 12 steps to master AI Agent development\n\nThe article provides a comprehensive AI Agent learning path, covering 12 key steps from generative AI basics to advanced Agentic RAG systems. It offers readers theoretical knowledge and practical guidance, including programming basics, large language models, prompt engineering, the use of various frameworks, and practical development experience from no-code tools to Python programming.",
    "link_lists": [
      "https://t.co/6M7RymhsKh",
      "https://x.com/shao__meng/status/1848308814715437317?t=5-2xeS5KJ5Hx3jemYGO0Ww&s=03"
    ],
    "post_summary_cn": "æ–‡ç« ä»‹ç»äº†ä»åŸºç¡€åˆ°é«˜çº§çš„ AI Agent å¼€å‘çš„ 12 ä¸ªæ­¥éª¤ï¼Œæä¾›ç†è®ºå’Œå®è·µæŒ‡å¯¼ã€‚",
    "post_summary_en": "The article outlines 12 steps from basic to advanced AI Agent development, providing theoretical and practical guidance.",
    "post_datetime": "2024-10-21T20:58:27-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192b25ffe5cadfcb": {
    "email_id": "192b25ffe5cadfcb",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "å®å®‡å¼ @ZJU (@zxlzr) äº 2024å¹´10æœˆ20æ—¥æ˜ŸæœŸæ—¥ä¸Šåˆ9:12å‘å¸ƒï¼š\nä»‹ç»æˆ‘ä»¬çš„æœ€æ–°è®ºæ–‡ï¼Œâ€œåŸºå‡†ä»£ç†å·¥ä½œæµç”Ÿæˆâ€ï¼ğŸš€\n\nArXiv: \n\nç½‘ç«™: \n\næ•°æ®: \n\nGithub: \n\nğŸ§  å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åˆ†è§£ä¸­èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨",
    "post_content_en": "Ningyu Zhang@ZJU (@zxlzr) posted at 9:12 AM on Sun, Oct 20, 2024:\nIntroducing our latest paper, \"Benchmarking Agentic Workflow Generation\"! ğŸš€\n\nArXiv: \n\nWebsite: \n\nData: \n\nGithub: \n\nğŸ§  Large Language Models (LLMs) play a crucial role in breaking down",
    "link_lists": [
      "https://t.co/WtzU8Ep87A",
      "https://t.co/71cauFyyYJ",
      "https://t.co/qlWNnNPA9D",
      "https://t.co/fNGNGYjJUu",
      "https://t.co/nYLGmb3NOh",
      "https://x.com/zxlzr/status/1848034469506330759?t=0cEg2uWx_N3z_rnnZcNGbw&s=03"
    ],
    "post_summary_cn": "å®å®‡å¼ ä»‹ç»äº†ä»–ä»¬çš„æœ€æ–°è®ºæ–‡â€œåŸºå‡†ä»£ç†å·¥ä½œæµç”Ÿæˆâ€ï¼Œå¹¶å¼ºè°ƒå¤§å‹è¯­è¨€æ¨¡å‹åœ¨åˆ†è§£ä¸­çš„é‡è¦ä½œç”¨ã€‚",
    "post_summary_en": "Ningyu Zhang introduces their latest paper \"Benchmarking Agentic Workflow Generation\" and highlights the crucial role of Large Language Models in breaking down tasks.",
    "post_datetime": "2024-10-21T20:58:09-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "192a239e70ff38c7": {
    "email_id": "192a239e70ff38c7",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "elvis (@omarsar0) äº 2024å¹´10æœˆ17æ—¥æ˜ŸæœŸå››ä¸Šåˆ8:05å‘å¸ƒï¼š\nAgent S æ˜¯ä¸€ä¸ªæ–°çš„å¼€æ”¾ä»£ç†æ¡†æ¶ï¼Œé€šè¿‡ GUI å®ç°ä¸è®¡ç®—æœºçš„è‡ªä¸»äº¤äº’ã€‚\nAgent S è§£å†³äº†è·å–çŸ¥è¯†ã€è§„åˆ’é•¿ä»»åŠ¡å‘¨æœŸä»¥åŠå¤„ç†åŠ¨æ€ç•Œé¢ç­‰æŒ‘æˆ˜ã€‚\nå®ƒå¼•å…¥äº†ç»éªŒå¢å¼ºçš„åˆ†å±‚ç»“æ„ã€‚",
    "post_content_en": "elvis (@omarsar0) posted at 8:05 AM on Thu, Oct 17, 2024:\nAgent S is a new open agentic framework that enables autonomous interaction with computers through a GUI.\nAgent S tackles challenges such as acquiring knowledge, planning over long-task horizons, and handling dynamic interfaces.\nIt introduces experience-augmented hierarchical",
    "link_lists": [
      "https://t.co/EMisz54euk",
      "https://x.com/omarsar0/status/1846930425849303424?t=VjOHRe_EG_x4A6p0Ht7TLw&s=03"
    ],
    "post_summary_cn": "Agent S æ˜¯ä¸€ä¸ªæ–°çš„å¼€æ”¾ä»£ç†æ¡†æ¶ï¼Œèƒ½å¤Ÿé€šè¿‡ GUI å®ç°ä¸è®¡ç®—æœºçš„è‡ªä¸»äº¤äº’ï¼Œè§£å†³çŸ¥è¯†è·å–ã€é•¿ä»»åŠ¡è§„åˆ’å’ŒåŠ¨æ€ç•Œé¢å¤„ç†ç­‰æŒ‘æˆ˜ã€‚",
    "post_summary_en": "Agent S is a new open agentic framework that enables autonomous interaction with computers through a GUI, addressing challenges like knowledge acquisition, long-term planning, and dynamic interface handling.",
    "post_datetime": "2024-10-18T17:42:36-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "192932fe9e25be66": {
    "email_id": "192932fe9e25be66",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "æˆ‘è®¤ä¸ºswarmè¿˜æ²¡æœ‰ä¸€ä¸ªUIç•Œé¢ï¼Œä¸€æ—¦åšå¥½äº†è¿™æ ·çš„äº¤äº’ï¼Œæ™®é€šç”¨æˆ·å…¶å®é è‡ªç„¶è¯­è¨€å°±èƒ½åšæˆä¸€ç¾¤Agentã€‚è€Œä¸”ä¸éœ€è¦æ‹–æ‹–æ”¾æ”¾ã€‚ä¼šæ›´åŠ çš„ç®€å•ã€‚ä¸€å¥è¯ï¼šLLM-based Agent will eat Rule-based Agent.",
    "post_content_en": "I think swarm does not yet have a UI interface. Once such interaction is completed, ordinary users can actually create a group of Agents using natural language. Moreover, there is no need for drag and drop. It will be simpler. In short: LLM-based Agent will eat Rule-based Agent.",
    "link_lists": [
      "https://x.com/JefferyTatsuya/status/1846073241619910656?t=jUcp_bYxBrzTeakGvFNCVQ&s=03"
    ],
    "post_summary_cn": "è®¨è®ºäº†swarmç¼ºä¹UIç•Œé¢ï¼Œæœªæ¥é€šè¿‡è‡ªç„¶è¯­è¨€å¯ä»¥æ›´ç®€å•åœ°åˆ›å»ºAgentã€‚",
    "post_summary_en": "Discussed the lack of a UI for swarm and how natural language can simplify creating Agents in the future.",
    "post_datetime": "2024-10-15T19:37:25-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1929325d0bd814d6": {
    "email_id": "1929325d0bd814d6",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 3:27 AM on Tue, Oct 15, 2024:\n# OpenAI o1 å¯èƒ½æ”¹å˜ AI Agent æ¶æ„æ–¹å¼\n\næ„Ÿè°¢ @JefferyTatsuya åˆ†äº«çš„è¿™ç¯‡æ–‡ç« , æ¢è®¨äº†ä¸€ç§æ–°çš„ AI Agent æ¶æ„, å®ƒåˆ©ç”¨äº† OpenAI o1 æ¨¡å‹çš„å¼ºå¤§èƒ½åŠ›,\nä¸ºä¼ä¸šå†³ç­–å’Œå¤æ‚é—®é¢˜è§£å†³æä¾›æ–°çš„æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•ç»“åˆäº†è‡ªåŠ¨åŒ–çš„æ•ˆç‡å’Œäººç±»æ™ºæ…§çš„çµæ´»æ€§, å¯èƒ½å¯¹æœªæ¥çš„ AI åº”ç”¨äº§ç”Ÿé‡å¤§å½±å“ã€‚",
    "post_content_en": "meng shao (@shao__meng) posted at 3:27 AM on Tue, Oct 15, 2024:\n# OpenAI o1 may change the architecture of AI Agents\n\nThanks to @JefferyTatsuya for sharing this article, which explores a new AI Agent architecture that leverages the powerful capabilities of the OpenAI o1 model,\nproviding new methods for enterprise decision-making and complex problem-solving. This approach combines the efficiency of automation with the flexibility of human intelligence, potentially having a significant impact on future AI applications.",
    "link_lists": [
      "https://t.co/vbwX59bXjB",
      "https://x.com/shao__meng/status/1846135706923814975?t=vtv3RTzdS4tf_mi82BXytQ&s=03"
    ],
    "post_summary_cn": "æ–‡ç« æ¢è®¨äº†åˆ©ç”¨ OpenAI o1 æ¨¡å‹çš„æ–° AI Agent æ¶æ„ï¼Œç»“åˆè‡ªåŠ¨åŒ–å’Œäººç±»æ™ºæ…§ï¼Œå¯èƒ½å¯¹æœªæ¥ AI åº”ç”¨äº§ç”Ÿé‡å¤§å½±å“ã€‚",
    "post_summary_en": "The article discusses a new AI Agent architecture using the OpenAI o1 model, combining automation and human intelligence, potentially impacting future AI applications.",
    "post_datetime": "2024-10-15T19:26:23-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1928e0d75a3a86bd": {
    "email_id": "1928e0d75a3a86bd",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "AutoGen å®ç° Handoff Multi-Agents @pyautogen\n\nHandoff æ¨¡å¼çš„æ ¸å¿ƒæ€æƒ³æ˜¯å…è®¸ Agents å°†ä»»åŠ¡å§”æ‰˜ç»™å…¶ä»– Agents, ä½¿ç”¨ç‰¹æ®Šçš„å·¥å…·è°ƒç”¨æ¥å®ç°, ä½¿ç”¨ AutoGen Core API æ¥å®ç° Handoff æ¨¡å¼, å‘æŒ¥ AutoGen å¯æ‰©å±•æ€§ã€çµæ´»æ€§å’Œæ˜“äºé›†æˆçš„ä¼˜åŠ¿ã€‚\n\n# å®ç°æ€æƒ³:\n- Multi-Agents åä½œ: ",
    "post_content_en": "AutoGen implements Handoff Multi-Agents @pyautogen\n\nThe core idea of the Handoff mode is to allow agents to delegate tasks to other agents, implemented using special tool calls, and to use the AutoGen Core API to realize the Handoff mode, leveraging the advantages of AutoGen's scalability, flexibility, and ease of integration.\n\n# Implementation Ideas:\n- Multi-Agents Collaboration: ",
    "link_lists": [
      "https://t.co/StuAo9LoSP",
      "https://x.com/shao__meng/status/1845991257161847071?t=_rWqa2qoE2mTzlbc0eZhCw&s=03"
    ],
    "post_summary_cn": "AutoGen çš„ Handoff æ¨¡å¼å…è®¸ä»£ç†å°†ä»»åŠ¡å§”æ‰˜ç»™å…¶ä»–ä»£ç†ï¼Œåˆ©ç”¨ AutoGen Core API å®ç°ï¼Œå…·æœ‰å¯æ‰©å±•æ€§å’Œçµæ´»æ€§ã€‚",
    "post_summary_en": "AutoGen's Handoff mode allows agents to delegate tasks to others using the AutoGen Core API, offering scalability and flexibility.",
    "post_datetime": "2024-10-14T19:41:40-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192223a50551b17f": {
    "email_id": "192223a50551b17f",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "GenAI Agents å¼€å‘çš„ç»¼åˆæ€§èµ„æºï¼Œæ¶µç›–äº†ä»åŸºç¡€åˆ°é«˜çº§çš„å„ç§ç†è®ºç»“åˆå®ç°çš„å¼€æºé¡¹ç›®ã€‚\n\nä¸»è¦ç‰¹ç‚¹ï¼š\n- æä¾›å„ç§éš¾åº¦çº§åˆ«çš„ GenAI Agents æ„å»ºæ•™ç¨‹\n- æ¢ç´¢å¤šç§ Agents æ¶æ„å’Œåº”ç”¨\n- åŒ…å«å®ç”¨çš„ã€éšæ—¶å¯ç”¨çš„ Agents å®ç°\n- å®šæœŸæ›´æ–°æœ€æ–°çš„ GenAI è¿›å±•",
    "post_content_en": "GenAI Agents is a comprehensive resource developed to cover open-source projects that combine theory and implementation from basic to advanced levels.\n\nMain features:\n- Provides tutorials for building GenAI Agents at various difficulty levels\n- Explores various Agents architectures and applications\n- Includes practical, ready-to-use Agents implementations\n- Regularly updates the latest GenAI developments",
    "link_lists": [
      "https://t.co/3f1z0Ak1ST",
      "https://x.com/shao__meng/status/1838130687322566699?t=wtqigjMDrdZvBz4GY64nbw&s=03"
    ],
    "post_summary_cn": "GenAI Agents æä¾›ä»åŸºç¡€åˆ°é«˜çº§çš„å¼€æºé¡¹ç›®èµ„æºï¼ŒåŒ…å«æ•™ç¨‹ã€æ¶æ„æ¢ç´¢ã€å®ç”¨å®ç°å’Œæœ€æ–°è¿›å±•æ›´æ–°ã€‚",
    "post_summary_en": "GenAI Agents offers resources for open-source projects from basic to advanced, including tutorials, architecture exploration, practical implementations, and updates on the latest developments.",
    "post_datetime": "2024-09-23T21:11:41-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "191636db3be1214e": {
    "email_id": "191636db3be1214e",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "ä¸€æ¬¾è½»é‡çº§ã€ç»“åˆLLMè¿›è¡Œç½‘é¡µæ•°æ®æŠ“å–çš„å·¥å…·ï¼šparsera\n\næ”¯æŒå¤šç§ LLM\næ”¯æŒæå–å¤šç§ç±»å‹æ–‡æœ¬æ•°æ®\nä½¿ç”¨LLMè¯†åˆ«æ‰€éœ€æå–çš„ä¿¡æ¯",
    "post_content_en": "A lightweight tool for web data extraction combined with LLM: parsera\n\nSupports multiple LLMs\nSupports extraction of various types of text data\nUses LLM to identify the information to be extracted",
    "link_lists": [
      "https://t.co/7RWmke3Of2",
      "https://t.co/qFWst9lFjx",
      "https://x.com/aigclink/status/1824985974323229166?t=aSV0TwYqP7TaBJh59Vqlqw&s=03"
    ],
    "post_summary_cn": "ä»‹ç»äº†ä¸€æ¬¾ç»“åˆLLMçš„ç½‘é¡µæ•°æ®æŠ“å–å·¥å…·parseraï¼Œæ”¯æŒå¤šç§LLMå’Œå¤šç§æ–‡æœ¬æ•°æ®æå–ã€‚",
    "post_summary_en": "Introduces a web data extraction tool called parsera combined with LLM, supporting multiple LLMs and various text data extraction.",
    "post_datetime": "2024-08-17T20:00:19-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "19163247db47eef3": {
    "email_id": "19163247db47eef3",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "å¤šæ¨¡æ€æŠ¥å‘Šç”Ÿæˆ AI Agent @llama_index\n\nLlamaIndex å…³äºå¤šæ¨¡æ€æ¨¡å‹çš„ Cookbookï¼Œå±•ç¤ºäº†å¦‚ä½•ä»ä¸€ç»„ç ”ç©¶æŠ¥å‘Šåº“ä¸­æ„å»ºä¸€ä¸ªå¤šæ¨¡æ€æŠ¥å‘Šç”Ÿæˆ AI Agentï¼Œä½œè€…æ˜¯\nLlamaIndex åˆ›å§‹äºº Jerry Liu @jerryjliu0\n\nä½œè€…ä½¿ç”¨äº†ä¸€ç»„ ICLR è®ºæ–‡ï¼Œå€ŸåŠ© Llama-Parse å·¥ä½œæµæŠ½è±¡æ¥å®šä¹‰ä¸€ä¸ª Agent",
    "post_content_en": "Multimodal report generation AI Agent @llama_index\n\nThe Cookbook on multimodal models by LlamaIndex demonstrates how to build a multimodal report generation AI Agent from a library of research reports, authored by LlamaIndex founder Jerry Liu @jerryjliu0\n\nThe author used a set of ICLR papers and leveraged the Llama-Parse workflow abstraction to define an Agent",
    "link_lists": [
      "https://t.co/CdQfHezrDU",
      "https://x.com/shao__meng/status/1824601351621578896?t=NNh-IiU5nr4RvUp07tafQA&s=03"
    ],
    "post_summary_cn": "LlamaIndex çš„ Cookbook ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨ ICLR è®ºæ–‡å’Œ Llama-Parse å·¥ä½œæµæ„å»ºå¤šæ¨¡æ€æŠ¥å‘Šç”Ÿæˆ AI Agentã€‚",
    "post_summary_en": "The LlamaIndex Cookbook explains how to use ICLR papers and the Llama-Parse workflow to build a multimodal report generation AI Agent.",
    "post_datetime": "2024-08-17T18:40:21-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "19114965b27eb33b": {
    "email_id": "19114965b27eb33b",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "å°äº’ (@imxiaohu) posted at 6:51 AM on Fri, Aug 02, 2024:\nMindSearchï¼šèƒ½å¤Ÿæ¨¡ä»¿äººç±»åœ¨ç½‘ç»œä¸Šå¯»æ‰¾å’Œæ•´åˆä¿¡æ¯çš„AIæœç´¢å¼•æ“\n\nMindSearchèƒ½å¤Ÿåœ¨3åˆ†é’Ÿå†…ä»è¶…è¿‡300ä¸ªç½‘é¡µä¸­æ”¶é›†å’Œæ•´åˆä¿¡æ¯ï¼Œè¿™ç›¸å½“äºäººç±»ä¸“å®¶å¤§çº¦3å°æ—¶çš„å·¥ä½œé‡ã€‚\n\nåœ¨æ·±åº¦ã€å¹¿åº¦å’Œç”Ÿæˆå“åº”çš„å‡†ç¡®æ€§ä¸‰ä¸ªæ–¹é¢ï¼Œå…¶åœ¨äººç±»ä¸“å®¶è¯„ä¼°ä¸­éƒ½è¶…è¶Šäº†ï¼› Perplexity AIå’Œ ChatGPTã€‚",
    "post_content_en": "Xiao Hu (@imxiaohu) posted at 6:51 AM on Fri, Aug 02, 2024:\nMindSearch: An AI search engine capable of mimicking human information search and integration on the internet.\n\nMindSearch can collect and integrate information from over 300 web pages in 3 minutes, equivalent to about 3 hours of work by a human expert.\n\nIn terms of depth, breadth, and accuracy of generated responses, it surpasses Perplexity AI and ChatGPT in human expert evaluations.",
    "link_lists": [
      "https://t.co/xIPzlIgCb0",
      "https://x.com/imxiaohu/status/1819370552848761191?t=2MXWmCp_sbP2DJrJjZP5uA&s=03"
    ],
    "post_summary_cn": "MindSearchæ˜¯ä¸€ç§AIæœç´¢å¼•æ“ï¼Œèƒ½å¤Ÿåœ¨çŸ­æ—¶é—´å†…ä»å¤§é‡ç½‘é¡µä¸­æ”¶é›†ä¿¡æ¯ï¼Œå…¶æ€§èƒ½åœ¨å¤šä¸ªæ–¹é¢è¶…è¶Šäº†å…¶ä»–AIå·¥å…·ã€‚",
    "post_summary_en": "MindSearch is an AI search engine that can quickly gather information from numerous web pages, outperforming other AI tools in several aspects.",
    "post_datetime": "2024-02-08T12:34:44-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "190e1066baa11125": {
    "email_id": "190e1066baa11125",
    "post_labels": [
      "LLM",
      "agent"
    ],
    "post_content_cn": "ä¸€ä¸ªçµæ´»æ˜“ç”¨çš„ LLM è·¯ç”±æ¡†æ¶ï¼šRouteLLM\nRouteLLMè§£å†³äº†å¤§æ¨¡å‹æ€§èƒ½å¼ºä»·æ ¼è´µï¼Œä»·æ ¼ä¾¿å®œä½†æ€§èƒ½å¼±çš„é—®é¢˜ï¼Œå…¶èƒ½å¤Ÿåœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€é€‰æ‹©æ›´å¼ºæˆ–æ›´å¼±çš„LLMï¼Œåšåˆ°é™ä½æˆæœ¬çš„åŒæ—¶ä¸å½±å“è´¨é‡\n\nåœ¨MT BenchåŸºå‡†ä¸Šæˆæœ¬é™ä½ 85%ï¼ŒåŒæ—¶å¯ä»¥è¾¾åˆ° 95% çš„ GPT-4 æ€§èƒ½\n\nåŠŸèƒ½:\n1ã€æ›¿ä»£OpenAI",
    "post_content_en": "A flexible and easy-to-use LLM routing framework: RouteLLM\nRouteLLM solves the problem of strong performance but expensive large models, and cheap but weak performance models. It can dynamically choose stronger or weaker LLMs during inference, reducing costs without affecting quality.\n\nOn the MT Bench benchmark, costs are reduced by 85% while achieving 95% of GPT-4 performance.\n\nFeatures:\n1. Replace OpenAI",
    "link_lists": [
      "https://t.co/KwcP0e2RJ5",
      "https://x.com/aigclink/status/1815700556914331662?t=bIygVtB2QBx9mk9eVC14VA&s=03"
    ],
    "post_summary_cn": "RouteLLMæ˜¯ä¸€ä¸ªçµæ´»çš„LLMè·¯ç”±æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€é€‰æ‹©ä¸åŒæ€§èƒ½çš„LLMï¼Œé™ä½æˆæœ¬çš„åŒæ—¶ä¿æŒé«˜è´¨é‡ã€‚åœ¨MT BenchåŸºå‡†ä¸Šï¼Œæˆæœ¬é™ä½85%ï¼Œæ€§èƒ½è¾¾åˆ°GPT-4çš„95%ã€‚",
    "post_summary_en": "RouteLLM is a flexible LLM routing framework that dynamically selects LLMs of varying performance during inference, reducing costs while maintaining high quality. It reduces costs by 85% on the MT Bench benchmark, achieving 95% of GPT-4 performance.",
    "post_datetime": "2024-07-23T12:16:52-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1905f18e265590c2": {
    "email_id": "1905f18e265590c2",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "Tom Huang (@tuturetom) posted at 6:31 AM on Thu, Jun 27, 2024:\nTuGraphã€OpenSPGã€DB-GPTï¼Œæ„Ÿè§‰é›†é½äº†æ„å»º AI Native Agentic Data App çš„æ ¸å¿ƒè¦ç´ ï¼ğŸ”¥\n\n- DB-GPTï¼šå›¾å½¢åŒ–ç•Œé¢ç®¡ç†èµ„æºã€Embeddingã€å›¾å­˜å‚¨ã€AWELï¼ˆAgentic Workflow è¡¨è¾¾è¯­è¨€ï¼‰ã€æ„å»º\nAgentã€å…¼å®¹å¼€æºæ¨¡å‹ã€æ”¶é›†æ•°æ®é›†å’Œè‡ªåŠ¨å¾®è°ƒ",
    "post_content_en": "Tom Huang (@tuturetom) posted at 6:31 AM on Thu, Jun 27, 2024:\nTuGraph, OpenSPG, DB-GPT, it feels like the core elements for building AI Native Agentic Data Apps are all here! ğŸ”¥\n\n- DB-GPT: Graphical interface for managing resources, Embedding, graph storage, AWEL (Agentic Workflow Expression Language), building\nAgents, compatible with open-source models, collecting datasets and automatic fine-tuning",
    "link_lists": [
      "https://t.co/77DjjH15kx",
      "https://t.co/yuWr76LkJ4",
      "https://x.com/tuturetom/status/1806319351609606470?t=OR-HKm6gOY9eOsq-QZfSQQ&s=03"
    ],
    "post_summary_cn": "Tom Huang è®¨è®ºäº† TuGraphã€OpenSPG å’Œ DB-GPT ä½œä¸ºæ„å»º AI Native Agentic Data App çš„æ ¸å¿ƒè¦ç´ ï¼Œç‰¹åˆ«æåˆ° DB-GPT çš„åŠŸèƒ½ã€‚",
    "post_summary_en": "Tom Huang discusses TuGraph, OpenSPG, and DB-GPT as core elements for building AI Native Agentic Data Apps, highlighting the features of DB-GPT.",
    "post_datetime": "2024-06-28T06:46:27-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1904d72deee53016": {
    "email_id": "1904d72deee53016",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "ç¡…åŸºæ™ºèƒ½å°†å…¶DUIXï¼ˆDialogue User Interface Systemï¼‰å¼€æºäº†\nDUIXæ˜¯2D çœŸäººçº§ã€AIGC å®æ—¶æ¸²æŸ“æ•°å­—äººæ¨¡å‹ï¼\n\nå¼€å‘è€…å¯è‡ªè¡Œæ¥å…¥å¤šæ–¹å¤§æ¨¡å‹ã€è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ã€è¯­éŸ³åˆæˆï¼ˆTTSï¼‰èƒ½åŠ›å®ç°æ•°å­—äººå®æ—¶äº¤äº’\n\nå¯åœ¨Androidå’ŒiOSå¤šç»ˆç«¯ä¸€é”®éƒ¨ç½²ï¼ŒDUIXè¿˜æä¾›äº† 14 ä¸ªæ•°å­—äººæ¨¡æ¿\n\næ”¯æŒä½æˆæœ¬å¿«é€Ÿéƒ¨ç½²åœ¨",
    "post_content_en": "Silicon-based intelligence has open-sourced its DUIX (Dialogue User Interface System).\nDUIX is a 2D, human-level, AIGC real-time rendering digital human model!\n\nDevelopers can integrate multiple large models, speech recognition (ASR), and speech synthesis (TTS) capabilities for real-time digital human interaction.\n\nIt can be deployed with one click on multiple terminals such as Android and iOS, and DUIX also provides 14 digital human templates.\n\nSupports low-cost rapid deployment at",
    "link_lists": [
      "https://t.co/oD6KffFCNR",
      "https://x.com/aigclink/status/1805167554174021830?t=j9DhkQ3qiDz2PSt_KXW1Pg&s=03"
    ],
    "post_summary_cn": "ç¡…åŸºæ™ºèƒ½å¼€æºäº†å…¶DUIXç³»ç»Ÿï¼Œæ”¯æŒå¤šæ¨¡å‹å’Œè¯­éŸ³æŠ€æœ¯çš„å®æ—¶äº¤äº’ï¼Œå¹¶å¯åœ¨å¤šå¹³å°å¿«é€Ÿéƒ¨ç½²ã€‚",
    "post_summary_en": "Silicon-based intelligence has open-sourced its DUIX system, supporting real-time interaction with multiple models and speech technologies, and can be rapidly deployed on multiple platforms.",
    "post_datetime": "2024-06-24T20:31:32-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1901e1d3340e613a": {
    "email_id": "1901e1d3340e613a",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "æœ‰ç‚¹çˆ±ä¸Š dify äº†ï¼Œä»Šå¤©è‡ªå·±éƒ¨ç½²äº†ä¸€å¥—æœåŠ¡ï¼Œå°è¯•å†™äº†å‡ ä¸ªæµç¨‹ï¼Œè¾¹å¼€å‘è¾¹è°ƒè¯•ï¼Œç›¸æ¯”åŸå…ˆé€šè¿‡ä»£ç ç¼–æ’å’Œè°ƒè¯•æ•ˆç‡é«˜å¤ªå¤šäº†ï¼Œæ•´ä¸ªé¡µé¢éå¸¸ä¸æ»‘ï¼Œåé¢ä¼šé€æ­¥å°† ä¸Šçš„ä¸€äº›è‡ªåŠ¨åŒ–æµç¨‹åˆ‡æ¢åˆ° dify ä¸Šæ¥ã€‚",
    "post_content_en": "I am somewhat falling in love with dify. Today, I deployed a set of services myself and tried writing several processes. Developing and debugging simultaneously is much more efficient compared to the previous method of coding and debugging. The entire interface is very smooth. Later, I will gradually switch some of the automated processes from the website to dify.",
    "link_lists": [
      "https://t.co/gLQOSl6U7V",
      "https://t.co/Ww3bDvm4lC",
      "https://x.com/hongming731/status/1801546636126208043?t=yvRcRVnltN9qqOvmaXPXkg&s=03"
    ],
    "post_summary_cn": "ä½œè€…å¯¹ dify è¡¨ç¤ºå–œçˆ±ï¼Œéƒ¨ç½²äº†æœåŠ¡å¹¶ç¼–å†™æµç¨‹ï¼Œæ•ˆç‡æå‡ï¼Œè®¡åˆ’å°†è‡ªåŠ¨åŒ–æµç¨‹åˆ‡æ¢åˆ° difyã€‚",
    "post_summary_en": "The author expresses fondness for dify, deployed services, wrote processes, improved efficiency, and plans to switch automated processes to dify.",
    "post_datetime": "2024-06-15T15:55:48-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1901e1be6d4b2dfb": {
    "email_id": "1901e1be6d4b2dfb",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "åˆå…³æ³¨åˆ°ä¸€æ‰¹ voice agent æ–¹å‘çš„äº§å“ï¼Œè¿™ä¸ªæ–¹å‘åˆ›ä¸šçš„äº§å“è¶Šæ¥è¶Šå¤šï¼š\n\néœ€è¦æ€è€ƒçš„ä¸€ä¸ªé—®é¢˜æ˜¯ï¼šå°†æ¥ä½ å¦‚ä½•åˆ†è¾¨ç”µè¯é‚£å¤´æ˜¯çœŸäººè¿˜æ˜¯ AIï¼Ÿ",
    "post_content_en": "Noticed another batch of products in the voice agent direction, and more and more products are being developed in this entrepreneurial direction:\n\nA question to consider is: How will you distinguish whether the person on the other end of the phone is real or AI in the future?",
    "link_lists": [
      "https://t.co/puwWf1grAN",
      "https://t.co/6ZF2AGHWBp",
      "https://t.co/3pGCO7mZfP",
      "https://x.com/leeoxiang/status/1801905998736883917?t=eMp57fTPTRyRO49M_nAlFQ&s=03"
    ],
    "post_summary_cn": "å…³æ³¨ voice agent äº§å“çš„å¢åŠ ï¼Œå¹¶æå‡ºå¦‚ä½•åˆ†è¾¨çœŸäººä¸ AI çš„é—®é¢˜ã€‚",
    "post_summary_en": "Focus on the increase in voice agent products and raise the question of how to distinguish between real people and AI.",
    "post_datetime": "2024-06-15T15:54:24-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "18febea25084aa94": {
    "email_id": "18febea25084aa94",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "é˜…è¯» Dr. Varshita Sher åœ¨ Medium ä¸Šçš„è¿™ç¯‡æ–‡ç« ï¼š",
    "post_content_en": "Read this story from Dr. Varshita Sher on Medium:",
    "link_lists": [
      "https://towardsdatascience.com/using-langchain-react-agents-for-answering-multi-hop-questions-in-rag-systems-893208c1847e"
    ],
    "post_summary_cn": "Dr. Varshita Sher åœ¨ Medium ä¸Šåˆ†äº«äº†ä¸€ç¯‡æ–‡ç« ã€‚",
    "post_summary_en": "Dr. Varshita Sher shared a story on Medium.",
    "post_datetime": "2024-05-06T21:59:01-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "18febcac2a05cf16": {
    "email_id": "18febcac2a05cf16",
    "post_labels": [
      "LLM/agent"
    ],
    "post_content_cn": "Cohereçš„ä½¿ç”¨æŒ‡å—\nå¯ä»¥å…¨é¢äº†è§£å¦‚ä½•åœ¨ Cohere ç”Ÿæˆå¼ AI å¹³å°ä¸Šæ„å»ºåº”ç”¨ï¼Œæ¯”å¦‚Agentã€å¼€æºè½¯ä»¶é›†æˆã€æœç´¢/åµŒå…¥ã€äº‘æœåŠ¡ã€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ã€æ‘˜è¦ä»¥åŠç”¨ä¾‹ç­‰",
    "post_content_en": "Guide to using Cohere\nProvides a comprehensive understanding of how to build applications on the Cohere generative AI platform, such as Agent, open-source software integration, search/embedding, cloud services, retrieval-augmented generation (RAG), summarization, and use cases.",
    "link_lists": [
      "https://t.co/K3bRZBQXKj",
      "https://t.co/4reZhjQlZ0",
      "https://x.com/aigclink/status/1798563171000824173?t=7a1Aetqo-DGhQy4obJdRnQ&s=03"
    ],
    "post_summary_cn": "Cohereå¹³å°çš„ä½¿ç”¨æŒ‡å—ï¼Œæ¶µç›–åº”ç”¨æ„å»ºã€é›†æˆã€æœç´¢ã€äº‘æœåŠ¡ç­‰ã€‚",
    "post_summary_en": "Guide on using the Cohere platform, covering application building, integration, search, cloud services, etc.",
    "post_datetime": "2024-05-06T21:24:44-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "191177442664eb60": {
    "email_id": "191177442664eb60",
    "post_labels": [
      "NLP"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 1:12 AM on Sat, Aug 03, 2024:\nğŸ—’txtai  @neumll  8.3kâœ¨\n\ntxtai æ˜¯ä¸€ä¸ªç”¨äºè¯­ä¹‰æœç´¢ã€ LLM ç¼–æ’å’Œå·¥ä½œæµçš„å…¨èƒ½åµŒå…¥æ•°æ®åº“ (embeddings db)\n\nåµŒå…¥æ•°æ®åº“æ˜¯å‘é‡ç´¢å¼•ã€å›¾ç½‘ç»œå’Œå…³ç³»æ•°æ®åº“çš„ç»“åˆä½“ï¼Œè¿™ä½¿å¾—å¯ä»¥ä½¿ç”¨ SQL è¿›è¡Œå‘é‡æœç´¢ã€ä¸»é¢˜å»ºæ¨¡ã€RAG ç­‰ã€‚\nå®ƒå¯ä»¥ç‹¬ç«‹å­˜åœ¨ï¼Œæˆ–è€…ä½œä¸º LLM prompts çš„å¼ºå¤§çŸ¥è¯†æºã€‚\n\nğŸ—’txtai åŠŸèƒ½æ€»ç»“",
    "post_content_en": "meng shao (@shao__meng) posted at 1:12 AM on Sat, Aug 03, 2024:\nğŸ—’txtai  @neumll  8.3kâœ¨\n\ntxtai is a versatile embedding database for semantic search, LLM orchestration, and workflows.\n\nThe embedding database is a combination of vector indexes, graph networks, and relational databases, allowing for vector search, topic modeling, RAG, etc., using SQL.\nIt can exist independently or serve as a powerful knowledge source for LLM prompts.\n\nğŸ—’Summary of txtai features",
    "link_lists": [
      "https://t.co/ljDXKwBAyI",
      "https://x.com/shao__meng/status/1819647434362151110?t=ZH-gMRb8LIdjatDmV2sIWQ&s=03"
    ],
    "post_summary_cn": "txtai æ˜¯ä¸€ä¸ªç”¨äºè¯­ä¹‰æœç´¢å’Œ LLM ç¼–æ’çš„åµŒå…¥æ•°æ®åº“ï¼Œç»“åˆäº†å‘é‡ç´¢å¼•ã€å›¾ç½‘ç»œå’Œå…³ç³»æ•°æ®åº“ï¼Œæ”¯æŒ SQL æŸ¥è¯¢ã€‚",
    "post_summary_en": "txtai is an embedding database for semantic search and LLM orchestration, combining vector indexes, graph networks, and relational databases, supporting SQL queries.",
    "post_datetime": "2024-03-08T01:56:22-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "190a51629638241f": {
    "email_id": "190a51629638241f",
    "post_labels": [
      "NLP"
    ],
    "post_content_cn": "â€œè‡ªå®šä¹‰è¯å½¢è¿˜åŸâ€\n\né˜…è¯» Daniel Kristiyanto åœ¨ Medium ä¸Šçš„æ–‡ç« â€œè‡ªç„¶è¯­è¨€å¤„ç†ï¼šç‰©ä¸šç§Ÿèµåˆ—è¡¨çš„æ–‡æœ¬æ‘˜è¦å’Œå…³é”®è¯æå–â€”â€”ç¬¬1éƒ¨åˆ†â€ï¼š",
    "post_content_en": "â€œcustom lemmatizationâ€œ\n\nRead â€œNLP: Text Summarization and Keyword Extraction on Property Rental Listings â€” Part 1â€œ by Daniel Kristiyanto on Medium:",
    "link_lists": [
      "https://towardsdatascience.com/nlp-text-summarization-and-keyword-extraction-on-property-rental-listings-part-1-f1b760cc7bbb"
    ],
    "post_summary_cn": "Daniel Kristiyanto åœ¨ Medium ä¸Šæ’°å†™äº†ä¸€ç¯‡å…³äºç‰©ä¸šç§Ÿèµåˆ—è¡¨çš„æ–‡æœ¬æ‘˜è¦å’Œå…³é”®è¯æå–çš„æ–‡ç« ã€‚",
    "post_summary_en": "Daniel Kristiyanto wrote an article on Medium about text summarization and keyword extraction for property rental listings.",
    "post_datetime": "2024-11-07T20:56:52-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "1902723e66f4eac9": {
    "email_id": "1902723e66f4eac9",
    "post_labels": [
      "NLP"
    ],
    "post_content_cn": "æœ€å…ˆè¿›çš„ç¥ç»å…±æŒ‡è§£æç”¨äºèŠå¤©æœºå™¨äºº\nè‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„å…±æŒ‡è§£æ",
    "post_content_en": "State-of-the-art neural coreference resolution for chatbots\nCoreference resolution in natural language processing",
    "link_lists": [
      "https://medium.com/huggingface/state-of-the-art-neural-coreference-resolution-for-chatbots-3302365dcf30",
      "https://medium.com/aimonks/coreference-resolution-in-natural-language-processing-nlp-5ba4f570bffe"
    ],
    "post_summary_cn": "è¿™å°é‚®ä»¶åŒ…å«äº†å…³äºèŠå¤©æœºå™¨äººå’Œè‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„å…±æŒ‡è§£æçš„ä¸¤ç¯‡æ–‡ç« é“¾æ¥ã€‚",
    "post_summary_en": "The email contains links to two articles about coreference resolution in chatbots and natural language processing.",
    "post_datetime": "2024-06-17T09:59:42-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "193c2d3e278fae79": {
    "email_id": "193c2d3e278fae79",
    "post_labels": [
      "LLM/NotebookLM"
    ],
    "post_content_cn": "orange.ai (@oran_ge) äº 2024å¹´12æœˆ13æ—¥æ˜ŸæœŸäº”ä¸‹åˆ5:02å‘å¸ƒï¼šNotebookLM æ–°ç‰ˆè¯•ç”¨åœ°å€ï¼š",
    "post_content_en": "orange.ai (@oran_ge) posted at 5:02 PM on Fri, Dec 13, 2024: NotebookLM new version trial address:",
    "link_lists": [
      "https://t.co/mUE4qYfqlx",
      "https://x.com/oran_ge/status/1867736778087772657?t=yQhn2FDuPCpJ4vukJgqa_Q&s=03"
    ],
    "post_summary_cn": "orange.ai å‘å¸ƒäº† NotebookLM æ–°ç‰ˆè¯•ç”¨åœ°å€ã€‚",
    "post_summary_en": "orange.ai posted the trial address for the new version of NotebookLM.",
    "post_datetime": "2024-12-13T17:41:27-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1938f161fa11850b": {
    "email_id": "1938f161fa11850b",
    "post_labels": [
      "LLM",
      "NotebookLM"
    ],
    "post_content_cn": "Ollama å³å°†æ”¯æŒ LLM ç»“æ„åŒ–è¾“å‡º ğŸ‰\n\nåœ¨ @github åŠå…¬å®¤ä¸¾åŠçš„ @ollama meetup ä¸­ï¼Œ@thanosthinking å®£å¸ƒ Ollama å³å°†æ”¯æŒ LLM ç»“æ„åŒ–è¾“å‡ºï¼Œé€šè¿‡ Github æäº¤è®°å½•å¯ä»¥çœ‹åˆ° ğŸ‘‡ğŸ‘‡\n\n1. æ–°åŠŸèƒ½\n\n- æ”¯æŒä¼ å…¥ JSON schema, å¹¶å°†å…¶è½¬æ¢ä¸ºè¯­æ³•è§„åˆ™æ¥è¿›è¡Œé‡‡æ ·\n- å¹³è¡¡æ˜“ç”¨æ€§å’ŒåŠŸèƒ½æ€§ - é€šè¿‡æ”¯æŒ JSON schema",
    "post_content_en": "Ollama is about to support LLM structured output ğŸ‰\n\nAt the @ollama meetup held at the @github office, @thanosthinking announced that Ollama is about to support LLM structured output, which can be seen through Github commit records ğŸ‘‡ğŸ‘‡\n\n1. New Features\n\n- Supports input of JSON schema and converts it into syntax rules for sampling\n- Balances usability and functionality - by supporting JSON schema",
    "link_lists": [
      "https://t.co/8fDxyk74BW",
      "https://x.com/shao__meng/status/1863784874509017298?t=2f2Tp1_lRUWdsvon6GscZg&s=03"
    ],
    "post_summary_cn": "Ollama å®£å¸ƒå³å°†æ”¯æŒ LLM ç»“æ„åŒ–è¾“å‡ºï¼Œæ”¯æŒ JSON schema è½¬æ¢ä¸ºè¯­æ³•è§„åˆ™ã€‚",
    "post_summary_en": "Ollama announced upcoming support for LLM structured output, with JSON schema conversion to syntax rules.",
    "post_datetime": "2024-03-12T16:33:32-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192d190af5002103": {
    "email_id": "192d190af5002103",
    "post_labels": [
      "LLM/NotebookLM"
    ],
    "post_content_cn": "ç†Šå¸ƒæœ— (@Stephen4171127) å‘å¸ƒäº†ä¸€ä¸ªå¼€æºçš„ NotebookLMã€‚æ­¥éª¤ 1ï¼šé¢„å¤„ç† PDFã€‚ä½¿ç”¨ Llama-3.2-1B-Instruct æ¥é¢„å¤„ç† PDF å¹¶ä¿å­˜ä¸º .txt æ–‡ä»¶ã€‚æ­¥éª¤ 2ï¼šè„šæœ¬ç¼–å†™ã€‚ä½¿ç”¨ Llama-3.1-70B-Instruct æ¥ä»æ–‡æœ¬ä¸­ç¼–å†™æ’­å®¢è„šæœ¬ã€‚æ­¥éª¤ 3ï¼šæˆå‰§åŒ–é‡å†™ã€‚ä½¿ç”¨ Llama-3.1-8B-Instruct æ¨¡å‹ä½¿è„šæœ¬æ›´åŠ æˆå‰§åŒ–ã€‚",
    "post_content_en": "Xiong Brown (@Stephen4171127) posted an open-source NotebookLM. Step 1: Preprocess the PDF. Use Llama-3.2-1B-Instruct to preprocess the PDF and save it as a .txt file. Step 2: Script writing. Use Llama-3.1-70B-Instruct to write a podcast script from the text. Step 3: Dramatic rewriting. Use the Llama-3.1-8B-Instruct model to make the script more dramatic.",
    "link_lists": [
      "https://t.co/S4RgHd2Aef",
      "https://t.co/s2PShRSpMu",
      "https://x.com/Stephen4171127/status/1850572995426717916?t=SNs3S-cNFzqCF36rOQqCFg&s=03"
    ],
    "post_summary_cn": "ç†Šå¸ƒæœ—ä»‹ç»äº†ä¸€ä¸ªå¼€æºçš„ NotebookLMï¼ŒåŒ…å«ä¸‰ä¸ªæ­¥éª¤ï¼šPDF é¢„å¤„ç†ã€è„šæœ¬ç¼–å†™å’Œæˆå‰§åŒ–é‡å†™ã€‚",
    "post_summary_en": "Xiong Brown introduced an open-source NotebookLM with three steps: PDF preprocessing, script writing, and dramatic rewriting.",
    "post_datetime": "2024-10-27T22:19:33-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "19231470fd03d7dc": {
    "email_id": "19231470fd03d7dc",
    "post_labels": [
      "LLM",
      "NotebookLM"
    ],
    "post_content_cn": "èµï¼ŒNotebookLMæ–°å¢äº†éŸ³é¢‘å’ŒYouTubeæ”¯æŒåŠŸèƒ½ï¼è¿™ä¹ˆç”¨èµ·æ¥å°±æ–¹ä¾¿å¤šäº†ï½\n\n1ã€æ”¯æŒæ·»åŠ YouTubeé“¾æ¥å’ŒéŸ³é¢‘æ–‡ä»¶åˆ°ç¬”è®°æœ¬ä¸­\n2ã€æ”¹è¿›äº†Audio Overviewsçš„åˆ†äº«åŠŸèƒ½\n\nå¯ä»¥åšä¸º\nè§†é¢‘å’Œè®²åº§åˆ†æåŠ©æ‰‹ï¼šæ€»ç»“å…³é”®æ¦‚å¿µï¼Œå¹¶æä¾›å†…è”å¼•ç”¨\néŸ³é¢‘åŠ©æ‰‹ï¼šå¯ä»¥è®©NotebookLM åœ¨è½¬å½•çš„å¯¹è¯ä¸­æœç´¢æŸ¥æ‰¾ç‰¹å®šä¿¡æ¯",
    "post_content_en": "Great, NotebookLM has added audio and YouTube support features! It's much more convenient to use now~\n\n1. Supports adding YouTube links and audio files to notebooks\n2. Improved the sharing function of Audio Overviews\n\nCan be used as\nVideo and lecture analysis assistant: Summarizes key concepts and provides inline citations\nAudio assistant: Allows NotebookLM to search for specific information in transcribed conversations",
    "link_lists": [
      "https://t.co/SyhYnl30Kx",
      "https://x.com/aigclink/status/1839489300393869696?t=aBeZDqEwt34C_VTy9wFIwA&s=03"
    ],
    "post_summary_cn": "NotebookLMæ–°å¢äº†éŸ³é¢‘å’ŒYouTubeæ”¯æŒï¼Œæ”¹è¿›äº†åˆ†äº«åŠŸèƒ½ï¼Œå¯ç”¨äºè§†é¢‘å’ŒéŸ³é¢‘åˆ†æã€‚",
    "post_summary_en": "NotebookLM has added audio and YouTube support, improved sharing features, and can be used for video and audio analysis.",
    "post_datetime": "2024-09-26T19:19:53-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "19221e49089695d5": {
    "email_id": "19221e49089695d5",
    "post_labels": [
      "LLM",
      "NotebookLM"
    ],
    "post_content_cn": "AIGCLINK (@aigclink) posted at 7:56 AM on Mon, Sep 23, 2024: PDFè½¬éŸ³é¢‘å·¥å…·ï¼šPDF2Audioï¼ŒNotebookLMçš„å¼€æºæ›¿ä»£æ–¹æ¡ˆ å¯ä»¥PDFè½¬æ’­å®¢ã€è®²åº§ã€è®¨è®ºã€çŸ­/é•¿æ–‡æ‘˜è¦ç­‰ æ”¯æŒä¸Šä¼ å¤šä¸ª PDF æ–‡ä»¶ æ”¯æŒä¸åŒæŒ‡ä»¤æ¨¡æ¿ï¼ŒåŒ…æ‹¬æ’­å®¢ã€è®²åº§ã€æ‘˜è¦ç­‰ è‡ªå®šä¹‰æ–‡æœ¬ç”Ÿæˆå’ŒéŸ³é¢‘æ¨¡å‹ æ”¯æŒä¸åŒå£°éŸ³é€‰æ‹© æ”¯æŒè‡ªå®šä¹‰éŸ³é¢‘é•¿åº¦ã€è¯­æ°”ã€é£æ ¼ç­‰",
    "post_content_en": "AIGCLINK (@aigclink) posted at 7:56 AM on Mon, Sep 23, 2024: PDF to audio tool: PDF2Audio, an open-source alternative to NotebookLM. It can convert PDFs to podcasts, lectures, discussions, short/long text summaries, etc. Supports uploading multiple PDF files. Supports different command templates, including podcasts, lectures, summaries, etc. Customizable text generation and audio models. Supports different voice choices. Supports custom audio length, tone, style, etc.",
    "link_lists": [
      "https://t.co/lywPfFAHzg",
      "https://t.co/tdwWRDiYXw",
      "https://x.com/aigclink/status/1838231005800624372?t=RKGMCNlu7-IljkjW8tB_Tw&s=03"
    ],
    "post_summary_cn": "AIGCLINKå‘å¸ƒäº†ä¸€æ¬¾åä¸ºPDF2Audioçš„å·¥å…·ï¼Œå¯ä»¥å°†PDFè½¬æ¢ä¸ºéŸ³é¢‘ï¼Œæ”¯æŒå¤šç§æ ¼å¼å’Œè‡ªå®šä¹‰é€‰é¡¹ã€‚",
    "post_summary_en": "AIGCLINK released a tool called PDF2Audio that converts PDFs to audio, supporting various formats and customization options.",
    "post_datetime": "2024-09-23T19:38:01-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1923996e5a914c84": {
    "email_id": "1923996e5a914c84",
    "post_labels": [
      "LLM/ppt-generation"
    ],
    "post_content_cn": "è°è¿˜éœ€è¦officeå‘¢ğŸ˜›",
    "post_content_en": "Who still needs office ğŸ˜›",
    "link_lists": [
      "https://x.com/JefferyTatsuya/status/1839916194243195345?t=8l6rAjSo1TS0jF958oEfMQ&s=03"
    ],
    "post_summary_cn": "è¯¢é—®æ˜¯å¦è¿˜æœ‰äººéœ€è¦ä½¿ç”¨officeã€‚",
    "post_summary_en": "Asking if anyone still needs to use office.",
    "post_datetime": "2024-09-28T10:04:05-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "19236767ca6262b0": {
    "email_id": "19236767ca6262b0",
    "post_labels": [
      "LLM/ppt-generation",
      "LLM"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 4:45 PM on Fri, Sep 27, 2024: AI PPT åŠ©æ‰‹ @KaranVaidya6\n\nåŸºäº Google Sheets æ•°æ®æ„å»º PPT æ–‡ç¨¿çš„ AI Agent, åˆ©ç”¨äº† LlamaIndex @llama_indexã€Composio @composiohqã€CrewAI @crewAIIncã€AgentOps @AgentOpsAI å’Œ ChatGPT ç­‰æŠ€æœ¯\n\nåŠŸèƒ½åŒ…æ‹¬è¯»å–è¡¨æ ¼ã€ç»˜åˆ¶å›¾è¡¨ã€å‘ç°å…³é”®æ´å¯Ÿå¹¶åˆ›å»º PPT æ–‡ç¨¿ã€‚",
    "post_content_en": "meng shao (@shao__meng) posted at 4:45 PM on Fri, Sep 27, 2024: AI PPT Assistant @KaranVaidya6\n\nAn AI Agent for building PPT documents based on Google Sheets data, utilizing technologies such as LlamaIndex @llama_index, Composio @composiohq, CrewAI @crewAIInc, AgentOps @AgentOpsAI, and ChatGPT.\n\nFeatures include reading tables, drawing charts, discovering key insights, and creating PPT documents.",
    "link_lists": [
      "https://x.com/shao__meng/status/1839813614263517295?t=e24CpHpjE5MqkIz9jt62uA&s=03"
    ],
    "post_summary_cn": "AI åŠ©æ‰‹åˆ©ç”¨å¤šç§æŠ€æœ¯ä» Google Sheets æ•°æ®åˆ›å»º PPTï¼ŒåŠŸèƒ½åŒ…æ‹¬è¯»å–è¡¨æ ¼ã€ç»˜åˆ¶å›¾è¡¨å’Œå‘ç°æ´å¯Ÿã€‚",
    "post_summary_en": "AI assistant uses various technologies to create PPTs from Google Sheets data, featuring table reading, chart drawing, and insight discovery.",
    "post_datetime": "2024-09-27T19:29:48-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1905f0edb6c42abf": {
    "email_id": "1905f0edb6c42abf",
    "post_labels": [
      "LLM/ppt-generation"
    ],
    "post_content_cn": "Figma ä¹Ÿæ€å…¥ PPT äº†\nPPT æ˜¯æµ·å†…å¤–é€šæ€çš„åˆšéœ€",
    "post_content_en": "Figma has also entered the PPT market.\nPPT is a universal necessity both domestically and internationally.",
    "link_lists": [
      "https://x.com/oran_ge/status/1806158860593528922?t=uE6LPFvrGWwSg1ERBn94nQ&s=03"
    ],
    "post_summary_cn": "Figma è¿›å…¥äº† PPT å¸‚åœºï¼ŒPPT æ˜¯å…¨çƒçš„å¿…éœ€å“ã€‚",
    "post_summary_en": "Figma has entered the PPT market, which is a global necessity.",
    "post_datetime": "2024-06-28T06:35:29-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "18f924a987299d8d": {
    "email_id": "18f924a987299d8d",
    "post_labels": [
      "kids"
    ],
    "post_content_cn": "é£›é³¥ (@askaiwy) posted at 5:29 PM on Sat, May 18, 2024:\nã€Šè§’é²¨è‚æ²¹çš„çŸ¥è¯†ã€‹\n\nå†™è¿™ç¯‡å…³äºè§’é²¨è‚æ²¹çš„ä»‹ç»çš„æ—¶å€™ï¼Œ\nå…‰æ˜¯æŸ¥èµ„æ–™å°±ç”¨äº†å·®ä¸å¤šå¤§åŠä¸ªæœˆçš„æ—¶é—´ã€‚\nå…¶é—´ä¸ºäº†å‡†ç¡®æŸ¥å‡ºå¯¹åº”çš„ä¸“ä¸šåè¯ï¼Œ\nä¸­ã€æ—¥ã€è‹±ä¸‰å›½çš„ç½‘ç«™é‡Œé¢åå¤åˆ‡æ¢ã€‚\næ‰€ä»¥ï¼Œ\nè¯¸ä½ä¸€å®šè¦æœ‰è€å¿ƒçœ‹åˆ°æœ€åå•Šï¼\n\né¦–å…ˆæˆ‘ä»¬è¦åˆ†æ¸…æ¥šï¼Œ\né±¼æ²¹è·Ÿé±¼è‚æ²¹çš„ä¸åŒã€‚\né±¼æ²¹ï¼Œâ€¦",
    "post_content_en": "Asuka (@askaiwy) posted at 5:29 PM on Sat, May 18, 2024:\n\"Knowledge of Squalene Oil\"\n\nWhen writing this introduction about squalene oil,\nI spent almost half a month just researching.\nDuring this time, to accurately find the corresponding professional terms,\nI repeatedly switched between Chinese, Japanese, and English websites.\nSo,\neveryone must be patient to see it through to the end!\n\nFirst, we need to distinguish between\nfish oil and fish liver oil.\nFish oil, ...",
    "link_lists": [
      "https://t.co/eM82FWxyRm",
      "https://x.com/askaiwy/status/1791989619753640168?t=fkURtChNKqWSXinAmtR7lQ&s=03"
    ],
    "post_summary_cn": "é£›é³¥ä»‹ç»äº†è§’é²¨è‚æ²¹çš„çŸ¥è¯†ï¼Œå¼ºè°ƒäº†é±¼æ²¹å’Œé±¼è‚æ²¹çš„åŒºåˆ«ï¼Œå¹¶æåˆ°ä¸ºäº†å‡†ç¡®æŸ¥æ‰¾ä¸“ä¸šåè¯ï¼ŒèŠ±è´¹äº†å¤§é‡æ—¶é—´åœ¨ä¸­ã€æ—¥ã€è‹±ç½‘ç«™ä¹‹é—´åˆ‡æ¢ã€‚",
    "post_summary_en": "Asuka introduced the knowledge of squalene oil, emphasizing the difference between fish oil and fish liver oil, and mentioned spending a lot of time switching between Chinese, Japanese, and English websites to accurately find professional terms.",
    "post_datetime": "2024-05-19T12:18:33-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "18f6fef7ec95cb5c": {
    "email_id": "18f6fef7ec95cb5c",
    "post_labels": [
      "kids"
    ],
    "post_content_cn": "",
    "post_content_en": "",
    "link_lists": [
      "https://twitter.com/essen_ai/status/1789471688121274678",
      "https://immersivemath.com/ila/index.html#"
    ],
    "post_summary_cn": "å®¶é•¿ä»¬å¯ä»¥æ”¶è—ä¸€ä¸ªåä¸ºimmersivemathçš„æ²‰æµ¸å¼æ•°å­¦ç½‘ç«™ï¼Œå¯¹æµ·å¤–åäººå®¶åº­å°¤å…¶æœ‰å¸®åŠ©ã€‚",
    "post_summary_en": "Parents are recommended to bookmark an immersive math website called immersivemath, which is especially helpful for overseas Chinese families.",
    "post_datetime": "2024-12-05T20:11:57-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1922a3e859b891b1": {
    "email_id": "1922a3e859b891b1",
    "post_labels": [
      "LLM/git-project"
    ],
    "post_content_cn": "Markdownæ–‡æœ¬è½¬æ€ç»´å¯¼å›¾å·¥å…·ï¼šmarkmap\né€šè¿‡è§£æMarkdownè¯­æ³•ï¼Œå®æ—¶ç”Ÿæˆç»“æ„åŒ–æ€ç»´å¯¼å›¾\n\nè½»é‡çº§ï¼Œå¯ä¸VS Codeã€Vim/Neovimã€Emacsé›†æˆ\næ”¯æŒå®æ—¶æ¸²æŸ“ã€å¯å®šåˆ¶å¯äº¤äº’ï¼ŒåµŒå…¥æ€§å¼º",
    "post_content_en": "Markdown text to mind map tool: markmap\nBy parsing Markdown syntax, it generates structured mind maps in real-time\n\nLightweight, can be integrated with VS Code, Vim/Neovim, Emacs\nSupports real-time rendering, customizable and interactive, strong embedding",
    "link_lists": [
      "https://t.co/lPYJJ0X8mu",
      "https://t.co/X0FtksjoTV",
      "https://x.com/aigclink/status/1838761274420900103?t=9f2VNJK7kFQIDpbLp_pG6w&s=03"
    ],
    "post_summary_cn": "ä»‹ç»äº†ä¸€ä¸ªåä¸ºmarkmapçš„å·¥å…·ï¼Œå¯ä»¥å°†Markdownæ–‡æœ¬è½¬æ¢ä¸ºæ€ç»´å¯¼å›¾ï¼Œæ”¯æŒå¤šç§ç¼–è¾‘å™¨é›†æˆå’Œå®æ—¶æ¸²æŸ“ã€‚",
    "post_summary_en": "Introduces a tool called markmap that converts Markdown text into mind maps, supporting integration with various editors and real-time rendering.",
    "post_datetime": "2024-09-25T10:33:14-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "191704314e946803": {
    "email_id": "191704314e946803",
    "post_labels": [
      "LLM/git-project"
    ],
    "post_content_cn": "ä¸€ä¸ªåŸºäºçŸ¥è¯†å›¾è°±çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼šfact-finder\nåˆ©ç”¨LLMå’Œ Neo4j æ•°æ®åº“å®ç°è‡ªåŠ¨åŒ–æŸ¥è¯¢ä¸å›ç­”ï¼Œå®ç°äº†ä»ç”¨æˆ·é—®é¢˜åˆ°è‡ªç„¶è¯­è¨€ç­”æ¡ˆçš„è‡ªåŠ¨åŒ–è½¬æ¢è¿‡ç¨‹\n\nç‰¹ç‚¹ï¼š\n1ã€åŸºäºçŸ¥è¯†å›¾è°±ï¼šä½¿ç”¨Neo4j æ•°æ®åº“å­˜å‚¨å’Œç®¡ç†çŸ¥è¯†å›¾è°±ï¼Œå¹¶åˆ©ç”¨å®ƒæ¥å›ç­”é—®é¢˜",
    "post_content_en": "An intelligent question-answering system based on knowledge graphs: fact-finder\nUtilizes LLM and Neo4j database to achieve automated query and response, realizing the automated conversion process from user questions to natural language answers\n\nFeatures:\n1. Based on knowledge graphs: Uses Neo4j database to store and manage knowledge graphs and utilizes it to answer questions",
    "link_lists": [
      "https://t.co/MdTaBB3CBf",
      "https://x.com/aigclink/status/1825808691075100687?t=wjaCDJi7PUSj_VlUZeYnug&s=03"
    ],
    "post_summary_cn": "ä»‹ç»äº†ä¸€ä¸ªåŸºäºçŸ¥è¯†å›¾è°±çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼Œä½¿ç”¨LLMå’ŒNeo4jæ•°æ®åº“å®ç°è‡ªåŠ¨åŒ–æŸ¥è¯¢å’Œå›ç­”ã€‚",
    "post_summary_en": "Introduces an intelligent question-answering system based on knowledge graphs, using LLM and Neo4j database for automated querying and answering.",
    "post_datetime": "2024-08-20T07:48:50-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1916db2af63b5ffa": {
    "email_id": "1916db2af63b5ffa",
    "post_labels": [
      "LLM/git-project"
    ],
    "post_content_cn": "æ›´å¿«ï¼ŒåŒæ—¶æ€§èƒ½æŸå¤±é™åˆ°æœ€ä½ï¼Ÿ800 è¡Œä»£ç è½»é‡çº§ GraphRAG æ¥äº† âš¡ï¸ ğŸ¤¯ğŸ¤¯\nnano-GraphRAG æŠ½ç¦» GraphRAG æœ€æ ¸å¿ƒå®ç°å¹¶å…è®¸ä½ æ›¿æ¢ LLMã€Embedding\næ¨¡å—ï¼Œæä¾›å¼‚æ­¥å’Œç±»å‹å®‰å…¨çš„å®ç°ï¼Œéå¸¸é€‚åˆç ”ç©¶å­¦ä¹  GraphRAG æºç å¹¶é€‚é…è‡ªèº«ä¸šåŠ¡ğŸ”¥",
    "post_content_en": "Faster with minimal performance loss? The 800-line lightweight GraphRAG is here âš¡ï¸ ğŸ¤¯ğŸ¤¯\nThe nano-GraphRAG extracts the core implementation of GraphRAG and allows you to replace the LLM and Embedding modules, providing an asynchronous and type-safe implementation, making it very suitable for studying and learning GraphRAG source code and adapting it to your own business needs ğŸ”¥",
    "link_lists": [
      "https://t.co/FpWEV0viyU",
      "https://t.co/eohTiVAaUJ",
      "https://x.com/tuturetom/status/1825340242578317732?t=1QSmehD__de6w8LbAkBr-g&s=03"
    ],
    "post_summary_cn": "ä»‹ç»äº†ä¸€ä¸ªè½»é‡çº§çš„ GraphRAG å®ç°ï¼Œå…·æœ‰å¼‚æ­¥å’Œç±»å‹å®‰å…¨çš„ç‰¹æ€§ï¼Œé€‚åˆç ”ç©¶å’Œä¸šåŠ¡é€‚é…ã€‚",
    "post_summary_en": "Introduces a lightweight GraphRAG implementation with asynchronous and type-safe features, suitable for research and business adaptation.",
    "post_datetime": "2024-08-19T19:51:54-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "193b3651694b78cf": {
    "email_id": "193b3651694b78cf",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "å®ç‰ (@dotey) posted at 11:24 PM on Sat, Dec 07, 2024: å¾ˆå¤šäººè¿˜ä¸çŸ¥é“ AIStudio å¯ä»¥å…è´¹ä½“éªŒ Gemini çš„",
    "post_content_en": "Baoyu (@dotey) posted at 11:24 PM on Sat, Dec 07, 2024: Many people still don't know that AIStudio offers a free trial of Gemini",
    "link_lists": [
      "https://t.co/nitrFrnNP9",
      "https://x.com/dotey/status/1865658660703068195?t=9OG5PDRYFx5WPKUGae5FQg&s=03"
    ],
    "post_summary_cn": "AIStudio æä¾›å…è´¹ä½“éªŒ Gemini çš„æœåŠ¡ï¼Œå¾ˆå¤šäººè¿˜ä¸çŸ¥é“ã€‚",
    "post_summary_en": "AIStudio offers a free trial of Gemini, which many people are unaware of.",
    "post_datetime": "2024-10-12T17:46:08-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1939256722b39736": {
    "email_id": "1939256722b39736",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "å®ç‰ (@dotey) åœ¨ 2024 å¹´ 12 æœˆ 3 æ—¥æ˜ŸæœŸäºŒä¸‹åˆ 6:56 å‘å¸ƒï¼šClaude æ–°çš„ MCP åè®®çš„è¶…é…·æ¡ˆä¾‹ï¼Œç”¨æˆ·ç›´æ¥ä» Claude å®¢æˆ·ç«¯å‘æ¶ˆæ¯ï¼Œå°±å¯ä»¥å¯¹å¾®ä¿¡ç¾¤çš„å†å²æ€»ç»“ã€æŸ¥è¯¢ã€‚æ¯”å¦‚ä½ æ—©ä¸Šèµ·æ¥ä¸€çœ‹ç¾¤é‡Œä¸Šåƒæ¡æ¶ˆæ¯ï¼Œå°±ç»™ Claude å‘ä¸€æ¡æ¶ˆæ¯ï¼šâ€œä»–ä»¬ä¸€å¤§æ—©åœ¨èŠå•¥ï¼Ÿâ€ï¼Œäºæ˜¯ Claude å°±è®¿é—® MCP Server å»æŸ¥è¯¢æœ€æ–°çš„æ¶ˆæ¯ï¼Œå¹¶æ€»ç»“å›å¤ç»™ä½ ã€‚è¿™ç§ MCP",
    "post_content_en": "Baoyu (@dotey) posted at 6:56 PM on Tue, Dec 03, 2024: A cool new case of Claude's MCP protocol, where users can directly send messages from the Claude client to summarize and query the history of WeChat groups. For example, if you wake up in the morning and see thousands of messages in the group, you can send a message to Claude: 'What were they talking about early in the morning?', and then Claude accesses the MCP Server to query the latest messages and summarizes them for you. This kind of MCP",
    "link_lists": [
      "https://x.com/dotey/status/1864141603096678658?t=J4H0DCMMFEZrkZcWcidePQ&s=03"
    ],
    "post_summary_cn": "å®ç‰ä»‹ç»äº† Claude çš„æ–° MCP åè®®ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡ Claude å®¢æˆ·ç«¯æŸ¥è¯¢å’Œæ€»ç»“å¾®ä¿¡ç¾¤å†å²æ¶ˆæ¯ã€‚",
    "post_summary_en": "Baoyu introduced Claude's new MCP protocol, allowing users to query and summarize WeChat group history via the Claude client.",
    "post_datetime": "2024-04-12T07:42:40-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1937fa3373dc97e1": {
    "email_id": "1937fa3373dc97e1",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Tom DÃ¶rr (@tom_doerr) åœ¨ 2024 å¹´ 11 æœˆ 29 æ—¥æ˜ŸæœŸäº”æ™šä¸Š 9:49 å‘å¸ƒï¼š\"å¼€æº LLMOps å¹³å°ï¼šæç¤ºæ¸¸ä¹åœºã€æç¤ºç®¡ç†ã€LLM è¯„ä¼°å’Œ LLM å¯è§‚å¯Ÿæ€§ï¼Œæ‰€æœ‰åŠŸèƒ½é›†äºä¸€èº«ã€‚\"",
    "post_content_en": "Tom DÃ¶rr (@tom_doerr) posted at 9:49 PM on Fri, Nov 29, 2024: \"The open-source LLMOps platform: prompt playground, prompt management, LLM evaluation, and LLM Observability all in one place.\"",
    "link_lists": [
      "https://t.co/ShiUzBlcuo",
      "https://x.com/tom_doerr/status/1862735724006523039?t=27wXm3TgjFO1w6TGGxWDVg&s=03"
    ],
    "post_summary_cn": "Tom DÃ¶rr ä»‹ç»äº†ä¸€ä¸ªé›†æˆæç¤ºç®¡ç†ã€LLM è¯„ä¼°å’Œå¯è§‚å¯Ÿæ€§çš„å¼€æº LLMOps å¹³å°ã€‚",
    "post_summary_en": "Tom DÃ¶rr introduced an open-source LLMOps platform integrating prompt management, LLM evaluation, and observability.",
    "post_datetime": "2024-11-30T16:33:43-08:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "193460a549478438": {
    "email_id": "193460a549478438",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "meng shao (@shao__meng) posted at 11:08 PM on Mon, Nov 18, 2024:\nLLM ç”Ÿæˆæ–‡æœ¬çš„å››ç§æ€§æ ¼ï¼šä»ä¿å®ˆæ´¾åˆ°åˆ›æ–°è€…\n\n// LLM ç”Ÿæˆæ–‡æœ¬çš„å››ç§ç­–ç•¥(è´ªå©ªã€å¤šé¡¹å¼é‡‡æ ·ã€é›†æŸæœç´¢ã€å¯¹æ¯”æœç´¢)ï¼Œå°±åƒä¸åŒæ€§æ ¼çš„å†™æ‰‹ï¼Œé€šè¿‡è°ƒèŠ‚æ¸©åº¦ã€Top-K\nç­‰å‚æ•°ï¼Œåœ¨\"ä¸¥è°¨-åˆ›æ„\"å…‰è°±ä¸Šæ‰¾åˆ°æœ€é€‚åˆå½“å‰ä»»åŠ¡çš„å¹³è¡¡ç‚¹\n\n1. è´ªå©ªç­–ç•¥(Greedy)å°±åƒä¸€ä¸ªè°¨æ…çš„äººï¼š\n- æ°¸è¿œé€‰æœ€ç¨³çš„é€‰é¡¹",
    "post_content_en": "meng shao (@shao__meng) posted at 11:08 PM on Mon, Nov 18, 2024:\nFour personalities of LLM-generated text: from conservative to innovator\n\n// Four strategies for LLM-generated text (Greedy, Multinomial Sampling, Beam Search, Contrastive Search) are like writers with different personalities. By adjusting parameters such as temperature and Top-K, the most suitable balance point on the \"rigorous-creative\" spectrum can be found for the current task.\n\n1. Greedy strategy is like a cautious person:\n- Always chooses the safest option",
    "link_lists": [
      "https://t.co/6zYys7czFq",
      "https://x.com/shao__meng/status/1858769277983379519?t=WYlJj5oFYTzhuxuEL5CDMw&s=03"
    ],
    "post_summary_cn": "è¿™ç¯‡æ–‡ç« è®¨è®ºäº† LLM ç”Ÿæˆæ–‡æœ¬çš„å››ç§ç­–ç•¥ï¼šè´ªå©ªã€å¤šé¡¹å¼é‡‡æ ·ã€é›†æŸæœç´¢å’Œå¯¹æ¯”æœç´¢ã€‚é€šè¿‡è°ƒèŠ‚å‚æ•°ï¼Œå¯ä»¥åœ¨ä¸¥è°¨å’Œåˆ›æ„ä¹‹é—´æ‰¾åˆ°å¹³è¡¡ã€‚",
    "post_summary_en": "The post discusses four strategies for LLM-generated text: Greedy, Multinomial Sampling, Beam Search, and Contrastive Search. By adjusting parameters, a balance between rigor and creativity can be achieved.",
    "post_datetime": "2024-11-19T12:08:22-08:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1930f733da07e48b": {
    "email_id": "1930f733da07e48b",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Rohan Paul (@rohanpaul_ai) åœ¨ 2024 å¹´ 11 æœˆ 8 æ—¥æ˜ŸæœŸäº”ä¸Šåˆ 10:02 å‘å¸ƒï¼š\nå…³äºåŸºç¡€æ¨¡å‹çš„ä¸€ä¸ªå¥½è¯¾ç¨‹",
    "post_content_en": "Rohan Paul (@rohanpaul_ai) posted at 10:02 AM on Fri, Nov 08, 2024:\nA good course on Introduction to Foundation Models",
    "link_lists": [
      "https://t.co/8YEWg6aflQ",
      "https://x.com/rohanpaul_ai/status/1854947658689134924?t=RWcKwZyJfPp72N6StQUXOg&s=03"
    ],
    "post_summary_cn": "Rohan Paul æ¨èäº†ä¸€é—¨å…³äºåŸºç¡€æ¨¡å‹çš„å¥½è¯¾ç¨‹ã€‚",
    "post_summary_en": "Rohan Paul recommended a good course on foundation models.",
    "post_datetime": "2024-08-11T21:43:51-08:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "192b5400ca9339f7": {
    "email_id": "192b5400ca9339f7",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Meta ä¸Šå‘¨å¼€æºäº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„è¯­éŸ³æ¨¡å‹ Spirit LMã€‚\n\nè¿™ä¸ªå¤ªé‡è¦äº†ï¼Œå±…ç„¶æ²¡æ³¨æ„åˆ°ã€‚\n\nè¿™ä¸ªæ¨¡å‹æœ‰ä¸¤ä¸ªç‰ˆæœ¬ï¼š\n\nåŸºç¡€ç‰ˆï¼š é€‚åˆè¿›è¡Œä¸€èˆ¬çš„è¯­éŸ³è¯†åˆ«å’Œç”Ÿæˆï¼Œä¸åŒ…å«æƒ…æ„Ÿå˜åŒ–ã€‚\n\né«˜è¡¨ç°åŠ›ç‰ˆï¼šå¯ä»¥æ•æ‰è¯­éŸ³ä¸­çš„æƒ…æ„Ÿç‰¹å¾ï¼Œèƒ½å¤Ÿç”ŸæˆåŒ…å«å¿«ä¹ã€æ„¤æ€’æˆ–å…´å¥‹ç­‰æƒ…æ„Ÿçš„è¯­éŸ³ã€‚\n\nä¸»è¦ç‰¹ç‚¹æœ‰ï¼š",
    "post_content_en": "Meta open-sourced an end-to-end speech model called Spirit LM last week.\n\nThis is too important, I didn't notice it.\n\nThe model has two versions:\n\nBasic version: Suitable for general speech recognition and generation, without emotional variation.\n\nHigh expressiveness version: Can capture emotional features in speech and generate speech with emotions such as happiness, anger, or excitement.\n\nMain features include:",
    "link_lists": [
      "https://t.co/KPKitdbJD6",
      "https://x.com/op7418/status/1848624774785986676?t=GmUamkm_SYS_WzHtuXtqyw&s=03"
    ],
    "post_summary_cn": "Meta å¼€æºäº†ä¸€ä¸ªåä¸º Spirit LM çš„è¯­éŸ³æ¨¡å‹ï¼Œåˆ†ä¸ºåŸºç¡€ç‰ˆå’Œé«˜è¡¨ç°åŠ›ç‰ˆï¼Œåè€…å¯ä»¥ç”Ÿæˆå¸¦æœ‰æƒ…æ„Ÿçš„è¯­éŸ³ã€‚",
    "post_summary_en": "Meta released an open-source speech model called Spirit LM, with a basic version and a high expressiveness version that can generate speech with emotions.",
    "post_datetime": "2024-10-22T10:22:08-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192aff7f75df9191": {
    "email_id": "192aff7f75df9191",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "å¥½ä¹…æ²¡å†™æ¨ç‰¹äº†ï¼Œä»Šå¤©åˆ†äº«å¦‚ä½•åœ¨Macæœ¬åœ°è¿è¡Œåƒé—®Qwen2-VL-7Bæ¨¡å‹ğŸ’»ã€‚\n\nOllamaæœ‰äº›è½åï¼Œç°åœ¨LM Studioæ”¯æŒMLXæ ¼å¼æ¨¡å‹å¹¶è‡ªå¸¦èŠå¤©UIğŸ› ï¸ã€‚\n\næµ‹è¯•äº†åƒé—®çš„è§†è§‰æ¨¡å‹çš„ 3 ä¸ªå‹å·ï¼Œå¤æ‚è¯†åˆ«ä¸€èˆ¬ï¼Œç®€å•åœºæ™¯è¿˜è¡ŒğŸ‘€ã€‚\n\nç°åœ¨MLXçš„å¼€æºåº“å‘å±•ç”Ÿæœºå‹ƒå‹ƒï¼Œä¾‹å¦‚mlx-lm, mlx-whisperã€‚\n\nollamaä¸è¦å·æ‡’å•Šï¼",
    "post_content_en": "It's been a while since I last tweeted. Today, I'm sharing how to run the Qwen2-VL-7B model locally on a MacğŸ’».\n\nOllama is somewhat behind, but now LM Studio supports MLX format models and comes with a chat UIğŸ› ï¸.\n\nTested three models of Qwen's visual model; complex recognition is average, but simple scenes are okayğŸ‘€.\n\nThe open-source MLX library is thriving, with examples like mlx-lm and mlx-whisper.\n\nOllama, don't be lazy!",
    "link_lists": [
      "https://t.co/5AQ5R2a7VO",
      "https://x.com/LinearUncle/status/1848208380655255719?t=DClXsk6SURi4s_sLyJ71RA&s=03"
    ],
    "post_summary_cn": "åˆ†äº«äº†å¦‚ä½•åœ¨Macä¸Šè¿è¡Œåƒé—®Qwen2-VL-7Bæ¨¡å‹ï¼Œå¹¶æåˆ°LM Studioæ”¯æŒMLXæ ¼å¼æ¨¡å‹ã€‚æµ‹è¯•äº†åƒé—®çš„è§†è§‰æ¨¡å‹ï¼Œå¤æ‚è¯†åˆ«ä¸€èˆ¬ï¼Œç®€å•åœºæ™¯è¡¨ç°è‰¯å¥½ã€‚MLXå¼€æºåº“å‘å±•è¿…é€Ÿã€‚",
    "post_summary_en": "Shared how to run the Qwen2-VL-7B model on a Mac, mentioning LM Studio's support for MLX format models. Tested Qwen's visual models with average complex recognition and good performance in simple scenes. MLX open-source libraries are rapidly developing.",
    "post_datetime": "2024-10-21T09:45:17-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1928e2aef24d00cb": {
    "email_id": "1928e2aef24d00cb",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "TuringPost (@TheTuringPost) äº 2024å¹´10æœˆ14æ—¥æ˜ŸæœŸä¸€ä¸‹åˆ6:11å‘å¸ƒï¼š\n6. åŸå§‹è®ºæ–‡ï¼š\nGitHubï¼š\n\nBaichuan Inc, @Westlake_Uni, @ZJU_China",
    "post_content_en": "TuringPost (@TheTuringPost) posted at 6:11 PM on Mon, Oct 14, 2024:\n6. Original paper:\nGitHub:\n\nBaichuan Inc, @Westlake_Uni, @ZJU_China",
    "link_lists": [
      "https://t.co/fHrj6mSqsN",
      "https://t.co/iTXMquVHRv",
      "https://t.co/IxwqGV3nEf",
      "https://x.com/TheTuringPost/status/1845995803862773910?t=Hd_Dsm-YztU1HMhm-oCufg&s=03"
    ],
    "post_summary_cn": "TuringPostå‘å¸ƒäº†ä¸€ç¯‡å…³äºBaichuan Inc, è¥¿æ¹–å¤§å­¦å’Œæµ™æ±Ÿå¤§å­¦çš„å¸–å­ï¼ŒåŒ…å«åŸå§‹è®ºæ–‡å’ŒGitHubé“¾æ¥ã€‚",
    "post_summary_en": "TuringPost shared a post about Baichuan Inc, Westlake University, and Zhejiang University, including links to the original paper and GitHub.",
    "post_datetime": "2024-10-14T20:13:52-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "1923998e7242c0be": {
    "email_id": "1923998e7242c0be",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Tom Huang (@tuturetom) posted at 6:35 PM on Fri, Sep 27, 2024:\n10 è¡Œä»£ç å³å¯åŸºäº Meta æœ€æ–°çš„ Llama 3.2 è¿›è¡Œåè®­ç»ƒï¼Ÿè¿˜èƒ½ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†ï¼âš¡ï¸\n\nHuggingface å‘å¸ƒçš„ trl å¼€æºåº“æ”¯æŒäº† sft_vlm è„šæœ¬ï¼æ”¯æŒå¯¹ 11B çš„å¤šæ¨¡æ€æ¨¡å‹è¿›è¡Œå¾®è°ƒğŸ”¥\n\nå¾®è°ƒè„šæœ¬å¼€æºä»£ç  ğŸ‘‰",
    "post_content_en": "Tom Huang (@tuturetom) posted at 6:35 PM on Fri, Sep 27, 2024:\nCan post-train based on Meta's latest Llama 3.2 with just 10 lines of code? You can also use your own dataset! âš¡ï¸\n\nHuggingface's released trl open-source library supports the sft_vlm script! It supports fine-tuning of 11B multimodal models ğŸ”¥\n\nFine-tuning script open-source code ğŸ‘‰",
    "link_lists": [
      "https://t.co/o1seLclUjc",
      "https://t.co/fgrlg5n3GZ",
      "https://x.com/tuturetom/status/1839841204315566399?t=p5GeGLwnadbQVhVdC-p-iQ&s=03"
    ],
    "post_summary_cn": "Tom Huang ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨ Huggingface çš„ trl å¼€æºåº“å¯¹ Meta çš„ Llama 3.2 è¿›è¡Œå¾®è°ƒï¼Œå¹¶æ”¯æŒä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†ã€‚",
    "post_summary_en": "Tom Huang introduced how to fine-tune Meta's Llama 3.2 using Huggingface's trl open-source library, with support for using your own dataset.",
    "post_datetime": "2024-09-28T10:06:16-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "19239720ee4d8e1a": {
    "email_id": "19239720ee4d8e1a",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Kalyan KS (@kalyan_kpl) äº 2024å¹´9æœˆ27æ—¥æ˜ŸæœŸäº”æ™šä¸Š7:32å‘å¸ƒï¼š\n7ä¸ªéœ€è¦äº†è§£çš„LLMç”Ÿæˆå‚æ•°\n\n- max_tokens\n- temperature\n- top_p\n- top_k\n- frequency penalty\n- presence penalty\n- stop sequence\n\n#llms #parameters #nlproc #textgeneration #deeplearning",
    "post_content_en": "Kalyan KS (@kalyan_kpl) posted at 7:32 PM on Fri, Sep 27, 2024:\n7 LLM Generation Parameters To Know\n\n- max_tokens\n- temperature\n- top_p\n- top_k\n- frequency penalty\n- presence penalty\n- stop sequence\n\n#llms #parameters #nlproc #textgeneration #deeplearning",
    "link_lists": [
      "https://t.co/LEixr3a1Nv",
      "https://x.com/kalyan_kpl/status/1839855780130107462?t=2b9-a94nPH_3OylvyvALUg&s=03"
    ],
    "post_summary_cn": "Kalyan KS åˆ—å‡ºäº†7ä¸ªé‡è¦çš„LLMç”Ÿæˆå‚æ•°ã€‚",
    "post_summary_en": "Kalyan KS listed 7 important LLM generation parameters.",
    "post_datetime": "2024-09-28T09:23:51-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "1923148621b83746": {
    "email_id": "1923148621b83746",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Yangqing Jia (@jiayq) äº 2024å¹´9æœˆ26æ—¥æ˜ŸæœŸå››ä¸Šåˆ10:59å‘å¸ƒï¼š\næˆ‘ä»¬å¯¹@OpenAI çš„è¯­éŸ³æ¨¡å¼ä½“éªŒå’Œ@AIatMeta çš„llama 3.2ç‰ˆæœ¬æ„Ÿåˆ°æƒŠè®¶ã€‚é‚£ä¹ˆå¦‚ä½•å°†å®ƒä»¬ç»“åˆåœ¨ä¸€èµ·å‘¢ï¼Ÿ\nå¾ˆé«˜å…´åˆ†äº«Lepton LLMå¼•æ“ç°åœ¨æœ¬åœ°æ”¯æŒå¼€æºæ¨¡å‹çš„è¯­éŸ³è¾“å…¥å’Œè¾“å‡º - é¦–æ¬¡éŸ³é¢‘æ—¶é—´",
    "post_content_en": "Yangqing Jia (@jiayq) posted at 10:59 AM on Thu, Sep 26, 2024: We've been amazed by the @OpenAI voice mode experience and the @AIatMeta llama 3.2 release. And how about combining them together? Excited to share that the Lepton LLM engine now natively supports voice input and output for open source models - with a time to first audio",
    "link_lists": [
      "https://x.com/jiayq/status/1839364177485607185?t=5sOb9dNlRrCaYBw_ENhI3Q&s=03"
    ],
    "post_summary_cn": "Yangqing Jia è®¨è®ºäº†å°† OpenAI çš„è¯­éŸ³æ¨¡å¼ä¸ Meta çš„ llama 3.2 ç»“åˆçš„å¯èƒ½æ€§ï¼Œå¹¶å®£å¸ƒ Lepton LLM å¼•æ“ç°åœ¨æ”¯æŒè¯­éŸ³è¾“å…¥å’Œè¾“å‡ºã€‚",
    "post_summary_en": "Yangqing Jia discusses the possibility of combining OpenAI's voice mode with Meta's llama 3.2 and announces that the Lepton LLM engine now supports voice input and output.",
    "post_datetime": "2024-09-26T19:21:20-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "1922fd75f4b1b31a": {
    "email_id": "1922fd75f4b1b31a",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "å¾ˆæœ‰æ„æ€çš„ä¸€ä¸ªé¡¹ç›®ï¼Œç”¨Excelæ‰‹åŠ¨å®ç°AIç®—æ³•ç»ƒä¹ ï¼šai-by-hand-excelï¼Œåœ¨Excelé‡Œä½“éªŒAIçš„é­…åŠ›\n\nç›®å‰åŒ…å«äº†softmaxã€LeakyReLUã€åå‘ä¼ æ’­ã€Transformer å’Œå¾ªç¯ç¥ç»ç½‘ç»œ (RNN) ç­‰\n\nåé¢ä¼šå¢åŠ è‡ªæ³¨æ„åŠ›ã€å¤šå±‚æ„ŸçŸ¥å™¨ (MLP) å’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) ç­‰",
    "post_content_en": "An interesting project to manually implement AI algorithms using Excel: ai-by-hand-excel, experience the charm of AI in Excel.\n\nCurrently includes softmax, LeakyReLU, backpropagation, Transformer, and Recurrent Neural Network (RNN), etc.\n\nSelf-attention, Multilayer Perceptron (MLP), and Generative Adversarial Network (GAN) will be added later.",
    "link_lists": [
      "https://t.co/GcHbjVFi0y",
      "https://t.co/CwvCEPl3e6",
      "https://x.com/aigclink/status/1839232237558182076?t=eGwR_9gJFCQPSe4I1-hSRg&s=03"
    ],
    "post_summary_cn": "ä¸€ä¸ªæœ‰è¶£çš„é¡¹ç›®ï¼Œé€šè¿‡Excelæ‰‹åŠ¨å®ç°AIç®—æ³•ï¼Œç›®å‰åŒ…æ‹¬softmaxã€LeakyReLUç­‰ï¼Œæœªæ¥å°†å¢åŠ æ›´å¤šåŠŸèƒ½ã€‚",
    "post_summary_en": "An interesting project to implement AI algorithms manually using Excel, currently includes softmax, LeakyReLU, etc., with more features to be added.",
    "post_datetime": "2024-09-26T12:38:15-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1922d0a8e8c01cc0": {
    "email_id": "1922d0a8e8c01cc0",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Llama 3.2 è§†è§‰æ¨¡å‹æœ€æ–°åº”ç”¨æ–¹å‘: Napkins\næ˜¯ä¸€ä¸ªå¼€æºçš„çº¿æ¡†å›¾åˆ°åº”ç”¨ç”Ÿæˆå™¨, å®ƒçš„æ ¸å¿ƒåŠŸèƒ½æ˜¯æ¥æ”¶ç”¨æˆ·ä¸Šä¼ çš„çº¿æ¡†å›¾æˆ–è‰å›¾, ç„¶ååˆ©ç”¨ AIæŠ€æœ¯å°†å…¶è½¬æ¢ä¸ºå¯è¿è¡Œçš„ Web åº”ç”¨ç¨‹åº, å¤§å¤§åŠ é€ŸåŸå‹è®¾è®¡å’Œå¼€å‘è¿‡ç¨‹ã€‚\n\næŠ€æœ¯æ ˆ:\n- Meta Llama 3.1 405B ä½œä¸ºä¸»è¦è¯­è¨€æ¨¡å‹\n- Meta Llama",
    "post_content_en": "Llama 3.2 visual model's latest application direction: Napkins\nIt is an open-source wireframe to application generator, whose core function is to receive user-uploaded wireframes or sketches, and then use AI technology to convert them into runnable web applications, greatly accelerating the prototyping and development process.\n\nTech stack:\n- Meta Llama 3.1 405B as the main language model\n- Meta Llama",
    "link_lists": [
      "https://t.co/xmBywgvBLW",
      "https://t.co/3TCEDzHsMk",
      "https://x.com/shao__meng/status/1839097896970629193?t=1WaM4Y6LNVAU_KPX7yJNCA&s=03"
    ],
    "post_summary_cn": "Llama 3.2 è§†è§‰æ¨¡å‹åº”ç”¨äº Napkinsï¼Œåˆ©ç”¨ AI å°†çº¿æ¡†å›¾è½¬æ¢ä¸º Web åº”ç”¨ï¼ŒåŠ é€Ÿå¼€å‘ã€‚",
    "post_summary_en": "Llama 3.2 visual model is applied to Napkins, using AI to convert wireframes into web applications, accelerating development.",
    "post_datetime": "2024-09-25T23:35:20-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1922d0a64f799829": {
    "email_id": "1922d0a64f799829",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Meta æ­£åœ¨å®šä¹‰ LLM æ—¶ä»£çš„ PyTorchï¼Ÿâš¡ï¸ğŸ¤¯ğŸ¤¯ å®£å¸ƒæ­£å¼å¼€æº Llama Stackï¼ŒçŸ­æ—¶é—´é£™å‡ 648 Star ğŸ”¥\n\nLlama Stack å°† LLM åº”ç”¨æ„å»ºç”Ÿæˆå‘¨æœŸçš„æ‰€æœ‰ç»„ä»¶æ‰“åŒ…ï¼ŒåŒ…æ‹¬è®­ç»ƒã€å¾®è°ƒã€äº§å“è¯„ä¼°ã€è§‚æµ‹ã€Agent & Memoryã€åˆæˆæ•°æ®ç”Ÿæˆç­‰ï¼Œå¹¶æ”¯æŒ 9+ æä¾›å•†ğŸ’ª",
    "post_content_en": "Is Meta defining the PyTorch of the LLM era? âš¡ï¸ğŸ¤¯ğŸ¤¯ Announced the official open-source release of Llama Stack, which quickly soared to 648 stars ğŸ”¥\n\nLlama Stack packages all components of the LLM application development cycle, including training, fine-tuning, product evaluation, observation, Agent & Memory, synthetic data generation, etc., and supports 9+ providers ğŸ’ª",
    "link_lists": [
      "https://t.co/fcsGWb7JMm",
      "https://x.com/tuturetom/status/1839122960948539415?t=53Rk8TcILjSGEQR4RLlWsA&s=03"
    ],
    "post_summary_cn": "Meta å®£å¸ƒå¼€æº Llama Stackï¼Œè¿…é€Ÿè·å¾— 648 æ˜Ÿã€‚Llama Stack åŒ…å« LLM åº”ç”¨å¼€å‘çš„æ‰€æœ‰ç»„ä»¶ï¼Œæ”¯æŒå¤šä¸ªæä¾›å•†ã€‚",
    "post_summary_en": "Meta announced the open-source release of Llama Stack, quickly gaining 648 stars. Llama Stack includes all components for LLM application development and supports multiple providers.",
    "post_datetime": "2024-09-25T23:35:10-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1922d09f40b85f3c": {
    "email_id": "1922d09f40b85f3c",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "æå¼€å¤ (@kaifulee) äº 2024å¹´9æœˆ25æ—¥æ˜ŸæœŸä¸‰æ™šä¸Š9:01å‘å¸ƒï¼š\nOpenAIåˆšåˆšå‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿï¼Ÿï¼Ÿ è¿™æ˜¯æˆ‘æœ€å–œæ¬¢çš„â€œè®°è€…â€åœ¨æŠ¥é“å’Œæ€»ç»“æœ€è¿‘çš„äº‹ä»¶ã€‚",
    "post_content_en": "Kai-Fu Lee (@kaifulee) posted at 9:01 PM on Wed, Sep 25, 2024: What just happened at OpenAI??? Here is my favorite \"reporter\" reporting and summarizing recent events.",
    "link_lists": [
      "https://t.co/I3rsBQm2mE",
      "https://x.com/kaifulee/status/1839153300572352921?t=HRwn6Q0-mb9SyfpL-agMhA&s=03"
    ],
    "post_summary_cn": "æå¼€å¤æåˆ°OpenAIæœ€è¿‘å‘ç”Ÿçš„äº‹ä»¶ï¼Œå¹¶åˆ†äº«äº†ä»–æœ€å–œæ¬¢çš„è®°è€…çš„æŠ¥é“ã€‚",
    "post_summary_en": "Kai-Fu Lee mentioned recent events at OpenAI and shared a report from his favorite reporter.",
    "post_datetime": "2024-09-25T23:34:41-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "1922cfe391bc3ff1": {
    "email_id": "1922cfe391bc3ff1",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Tom Huang (@tuturetom) åœ¨ 2024 å¹´ 9 æœˆ 25 æ—¥æ˜ŸæœŸä¸‰æ™šä¸Š 7:07 å‘å¸ƒï¼š\nLlama Stack æŠ€æœ¯æ¶æ„ä¸€è§ˆ âš¡ï¸ æ–°ä¸€è½® LLMOps & Infra å¼€å§‹è§’é€ ğŸ¤”",
    "post_content_en": "Tom Huang (@tuturetom) posted at 7:07 PM on Wed, Sep 25, 2024:\nOverview of Llama Stack technology architecture âš¡ï¸ A new round of LLMOps & Infra competition begins ğŸ¤”",
    "link_lists": [
      "https://t.co/fcsGWb7JMm",
      "https://t.co/fnBu4Swfbn",
      "https://x.com/tuturetom/status/1839124585670947023?t=9To-rc9HKkCHYft-JBqQvw&s=03"
    ],
    "post_summary_cn": "Llama Stack æŠ€æœ¯æ¶æ„çš„æ¦‚è¿°ï¼Œæ ‡å¿—ç€æ–°ä¸€è½® LLMOps å’ŒåŸºç¡€è®¾æ–½çš„ç«äº‰å¼€å§‹ã€‚",
    "post_summary_en": "An overview of Llama Stack technology architecture, marking the start of a new round of LLMOps and infrastructure competition.",
    "post_datetime": "2024-09-25T23:21:52-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "1922a965beb632df": {
    "email_id": "1922a965beb632df",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Jim Fan (@DrJimFan) äº 2024å¹´9æœˆ25æ—¥æ˜ŸæœŸä¸‰ä¸Šåˆ11:42å‘å¸ƒï¼šæˆ‘åˆšåˆšè·å–äº†Llama-3.2-11Bï¼ˆè§†è§‰ï¼‰çš„è§†è§‰è¯­è¨€åŸºå‡†æ•°æ®ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œå¼€æºç¤¾åŒºåœ¨è½»é‡çº§æ¨¡å‹ç±»åˆ«ä¸­å¹¶ä¸è½åï¼Pixtralã€Qwen2-VLã€Molmoå’ŒInternVL2éƒ½è¡¨ç°å‡ºè‰²ã€‚å¼€æºAIæ¨¡å‹ä»æœªå¦‚æ­¤å¼ºå¤§ã€‚",
    "post_content_en": "Jim Fan (@DrJimFan) posted at 11:42 AM on Wed, Sep 25, 2024: I just pulled the numbers on vision-language benchmarks for Llama-3.2-11B (vision). Surprisingly, the open-source community at large isn't behind in the lightweight model class! Pixtral, Qwen2-VL, Molmo, and InternVL2 all stand strong. OSS AI models have never been stronger.",
    "link_lists": [
      "https://t.co/NQaVVggNcU",
      "https://x.com/DrJimFan/status/1839012622441787430?t=T3bmOCbh0H26HRaPM7SAiw&s=03"
    ],
    "post_summary_cn": "Jim Fan è®¨è®ºäº†Llama-3.2-11Bçš„è§†è§‰è¯­è¨€åŸºå‡†ï¼ŒæŒ‡å‡ºå¼€æºç¤¾åŒºåœ¨è½»é‡çº§æ¨¡å‹æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚",
    "post_summary_en": "Jim Fan discussed the vision-language benchmarks for Llama-3.2-11B, noting the strong performance of the open-source community in lightweight models.",
    "post_datetime": "2024-09-25T12:09:10-07:00",
    "source_language": "en",
    "confidence_score": 0.95
  },
  "19222379902e02e8": {
    "email_id": "19222379902e02e8",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "é˜¿é‡Œæœ€è¿‘å‘å¸ƒçš„ QWen 2.5 70B æœ‰ç‚¹ç‰›é€¼ğŸ‚ğŸº åœ¨ LiveBench Coding æ¦œå•ä¸Šå·²ç»æ‹¿ä¸‹ç¬¬äºŒï¼è¶…è¶Š gpt-4o å’Œæœ€è¿‘å‘å¸ƒçš„åŠæˆå“ O1-preview ğŸ¤ª\n\nLiveBench æ˜¯è‹±ä¼Ÿè¾¾ï¼ŒNYUï¼Œ@ylecun ç­‰äººå‘èµ·çš„æƒå¨æ¦œå•ï¼Œè¯„å®šæœ‰æŒ‘æˆ˜æ€§ä»»åŠ¡çš„æ¨¡å‹å¾—åˆ†",
    "post_content_en": "Alibaba's recently released QWen 2.5 70B is quite impressive ğŸ‚ğŸº. It has already taken second place on the LiveBench Coding leaderboard, surpassing gpt-4o and the recently released semi-finished O1-preview ğŸ¤ª.\n\nLiveBench is an authoritative leaderboard initiated by NVIDIA, NYU, @ylecun, and others, evaluating model scores on challenging tasks.",
    "link_lists": [
      "https://t.co/7Z2FixtvB2",
      "https://t.co/SYVWB1lZ0r",
      "https://x.com/tuturetom/status/1838036239603397071?t=UIO_Wv1KHiBCJK-1SuznSg&s=03"
    ],
    "post_summary_cn": "é˜¿é‡Œå‘å¸ƒçš„ QWen 2.5 70B åœ¨ LiveBench æ¦œå•ä¸Šæ’åç¬¬äºŒï¼Œè¶…è¶Šäº† gpt-4o å’Œ O1-previewã€‚",
    "post_summary_en": "Alibaba's QWen 2.5 70B ranks second on the LiveBench leaderboard, surpassing gpt-4o and O1-preview.",
    "post_datetime": "2024-09-23T21:08:43-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "19221f2c71f8d36e": {
    "email_id": "19221f2c71f8d36e",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "ä» LLM åˆ° LRM: OpenAI O1 æ¨¡å‹åœ¨ PlanBench ä¸Šçš„è§„åˆ’èƒ½åŠ›è¯„ä¼°\n\næœ€æ–° LLMs ä»ç„¶æ— æ³•è§„åˆ’, å¤§å‹æ¨ç†æ¨¡å‹ (LRM, OpenAI o1) å¯ä»¥å—? ä¸€èµ·çœ‹çœ‹ ğŸ‘‡\n\nLLMs çš„è§„åˆ’è¡¨ç°:\n- æœ€æ–°çš„ LLMs åœ¨æ™®é€š Blocksworld ä¸Šæœ‰æ‰€è¿›æ­¥, æœ€ä½³æ¨¡å‹ (LLaMA 3.1 405B) è¾¾åˆ° 62.5% çš„å‡†ç¡®ç‡\n- ä½†åœ¨æ··æ·†ç‰ˆæœ¬ (Mystery Blocksworld)",
    "post_content_en": "From LLM to LRM: Evaluation of OpenAI O1 Model's Planning Ability on PlanBench\n\nThe latest LLMs still cannot plan, can large reasoning models (LRM, OpenAI o1) do it? Let's take a look ğŸ‘‡\n\nPlanning performance of LLMs:\n- The latest LLMs have made progress in the regular Blocksworld, with the best model (LLaMA 3.1 405B) achieving 62.5% accuracy\n- But in the confusing version (Mystery Blocksworld)",
    "link_lists": [
      "https://t.co/8YZg0v2yK3",
      "https://x.com/shao__meng/status/1838366411389063616?t=jbXqWLf--KmI0_KDrC2vcg&s=03"
    ],
    "post_summary_cn": "è®¨è®ºäº†æœ€æ–°çš„ LLMs åœ¨è§„åˆ’èƒ½åŠ›ä¸Šçš„ä¸è¶³ï¼Œå¹¶è¯„ä¼°äº†å¤§å‹æ¨ç†æ¨¡å‹ (LRM, OpenAI o1) çš„æ½œåŠ›ã€‚æœ€æ–°çš„ LLMs åœ¨æ™®é€š Blocksworld ä¸Šæœ‰æ‰€è¿›æ­¥ï¼Œä½†åœ¨æ··æ·†ç‰ˆæœ¬ä¸­è¡¨ç°ä¸ä½³ã€‚",
    "post_summary_en": "Discusses the shortcomings of the latest LLMs in planning ability and evaluates the potential of large reasoning models (LRM, OpenAI o1). The latest LLMs have made progress in the regular Blocksworld but perform poorly in the confusing version.",
    "post_datetime": "2024-09-23T19:53:32-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  },
  "192124fc66236e00": {
    "email_id": "192124fc66236e00",
    "post_labels": [
      "LLM"
    ],
    "post_content_cn": "Tom Huang (@tuturetom) posted at 8:16 PM on Mon, Sep 16, 2024: 275+ æ’ç”»ï¼Œ12+ ç« èŠ‚ï¼Œå´æ©è¾¾åŠ›èï¼âš¡ï¸å®Œç¾å‘ˆç° LLM å·¥ä¸šçº§åº”ç”¨ï¼Œæä¾›å®Œæ•´å¯è¿è¡Œçš„ä»£ç å’Œ Paper å¼•ç”¨ğŸ¤¯ğŸ¤¯ï¼Œè¿™æœ¬ã€Šå®è·µå¤§è¯­è¨€æ¨¡å‹ã€‹ä¹Ÿå¤ªå¥½äº†ğŸ”¥ ä»‹ç»åŒ…æ‹¬è¯­è¨€æ¨¡å‹ã€Prompt Engineeringã€RAGã€å¤šæ¨¡æ€ã€å¾®è°ƒç­‰æ ¸å¿ƒå·¥ç¨‹å®è·µæŠ€æœ¯ï¼Œæ¯ç« æä¾›å®Œæ•´å¯è¿è¡Œçš„ä»£ç å’Œç¯å¢ƒé…ç½®",
    "post_content_en": "Tom Huang (@tuturetom) posted at 8:16 PM on Mon, Sep 16, 2024: Over 275 illustrations, 12+ chapters, recommended by Andrew Ng! âš¡ï¸ Perfectly presents industrial-grade applications of LLM, providing complete runnable code and paper references ğŸ¤¯ğŸ¤¯, this book 'Practical Large Language Models' is amazing ğŸ”¥ The introduction includes core engineering practice techniques such as language models, Prompt Engineering, RAG, multimodal, fine-tuning, etc., with complete runnable code and environment configuration provided in each chapter.",
    "link_lists": [
      "https://t.co/QTcuP31CjZ",
      "https://t.co/HY8Q9SJrIw",
      "https://x.com/tuturetom/status/1835880356475724141?t=KldLH9XhzZ6TVotOPrUbeA&s=03"
    ],
    "post_summary_cn": "Tom Huangæ¨èäº†ä¸€æœ¬å…³äºå¤§è¯­è¨€æ¨¡å‹çš„ä¹¦ï¼ŒåŒ…å«275+æ’ç”»å’Œ12+ç« èŠ‚ï¼Œæä¾›å®Œæ•´ä»£ç å’Œç¯å¢ƒé…ç½®ã€‚",
    "post_summary_en": "Tom Huang recommends a book on large language models, featuring over 275 illustrations and 12+ chapters, with complete code and environment configuration.",
    "post_datetime": "2024-09-20T19:01:11-07:00",
    "source_language": "cn",
    "confidence_score": 0.95
  }
}